% -*- TeX -*- -*- Soft -*-

Analyzing the effect that a syntactic restriction (such as safety) has on the game-semantic model is a difficult task since the main feature of game semantics is precisely to be syntax-independent.
The aim of this chapter is to establish an explicit correspondence between the game denotation of a term and its syntax. This will be used in the next chapter to give a characterization of the game semantics of the safe lambda calculus.

Our approach follows ideas recently introduced by Ong \cite{OngLics2006}, namely the notion of \emph{computation tree} of a simply-typed lambda-term and \emph{traversals} over the computation tree. A computation tree is just an abstract syntax tree (AST) representation of the $\eta$-long normal form of a term. Traversals are justified sequences of nodes of the computation tree respecting some formation rules. They are meant to describe the computation of the term, but at the same time they carry information about the syntax of the term in the following sense: the \emph{P-view} of a traversal (computed in the same way as P-view of plays in game semantics) is a path in the computation tree. Traversals provide a way to perform \emph{local computation} of $\beta$-reductions as opposed to a global approach where $\beta$-redexes are contracted using substitution.

The culmination of this chapter is the \emph{Correspondence Theorem} (Theorem \ref{thm:correspondence}). It states that traversals over the computation tree are just representations of the uncovering of plays in the strategy-denotation of the term. Hence there is an isomorphism between the strategy denotation of a term and its revealed game denotation. In a nutshell, the revealed denotation is computed similarly to the standard strategy denotation except that internal moves are not hidden after composition. In order to make a connection with the standard game denotation, we define an operation that extracts the \emph{core} of a traversal by eliminating occurrences of ``internal nodes''. These node occurrences are the counterparts of internal moves that are hidden when performing strategy composition in game semantics. This leads to a correspondence between the standard game denotation of a term and the set traversal cores over its computation tree.

Using this correspondence, it possible to analyze the effect that a syntactic restriction has on the strategy denotation of a term. This is illustrated in the next chapter where we rely on the Correspondence Theorem to analyze the game semantics of the safety restriction.

 \bigskip

 \emph{Related works}:
 The useful transference technique between plays and traversals was
originally introduced by Ong for studying
the decidability of monadic second-order theories of infinite structures generated by higher-order grammars \cite{OngLics2006}.
In this setting, the $\Sigma$-constants or terminal symbols are at most order 1, and are \emph{uninterpreted}.
Here we present an extension of this framework to the
general case of the simply-typed lambda calculus with free variables
of any order. Further the term considered is not required to be of ground type
contrary to higher-order grammars. This requires us to add new traversal rules to handle variables whose value is undetermined (\ie, those that cannot be resolved through redex-contraction). We also extend computation trees with additional nodes
accounting for answer moves of game semantics. This enables our framework to be extended to languages with interpreted constants such as \pcf\ and Idealized Algol.

A notion of local computation of $\beta$-reduction has also been investigated through the use of special graphs called ``virtual nets'' that embed the lambda calculus \cite{DanosRegnier-Localandasynchronou}.

Asperti et~al.\ introduced \cite{DBLP:conf/lics/AspertiDLR94} a syntactic representation of lambda-terms based on Lamping's graphs \citep{lamping}. They unified various notions of paths (regular, legal, consistent and persistent paths) that have appeared in the literature as ways to implement graph-based reduction of lambda-expressions. We can regard a traversal as an alternative notion of path adapted to the graph representation of lambda-expressions given by computation trees.

\section{Computation tree}
We work in the general setting of the simply-typed lambda calculus extended with a fixed set $\Sigma$ of (higher-order) uninterpreted constants. We fix a simply-typed term-in-context $\Gamma \entail M :T$ for the rest of the section.

%%% Section to include in the LMCS paper (not needed in the thesis because eta-long nf are already defined in the background chapter
%\subsection{Eta-long normal form}

\begin{notation}[Simple types]
 For simplicity we assume that types are generated over a single atomic type $o$.
  By convention, $\typear$ associates to the right. Thus every simple type can be written as $A_1 \typear \cdots \typear A_n \typear o$ which we abbreviate to $(A_1, \cdots, A_n, o)$; in case $n = 0$, we identify $(o)$ with $o$.
\end{notation}

\subsection{Definition}

We define the \emph{computation tree} of a simply-typed lambda-term as a tree representation of its \emph{$\eta$-long normal form}. Our definition generalizes the notion of computation tree for higher-order recursion schemes \cite{OngLics2006}.

\begin{definition}
\label{dfn:etalongnf}
The \defname[eta-long normal form]{$\eta$-long normal form}, written $\elnf{M}$ or sometimes $\etalnf{M}$, of a (type-annotated)
 term $M$ of type $(A_1,\ldots,A_n,o)$ with $n \geq 0$ is defined as follows:%
\indexnotation{$\elnf{M}$}{Eta-long normal form of the term $M$}%
\begin{eqnarray*}
  \elnf{\lambda x^\tau . N } & \defeq & \lambda x^\tau . \elnf{N} \\
  \elnf{\alpha N_1 \ldots N_m } & \defeq & \lambda \overline{\varphi}^{\overline{A}} . \alpha \elnf{N_1}\ldots \elnf{N_m} \elnf{\varphi_1} \ldots \elnf{\varphi_n} \\
  \elnf{(\lambda x^\tau . N) N_1 \ldots N_p } & \defeq & \lambda \overline{\varphi}^{\overline{A}} . (\lambda x^\tau . \elnf{N}) \elnf{N_1} \ldots \elnf{N_p} \elnf{\varphi_1} \ldots \elnf{\varphi_n}
\end{eqnarray*}
where $m \geq 0$, $p\geq 1$, $x$ is a variable, $\overline{\varphi} = \varphi_1 \ldots \varphi_n$ and each $\varphi_i : A_i$ is a fresh variable, and $\alpha$ is either a variable or a constant. The binder notation `$\lambda \overline{\varphi}^{\overline A}$' stands for
`$\lambda \varphi_1^{A_1} \ldots \varphi_n^{A_n}$' if $n\geq 1$, and for `$\lambda$' (called the \emph{dummy lambda}) in the case $n=0$.
\end{definition}


Thus an $\eta$-long nf has the shape $\lambda x_1 \ldots x_n . s_0 s_1 \ldots s_m$ where $m, n \geq 0$ such that:
\begin{inparaenum}[i.]
\item $s_0 s_1 \ldots s_m$ is of ground type,
\item each $s_j$ for $j \in 1..m$ is in $\eta$-long nf,
\item either $s_0$ is a variable or a constant and $m\geq0$, or $s_0$ is an abstraction in $\eta$-long nf and $m\geq1$.
\end{inparaenum}
Note that $\eta$-long normal forms of ground type have the form  $\lambda . N$ with a `dummy lambda'.

\begin{definition}
Let $\Gamma \stentail M:T$ be a simply-typed term with variable names from $\mathcal{V}$ and constants from $\Sigma$.
The \emphind{pre-computation} tree $\tau^-(M)$ with labels taken from $ \{ @ \} \union \Sigma \union \mathcal{V}
  \union \{ \lambda x_1 \ldots x_n \ | \ x_1 ,\ldots, x_n \in
  \mathcal{V}, n \geq 0 \}$, is defined inductively on its $\eta$-long normal form $\etalnf{M}$ as follows.
\begin{eqnarray*}
  \mbox{For $m\geq 0$, $\$ \in \mathcal{V}\union\Sigma$: } \tau^-(\lambda \overline{x} . \$ s_1 \ldots s_m : o) &\defeq& \lambda \overline{x} \langle \$ \langle\tau^-(s_1),\ldots,\tau^-(s_m)\rangle\rangle \\
  \mbox{for $m \geq 1$: } \tau^-(\lambda \overline{x} . (\lambda y.t) s_1 \ldots s_m :o) &\defeq& \lambda \overline{x} \langle @ \langle \tau^-(\lambda y.t),\tau^-(s_1),\ldots,\tau^-(s_m) \rangle \rangle \enspace ,
\end{eqnarray*}
where we write $l\langle t_1, \ldots, t_n \rangle$, for $n \geq 0$, to denote the \emph{ordered tree} whose root is labelled $l$ and has $n$ child-subtrees $t_1$, \ldots, $t_n$. The trees from the equations above are illustrated in Table \ref{tab:defcomptree}.
\end{definition}

In the tree $\tau^-(M)$, nodes at levels 0, 2, 4, etc.~are labelled by lambdas, whereas nodes at levels 1, 3, 5, etc.~are labelled by variables, constants or application nodes. Note that a lambda label $\lambda\overline x$ can represent several consecutive abstractions or it can just be a \emphind{dummy lambda} i.e.~$|x| = 0$ (if the corresponding subterm is of ground type).

\begin{table}
  \centering
\begin{tabular}{cp{20pt}c}
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,inner ysep=0.5mm,shape border rotate=90,sibling distance=15mm]
    \node (root) {$\lambda\overline{x}$}
        child { node{$z$}
                child[child anchor=north]{node[isosceles triangle,draw,anchor=north]{$\tau^-(s_1)$}}
                child{node{$\ldots$}}
                child[child anchor=north]{node[isosceles triangle,draw,anchor=north]{$\tau^-(s_m)$}}
        };
\end{tikzpicture}
& &
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,inner ysep=0.5mm,shape border rotate=90,sibling distance=20mm]
    \node(root){$\lambda\overline{x}$}
        child { node{$@$}
                child[child anchor=north]{node[isosceles triangle,draw,anchor=north]{$\tau^-(\lambda\overline{y}.t)$}}
                child[child anchor=north]{node[isosceles triangle,draw,anchor=north]{$\tau^-(s_1)$}}
                child{node{$\ldots$}}
                child[child anchor=north]{node[isosceles triangle,draw,anchor=north]{$\tau^-(s_m)$}}
        };
\end{tikzpicture}\\
$\tau^-( \lambda\overline{x} . z s_1 \ldots s_m : o)$
& &
$\tau^-(\lambda\overline{x} . (\lambda\overline{y}.t) s_1 \ldots s_m : o)$ \\
$m\geq0$ and $z\in\mathcal{V}\union\Sigma$ &&
$m \geq 1$
\end{tabular}
\caption{The tree $\tau^-(M)$.}\label{tab:defcomptree}
\end{table}

\begin{definition}
\label{dfn:comptree}
Let $M$ be a simply-typed term not necessarily in $\eta$-long normal
form. Let $\mathcal{D}$ be the set of values of the base type $o$.
The \defname{computation tree} of $M$, written $\tau(M)$, is the tree
obtained from $\tau^-(\elnf{M})$ by attaching leaves to each node: for every node $n \in \tau^-(M)$, the corresponding node in $\tau(\elnf{M})$ has a
child leaf labelled $v_n$, called \defname{value-leaf}, for every value $v \in \mathcal{D}$.
\indexnotation{$\tau(M)$}{Computation tree of the term $M$}%
\end{definition}

\emph{Inner nodes} of the tree are thus of three kinds:
\begin{itemize}
\item $\lambda$-nodes labelled $\lambda \overline{x}$ for a list of variables $\overline{x}$
\item long-application nodes labelled @
\item variable or constant nodes with labels in $\Sigma \union \mathcal{V}$.
\end{itemize}
The $0^{th}$ child of an @-node is called a \defname[prime!node]{prime node}.
The children nodes of @-nodes and $\Sigma$-nodes are called \index{spawn node}\defname[node!spawn]{spawn nodes}.
\bigskip

\begin{example} \hfill
\begin{itemize}
\item The computation tree of a ground type variable or constant $\alpha$ is
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,inner ysep=0.5mm,sibling distance=10mm]
\node (root) {$\lambda$}
child {node {$\alpha$} };
\end{tikzpicture}

\item The computation tree of a higher-order variable or constant $\alpha : (A_1,\ldots,A_p,o)$ has the following form:
\begin{tikzpicture}[baseline=(root.base),level distance=3ex,sibling distance=15mm]
\node (root) {$\lambda$}
child {node {$\alpha$}
    child{node {$\lambda\overline{\xi_1}$}
          child{node{$\ldots$}}}
    child{node{$\ldots$}}
    child{node {$\lambda\overline{\xi_p}$}
          child{node{$\ldots$}}}
    };
\end{tikzpicture}
\end{itemize}
\end{example}


\begin{example}
\label{examp:comptree}
  Take $\stentail \lambda f^{o \typear o} .
(\lambda u^{o \typear o} . u) f : (o \typear o) \typear
o \typear o$.
\bigskip

\noindent
\begin{tabular}{cc}
Its $\eta$-long normal form is: & Its computation tree is:\\[8pt]
\begin{minipage}{0.45\textwidth}
\centering
$\begin{array}{ll}
 &\stentail  \lambda f^{o \typear o} z^o . \\
&\qquad(\lambda u^{o \typear o} v^o . u (\lambda.v)) \\
&\qquad(\lambda y^o. f y) \\
&\qquad(\lambda.z) \\
&: (o \typear o) \typear o \typear o
\end{array}$
\end{minipage}
&
\begin{minipage}{0.45\textwidth}
\centering
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,inner ysep=0.5mm,sibling distance=10mm]
\node (root) {$\lambda f z$}
child {node {$@$}
    child {node {$\lambda u v$}
           child {node {$u$}
                  child {node {$\lambda$}
                      child {node {$v$}}
                  }
           }
    }
    child {node {$\lambda y$}
           child {node {$f$}
                  child {node {$\lambda$}
                      child {node {$y$}}
                  }
           }
    }
    child {node {$\lambda$}
           child {node {$z$}}
    }
    };
\end{tikzpicture}
\end{minipage}
\end{tabular}
\end{example}

\begin{example}
  Take $\stentail \lambda u^o v^{((o \typear o) \typear o)} . (\lambda x^o . v (\lambda z^o . x)) u : o \typear ((o \typear o) \typear o) \typear o$.
  \bigskip

\noindent
\begin{tabular}{cc}
Its $\eta$-long normal form is: & Its computation tree is:\\[8pt]
\begin{minipage}{0.45\textwidth}
\centering
$\begin{array}{ll}
 &\stentail  \lambda u^o v^{((o \typear o) \typear o)} . \\
&\qquad(\lambda x^o . v (\lambda z^o . x)) u \\
&: o \typear ((o \typear o) \typear o) \typear o
\end{array}$
\end{minipage}
&
\begin{minipage}{0.45\textwidth}
\centering
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,inner ysep=0.5mm,sibling distance=10mm]
\node (root) {$\lambda u v$}
child {node {$@$}
    child {node {$\lambda x$}
           child {node {$v$}
                  child {node {$\lambda z$}
                      child {node {$x$}}
                  }
           }
    }
    child {node {$\lambda$}
           child {node {$u$}}
    }
    };
\end{tikzpicture}
\end{minipage}
\end{tabular}
\end{example}


\begin{notations} \indexnotation{$\theroot$}{Root of the computation tree}%
We write $\theroot$ to denote the root of $\tau(M)$. The set of nodes of the tree is denoted by $\Nodes$. The subset of \index{node!inner}\emphind{inner nodes} is denoted $\INodes$ and the subset of \index{node!leaf}\emphind{leaf nodes} is denoted $\LNodes$ (Thus $\Nodes = \INodes \union \LNodes$). We write $E \subseteq \Nodes \times \Nodes$ to denote
the parent-child relation on the tree nodes.

We write $\INodes_\Sigma$ for the set of $\Sigma$-labelled (inner) nodes, $\INodes_@$ for the set of @-labelled nodes, $\INodes_{\sf var}$ for the set of variable nodes,
$\INodes_{\sf fv}$ for the subset of $\INodes_{\sf var}$ consisting of free-variable nodes, $\INodes_{\sf prime}$ for the set of prime nodes and $\INodes_{\sf spawn}$ for the set of spawn nodes.

For $\$$ ranging over $\{@, \lambda, {\sf var}, {\sf fv} \}$,
we write $\LNodes_\$$ to denote the set of value-leaves which are children of nodes from $\INodes_\$$; formally $\LNodes_\$ = \{ v_n \ | \ n \in \INodes_\$, v \in \mathcal{D} \}$. We write $\Nodes_\$$ for $\INodes_\$ \union \LNodes_\$ $.

We partition the set of nodes in two subsets: the \index{node!P-}\defname{P-nodes}
$\INodes_{\sf var} \union \INodes_\Sigma \union \INodes_@ \union \LNodes_\lambda$,
and the \index{node!O-}\defname{O-nodes} $\LNodes_{\sf var} \union \LNodes_\Sigma \union \LNodes_@\union \INodes_\lambda$.

Each subtree of the computation tree $\tau(M)$ represents a subterm of $\elnf{M}$.
For every lambda node $n$ in $\INodes_\lambda$ we write $M^{(n)}$ for the subterm of $\elnf{M}$ corresponding to the subtree of $\tau(M)$ rooted at $n$, and $\Nodes^{(n)}$ for the set of nodes of this subtree (which is isomorphic to $\tau(M^{(n)})$); formally $\Nodes^{(n)} = E^*(\{n\})$ where $E^*$ denotes the transitive, reflexive closure of the parent-child relation $E$.
(In particular we have $M^{(\theroot)} = \elnf{M}$.)
\end{notations}

%\begin{remark}
%Since the computation tree is computed from the eta-long normal form, for every subtree of $\tau(M)$ of the form
%\begin{tikzpicture}[baseline=(root.base),level distance=3ex,sibling distance=15mm]
%\node (root) {$\lambda\overline\varphi$}
%child {node {$n$}
%    child{node {$\lambda\overline{\xi_1}$}
%          child{node{$\ldots$}}}
%    child{node{$\ldots$}}
%    child{node {$\lambda\overline{\xi_p}$}
%          child{node{$\ldots$}}}
%    };
%\end{tikzpicture}, we have $\ord{M^{(n)}}=0$.
%\end{remark}

\begin{definition}[Type and order of a node]
\label{def:nodeorder}
Suppose $\Gamma \entail M : T$.
The \defname{type} of an inner-node $n \in \INodes$ of $\tau(M)$ written $\typeof{n}$ is defined as follows:
\begin{eqnarray*}
\typeof{\theroot} &=& \Gamma \typear T, \\
\hbox{for $n \in (\INodes_\lambda \union \INodes_@) \setminus \{\theroot \}$: } \typeof{n} &=& \hbox{type of the term $M^{(n)}$,} \\
\hbox{ for $n\in \INodes_{\sf var} \union \INodes_\Sigma$: } \typeof{n} &=& \hbox{type of the variable labelling $n$}.
\end{eqnarray*}
where the notation $\Gamma \typear T$ is an abbreviation for
$(A_1,\ldots,A_p, T)$ and $A_1,\ldots, A_p$ are the types of the variables in the context $\Gamma$.

The \defname[order!node]{order} of a node $n \in \Nodes$, written $\ord{n}$, is defined as follows: a value-leaf from $\LNodes$ has order $0$ and the order of an inner node from $\INodes$ is defined as the order of its type.
\end{definition}

Since the computation tree is calculated from the $\eta$-long normal form, all the @-nodes have order $0$ ($\ord{@} = 0$);
for every lambda node $\lambda \overline{\xi} \neq
\theroot$ we have $\ord{\lambda \overline{\xi}} = 1+
\max_{z\in \overline{\xi}} \ord{z}$; and if the root $\theroot$ is labelled $\lambda \overline{\xi}$ then $\ord{\theroot} = 1 + \max_{z\in \overline{\xi}\union \Gamma} \ord{z}$ with the convention $\max \emptyset = -1$.

\begin{definition}[Binder]
We say that a variable node $n$ labelled $x$ is \defname{bound} by a node $m$, and $m$ is called the \defname{binder} of $n$, if $m$ is
the closest node in the path from $n$ to the root such that $m$ is
labelled $\lambda \overline{\xi}$ with $x\in \overline{\xi}$.
\end{definition}


\subsection{Pointers and justified sequence of nodes}
\subsubsection{Definitions}
\begin{definition}[Enabling]
The \defname{enabling relation} $\enable$ is defined on the set of
nodes of the computation tree as follows. We write $m \enable n$ and we say that $m$ enables $n$ if and only if
$m \in \LNodes \union \INodes_\lambda \union \INodes_{\sf var}$
and one of the following conditions holds:
\begin{itemize}
\item $n \in \INodes_{\sf fv}$ and $m$ is the root $\theroot$;
\item $n \in \INodes_{\sf var} \setminus \INodes_{\sf fv}$ and
        $m$ is $n$'s binder, in which case we write $m \enable_i n$ to indicate that $n$ is the $i^{\sf th}$ variable bound by $m$;
\item $n\in \INodes_\lambda$ and  $m$ is $n$'s parent;
\item $n \in \LNodes$ and $m$ is $n$'s parent (\ie, $n=v_m$ for some $v\in\mathcal{D}$).
\end{itemize}
\end{definition}

Nodes that are not in the image of the relation $\enable$ are called \index{node!initial}\defname{initial nodes}; the initial P-nodes are $\INodes_@ \union \INodes_\Sigma$ and the only initial O-node is the root $\theroot$.

We say that a node $n_0$ of the computation tree is \defname{hereditarily enabled} by $n_p \in \Nodes$ if there are nodes $n_1,\ldots, n_{p-1} \in \Nodes$ such that $n_{i+1}$ enables $n_{i}$
for all $i\in 0..p-1$.

For every sets of nodes $S, H \subseteq \Nodes$ we write $S^{H\enable}$ to denote
the subset $S \inter \enable^*(H)$ of $S$ consisting of nodes hereditarily enabled by some node in $H$. Formally:
$$S^{H\enable} = \{ n \in S \ | \exists n_0 \in H \mbox{ s.t. }n_0  \enable^* n \} \enspace .$$
If $H$ is a singleton $\{n_0\}$ then we abbreviate $S^{\{n_0\}\enable}$ into $S^{n_0\enable}$.
\indexnotation{$S^{H\enable}$}{Subset of $S$ consisting of the nodes hereditarily enabled by some node in $H$}%

It can be verified that a non-initial node is either hereditarily enabled by the root, an application node or a constant node; thus the subsets $\{\theroot \}$, $\INodes_@$, $\INodes_@$, $\Nodes^{\theroot\enable}$, $\Nodes^{\INodes_@\enable}$
and $\Nodes^{\INodes_\Sigma\enable}$ form a partition of $N$. The elements of $\INodes_{\sf var}^{\theroot\enable}$ (\ie, variable nodes that are hereditarily enabled by the root of $\tau(M)$) are called
\defname{input-variables nodes}.
\smallskip

We use the following numbering conventions:
The first child of a @-node---a prime node---is numbered $0$;
the first child of a variable or constant node is numbered $1$;
and variables in $\overline{\xi}$ are numbered from $1$ onward ($\overline{\xi} = \xi_1 \ldots \xi_n$).
We write $n.i$ to denote the $i^{th}$ child of node $n$.

\begin{definition}[Justified sequence of nodes]
\label{dfn:justseqnode} A \defname{justified sequence of nodes} is a
sequence of nodes $s$ of the computation tree $\tau(M)$ with
pointers. Each occurrence in $s$ of a node $n$
in $\LNodes \union \INodes_\lambda \union \INodes_{\sf var}$ has a link pointing to some preceding occurrence of a node $m$ satisfying $m \enable n$;
and occurrences of nodes in $\INodes_@ \union \INodes_\Sigma$ do not have pointer.

If an occurrence $n$ points to an occurrence $m$ in $s$ then we say that $m$ \defname{justifies} $n$.
If $n$ is an inner node then we represent this pointer in the sequence as \Pstr[0.4cm]{(m){m} \ldots (n-m,45:i) n } where the label indicates that either $n$ is labelled with the $i^{th}$ variable abstracted by the
$\lambda$-node $m$ or that $n$ is the $i^{\sf th}$ child of $m$.
The pointer associated to a leaf $v_m$, for some value $v\in\mathcal{D}$ and internal node $m\in \INodes$, is represented as
$\Pstr[0.5cm]{ (m){m} \cdot \ldots \cdot (vm-m,40:v){v_m} }$.
\end{definition}

To sum-up, a pointer in a justified sequence of nodes has
one of the following forms:
\smallskip

\begin{tabular}{cll}
    & \Pstr[0.7cm]{ (m){r} \cdot \ldots \cdot (n-m,40){z} }
    & for some occurrences $r$ of $\tau(M)$'s root and $z \in \INodes_{\sf fv}$\enspace ;
\\
    or
    & \Pstr[0.7cm]{ (m){\lambda \overline{\xi}} \cdot \ldots \cdot (n-m,40:i){\xi_i} }
& for some variable $\xi_i$ bound by $\lambda \overline{\xi}$, $i \in 1..|\overline{\xi}|$\enspace ;
\\
    or
    & \Pstr[0.7cm]{ (m){@} \cdot \ldots \cdot (n-m,40:j){\lambda \overline{\eta}} }
    & $j\in \{ 1 ..(arity(@)-1) \}$\enspace ;
\\
    or
    & \Pstr[0.7cm]{ (m){\alpha } \cdot \ldots \cdot (n-m,40:k){\lambda \overline{\eta}} },
    & for $\alpha \in \INodes_{\Sigma} \union \INodes_{\sf var}$,  $k \in \{ 1 ..arity(\alpha) \}$\enspace ;
\\
    or
    & $\Pstr[0.7cm]{ (m){m} \cdot \ldots \cdot (vm-m,40:v){v_m} }$
    & for some value $v\in \mathcal{D}$ and inner node $m \in \Nodes$\enspace .
\end{tabular}
\bigskip


We say that an inner node $n$ in of a justified sequence of nodes is
\defname{answered}\footnote{This terminology is deliberately suggestive of the correspondence with game-semantics.} by the value-leaf $v_n$ if there is an occurrence of $v_n$ for some value $v$ in the
sequence that points to $n$, otherwise we say that $n$ is
\defname[node!unanswered]{unanswered}. The last unanswered node is called the
\index{node!pending}\defname{pending node}.  A justified sequence of nodes is
\defname[well-bracketing]{well-bracketed} if each value-leaf occurring in it is justified by the pending node at that point.

For every justified sequence of nodes $t$ we write $?(t)$
to denote the subsequence of $t$ consisting only of unanswered
nodes. Formally:
\begin{align*}
  ?(\Pstr[0.4cm]{u_1 \cdot (n){n} \cdot u_2 \cdot (nv-n){v_n} }  ) &= ?(u_1 \cdot n \cdot u_2) \setminus \{ n \}
        & \mbox{for some value $v\in\mathcal{D}$ \enspace ,} \\
  ?(u \cdot n)   &= ?(u)\cdot n    & \mbox{for $n\not\in \LNodes$ \enspace ,}
\end{align*}
where $u \setminus \{ n \}$ denotes the subsequence of $u$ obtained by removing the occurrence $n$.

If $u$ is a well-bracketed sequences then $?(u)$ can be defined as follows:
\begin{align*}
  ?(\Pstr[0.4cm]{u \cdot (n){n} \ldots (nv-n){v_n} }  ) &= ?(u)
          & \mbox{for some value $v\in\mathcal{D}$\enspace ,}  \\
    ?(u \cdot n) &= ?(u)\cdot n    & \mbox{where $n\not\in \LNodes$} \enspace .
\end{align*}


\begin{notations}\indexnotation{$s \prefixof s'$}{Prefix ordering for (justified) sequences}%
We write $s = t$ to denote that the justified sequences $s$ and $t$
have the same nodes \emph{and} pointers. Justified sequence of nodes can
be ordered using the prefix ordering: $t \prefixof t'$ if and only
if $t=t'$ or the sequence of nodes $t$ is a finite prefix of $t'$
(and the pointers of $t$ are the same as the pointers of the
corresponding prefix of $t'$). Note that with this definition,
infinite justified sequences can also be compared. This ordering
gives rise to a complete partial order.
We say that a node $n_0$ of a justified sequence is \defname{hereditarily justified} by $n_p$ if there
 are nodes $n_1, n_2, \ldots n_{p-1}$ in the sequence such that $n_i$ points to $n_{i+1}$ for all $i\in \{0..p-1\}$.
We write $t^\omega$ to denote the last element of the sequence $t$.
%\indexnotation{$\ip(t)$}{Immediate prefix of a justified sequence}%
% and $\ip(t)$ for the immediate prefix of $t$ obtained by removing $t$'s last occurrence.
%\indexnotation{$\jp(t)$}{Justifying prefix of a justified sequence}%
%We write $\jp(t)$ for the sequence $t_{\prefixof j}$ where $j$ is the justifier of $t^\omega$ in $t$.
\end{notations}

\subsubsection{Projection}

We define two different projection operations on justified sequences
of nodes.

\begin{definition}[Projection on a set of nodes]
Let $A$ be a subset of $\Nodes$, the set of nodes of
$\tau(M)$, and $t$ be a justified sequence of nodes then we write
$t\filter A$ for the subsequence of $t$ consisting of nodes in $A$.
This operation can cause a node $n$ to lose its pointer. In that
case we reassign the target of the pointer to the last node in
$t_{\prefixof n}\filter A$ that hereditarily justifies $n$ (This node can be found by following the pointers from $n$ until reaching a node appearing in $A$); if there is no such node then $n$ just loses its pointer.
\end{definition}


\begin{definition}[Hereditary projection]
Let $t$ be a justified sequence of nodes of $\travset(M)$ and $n$ be
some occurrence in $t$. We define the justified sequence $t \filter
n$ as  the subsequence of $t$ consisting of nodes hereditarily
justified by $n$ in $t$.
\indexnotation{$t \filter n$}{Hereditary projection of justified sequence $t$ with respect to occurrence $n$}%
\end{definition}

\begin{lemma}
\label{lem:projection_continuous} The projection function $\_
\filter n$ defined on the cpo of justified sequences ordered by the
prefix ordering is continuous.
\end{lemma}
\begin{proof}
Clearly $\_ \filter n$ is monotonous.
Suppose that $(t_i)_{i\in\omega}$ is a chain of justified sequences. Let $u$ be a finite prefix of $(\bigvee t_i) \filter n$.
Then $u = s \filter n$ for some finite prefix $s$ of $\bigvee t_i$. Since $s$ is finite we must have $s \prefixof t_j$ for some $j\in\omega$.
Therefore $u \prefixof t_j \filter n \prefixof \bigvee (t_j \filter  n)$.
This is valid for every finite prefix $u$ of $(\bigvee t_i) \filter n$ thus $(\bigvee t_i) \filter  n \prefixof \bigvee (t_j \filter n)$.
\end{proof}


The nodes occurrences that do not have pointers in a justified
sequence are called \defname{initial occurrences}. An initial
occurrence is either the root of the computation tree,
an @-node or a $\Sigma$-node. Let $n$ be occurrence in a justified
sequence of nodes $t$. The subsequence of $t$ consisting of occurrences that are hereditarily justified by the same \emph{initial occurrence} as $n$ is called \defname[thread!in a traversal]{thread} of $n$. Thus each thread in a traversal contains a single initial occurrence. The thread of $n$ is given by $n \filter i$ where $i$ is the first node in $t$ hereditarily justifying $n$; $i$ is
called the \defname{initial occurrence of the thread of $n$}.

\subsubsection{Views}
The notion of \index{view!P-view}\defname{P-view} $\pview{t}$ of a justified sequence
of nodes $t$ is defined the same way as the P-view of a justified
sequences of moves in Game Semantics:

\begin{definition}[P-view of justified sequence of nodes]
The P-view of a justified sequence of nodes $t$ of $\tau(M)$, written $\pview{t}$, is defined as follows:
$$\begin{array}{rcll}
 \pview{\epsilon} &=&  \epsilon \\
 \pview{s \cdot n }  &=&  \pview{s} \cdot n
    & \mbox{if $n$ is a P-node\enspace ;}
    \\
 \pview{\Pstr[10pt]{ s \cdot (m){m} \cdot \ldots \cdot (lmd-m,25){n}}} &=&
        \Pstr{ \pview{s} \cdot (m2){m} \cdot (lmd2-m2,60){n} }
    & \mbox{if $n$ is an O-node\enspace ;}
    \\
 \pview{s \cdot \theroot }  &=&  \theroot \enspace .
\end{array}$$
The equalities in the definition determine pointers implicitly. For
instance in the second clause, if in the left-hand side, $n$ points
to some node in $s$  that is also present in $\pview{s}$ then in the
right-hand side, $n$ points to that occurrence of the node in
$\pview{s}$.
\end{definition}

The O-view of $s$, written $\oview{s}$, is defined dually.
\begin{definition}[O-view of justified sequence of nodes]
\label{dfn:oview} The O-view of a justified sequence of nodes $t$ of
$\tau(M)$, written $\oview{t}$, is defined as follows:
$$\begin{array}{rcll}
 \oview{\epsilon} &=&  \epsilon \\
 \oview{s \cdot n }  &=&  \oview{s} \cdot n
    & \mbox{if $n$ is an O-node \enspace ;}
    \\
 \oview{\Pstr[10pt]{s \cdot (m){m} \cdot \ldots \cdot (x-m,30){n}}} &=&
    \Pstr{ \oview{s} \cdot (m2){m} \cdot (n2-m2,60){n} }
    & \mbox{if $n$ is a non-initial P-node \enspace ;}
    \\
 \oview{s \cdot n }  &=&  n
    & \mbox{if $n$ is an initial P-node \enspace .}
\end{array}$$
\end{definition}


We borrow some terminology from game semantics:
\begin{definition} Let $s$ be a justified sequence of nodes. We list the following axioms:
\begin{itemize}[-]
\item \defname{Alternation} for every pair of consecutive nodes in $s$, one is a P-node and the other is an O-node;
\item \defname[visibility]{P-visibility} for every occurrence in $s$
of a non-initial P-node, its justifier occurs in the P-view at that point;
\item  \defname[visibility]{O-visibility} for every occurrence in $s$
of a non-initial O-node, its justifier occurs in the O-view at that point;
\end{itemize}
\end{definition}

We then have the same basic property as in game semantics:
%\begin{property}
The P-view (resp.\ O-view) of a justified sequence satisfying P-visibility (resp.\ O-visibility)
is a well-formed justified sequence satisfying P-visibility (resp.\ P-visibility).
%\end{property}
(This property follows by an easy induction.)


\subsection{Traversal of the computation tree}
\label{subsec:traversal}

We now define the notion of \emph{traversal} over the computation tree $\tau(M)$.  We first consider the simply-typed lambda calculus without interpreted constants; everything remains valid in the presence of \emph{uninterpreted} constants as we can just consider them as free variables. In the next section, we extend the notion of traversal to a more general setting with interpreted constants.

\subsubsection{Traversals for simply-typed \texorpdfstring{$\lambda$}{lambda}-terms}

Informally, a traversal is a justified sequence of nodes of the computation tree where each node indicates a step that is taken during the evaluation of the term.

\input{traversal_rules_def.texi}

\begin{example}
\label{examp:trav} The following justified sequence is a traversal
of the computation tree from Example \ref{examp:comptree}:
$$\Pstr[1.3cm]{ t= (n0){\lambda f z}
        \cdot (n1){@}
        \cdot (n2-n1){\lambda u v}
        \cdot (n3-n2){u}
        \cdot (n4-n1){\lambda y}
        \cdot (n5-n0){f}
        \cdot (n6-n5){\lambda }
        \cdot (n7-n4){y}
        \cdot (n8-n3){\lambda }
        \cdot (n9-n2){v}
        \cdot (n10-n1){\lambda }
        \cdot (n11-n0){z} \enspace .
}$$
\end{example}


\begin{remark} \hfill
\label{rem:traversal_rules}
\begin{enumerate}
\item
    The rule \rulenamet{Value} from Table \ref{tab:trav_rules}
    can be equivalently reformulated into four distinct rules
    \rulenamet{Value^{\lambda\mapsto @}},
    \rulenamet{Value^{@\mapsto\lambda}},
    \rulenamet{Value^{\lambda\mapsto{\sf var}}} and
    \rulenamet{Value^{{\sf var}\mapsto\lambda}}, each one
    dealing with a different possible category for the nodes $n$
    and $m$:
    \begin{description}
    \item[\rulenamet{Value^{\lambda\mapsto @}}]
      If \Pstr{t \cdot (app){@} \cdot (lz-app,60:0){\lambda
    \overline{z}}  \ldots  (lzv-lz,60:v){v}_{\lambda \overline{z}} }
    is a traversal then so is \Pstr[0.5cm]{t \cdot (app){@} \cdot
    (lz-app,60){\lambda \overline{z}} \ldots
    (lzv-lz,60:v){v}_{\lambda \overline{z}} \cdot
    (appv-app,45:v){v}_@}.

    \item[\rulenamet{Value^{@\mapsto\lambda}}] If \Pstr[0.4cm]{t \cdot \lambda \overline{\xi} \cdot (x){@}  \ldots   (xv-x,50:v){v_@}}
    is a traversal then so is \Pstr[0.5cm]{t \cdot (lmd){\lambda
    \overline{\xi}} \cdot (x){@}  \ldots  (xv-x,50:v){v}_@  \cdot
    (lmdv-lmd,33:v){v}_{\lambda \overline{\xi}} }.

    \item[\rulenamet{Value^{\lambda\mapsto{\sf var}}}] If \Pstr[0.4cm]{t \cdot y \cdot (lmd){\lambda \overline{\xi}}
    \ldots (lmdv-lmd,50:v){v_{\lambda\overline\xi}} } is a
    traversal with $y\in \INodes_{\sf var}^{@\enable}$ then so is
    \Pstr[0.5cm]{t \cdot (y){y} \cdot (lmd){\lambda \overline{\xi}}
    \ldots (lmdv-lmd,30:v){v}_{\lambda \overline{\xi}}  \cdot
    (vy-y,50:v){v}_y }.

    \item[\rulenamet{Value^{var\mapsto\lambda}}] If \Pstr[0.4cm]{t \cdot \lambda \overline{\xi} \cdot (x){x}  \ldots   (xv-x,50:v){v}_x}
    is a traversal where $x\in \INodes_{\sf var}$ then so is
    \Pstr[0.5cm]{t \cdot (lmd){\lambda \overline{\xi}} \cdot (x){x}
    \ldots  (xv-x,50:v){v}_x  \cdot (lmdv-lmd,30:v){v}_{\lambda
    \overline{\xi}} }.
    \end{description}
    In the rest of this chapter we will prove various resulting
    by induction on the structure of a traversal and by case
    analysis on the last rule used to form it. Some of
    these proofs will rely on the above-defined reformulation of
    \rulenamet{Value} instead of its original definition.

    \item In the rule \rulenamet{InputValue}, the last node in the traversal $t_1 \cdot x \cdot t_2$ necessarily belongs to $\INodes_{\sf var} \union \LNodes_\lambda$. Indeed, since the pending node $x$ is a variable node, the traversal is of the form
$$\Pstr[0.5cm]{\ldots \cdot x \cdot  (l){\lambda \overline{\eta}_1}\ldots (v-l){v^1_{\lambda \overline{\eta}_1}}
(l2){\lambda \overline{\eta}_2}\ldots (v2-l2){v^2_{\lambda \overline{\eta}_2}}
\ldots (lk){\lambda \overline{\eta}_k}\ldots (vk-lk){v^k_{\lambda \overline{\eta}_k}}
}$$ for some nodes $\lambda \overline{\eta}_k$, values $v^k \in \mathcal{D}$ and $k\geq 0$; thus the last occurrence belongs to $\INodes_{\sf var}$ if $k=0$ and to $\LNodes_\lambda$ if $k\geq1$.

    Furthermore, the pending node appears necessarily in the O-view.

    These two observations show that the rule \rulenamet{InputValue} is essentially a specialization of \rulenamet{InputVar} to value-leaves. The only difference is that \rulenamet{InputVar}
    allows the visited node to be justified by \emph{any} variable node occurring in the O-view whereas \rulenamet{InputValue} constrains the node
    to be justified by the pending node (which necessarily occurs in the O-view). This restriction is here to ensure that traversals are well-bracketed.

\item In the rule
\rulenamet{Value}, it is possible to replace the condition ``$n\in \INodes$'' by the stronger ``$n\in \INodes\setminus \INodes_{\sf \lambda}^{\theroot\enable}$''. Indeed a later result (Lemma \ref{lem:trav_oview_single_threaded}) will show that if $n$ belongs to $\INodes_{\lambda}^{\theroot\enable}$ then the preceding occurrence $m$ is necessarily an input-variable.
Furthermore, another result (Prop.~\ref{prop:pviewtrav_is_path}) shows that traversals are well-bracketed, therefore $m$ is necessarily the pending node. Hence the rule \rulenamet{InputValue} can be use in place of
\rulenamet{Value} to visit $v_m$.


The advantage of this alternative formulation is that the traversal rules have disjoint domains of definition.
\end{enumerate}
\end{remark}
\bigskip

A traversal always starts with the root node and mainly follows the
structure of the tree. The exception is the \rulenamet{Var} rule
which permits the traversal to jump across the computation tree. The
idea is that after visiting a non-input variable node $x$, a jump
can be made to the node corresponding to the subterm that would be
substituted for $x$ if all the $\beta$-redexes occurring in the term
were to be reduced. Let $\lambda \overline{x}$ be $x$'s binder and
suppose $x$ is the $i^{th}$ variable in $\overline{x}$. The binding
node necessarily occurs previously in the traversal (This will be
proved in Prop.~\ref{prop:pviewtrav_is_path}). Since $x$ is not
hereditarily justified by the root, $\lambda \overline{x}$ is not
the root of the tree and therefore it is not the first node of the
traversal. We do a case analysis on the node preceding $\lambda
\overline{x}$:
    \begin{itemize}
    \item If it is an @-node then $\lambda \overline{x}$ is necessarily the first child node of that node
    and it has exactly $|\overline{x}|$ siblings:
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=6ex,sibling distance=17mm,
level 2/.style={level distance=10ex},
level 3/.style={level distance=6ex}]
\node(root){}
child[dotted]{
    node[anchor=south]{$@$}
    child[solid] {node {$\lambda\overline x$}
        child[dotted,level distance=8ex]{node{$x$}}
        edge from parent node[fill=white]{$0$}
        }
    child[solid] {node {$\lambda\overline\eta_1$}
        child[dotted] {node{}}
        edge from parent node[fill=white]{$1$}
        }
    child[dotted]{node{}}
    child[solid] {node {$\lambda\overline\eta_i$}
        child[dotted]{node{}}
        edge from parent node[fill=white]{$i$}
        }
    child[dotted]{node{}}
    child[solid] {node {$\lambda\overline\eta_{|x|}$}
        child[dotted]{node{}}
        edge from parent node[fill=white]{$|x|$}
        }
};
\end{tikzpicture}
\end{center}

    In that case, the next step of the traversal is a jump to $\lambda \overline{\eta_i}$---the $i^{th}$ child of
    @---which corresponds to the subterm that would be substituted for $x$ if the $\beta$-reduction was
    performed:
    $$\Pstr[19pt]{ t' \cdot
            (n){@} \cdot
            (lx){\lambda \overline{x}} \cdot \ldots \cdot
            (x-lx,40:i){x} \cdot
            (mi-n,40:i){\lambda \overline{\eta_i}} \cdot \ldots
            \in {\travset(M)}   } \enspace .
    $$

    \item If it is a variable node $y$, then
    the node $\lambda \overline{x}$ was necessarily added to the traversal $t_{\leq y}$ using the \rulenamet{Var} rule.
    (Indeed, if it was visited using \rulenamet{InputVar} then $\lambda \overline{x}$ would be hereditarily justified by the root, but this is not possible since $x_i$, bound by $\lambda \overline{x}$, is not an input-variable.)
    Therefore $y$ is substituted by the term rooted at $\lambda \overline{x}$ during the evaluation of the term.

    Consequently, during reduction, the variable $x$ will be substituted by the subterm represented by
    the $i^{th}$ child node of $y$. Hence the following justified sequence is also a traversal:
    $$\Pstr[18pt]{ t' \cdot
            (y){y} \cdot
            (lx){\lambda \overline{x}} \cdot \ldots \cdot
            (x-lx,40:i){x} \cdot
            (mi-y,40:i){\lambda \overline{\eta_i}} \cdot \ldots
    }
    $$
    \end{itemize}

\begin{remark}
Our notions of computation tree and traversal differ slightly from the original definitions by Ong \cite{OngLics2006}.
In his setting:
\begin{itemize}[-]
    \item computation trees contain (uninterpreted first-order) constants. Here we have not accounted for constants but as previously observed, uninterpreted constants can just be regarded as free variables, thus we do not lose any expressivity here.

    \item constants are restricted to order one at most. (Terms are used as generators
        of trees where first-order constants act as tree-node constructors). Here we do not need this restriction: as long as constants are uninterpreted we can regard them as free variables, even at higher-orders.

    \item one rule (\rulenamet{Sig}) suffices to model the first-order constants. In contrast our setting
    accounts for higher-order variables, thus the more complicated rules \rulenamet{InputValue} and \rulenamet{InputVar} are required.

    \item computation trees do not have value-leaves. These are not necessary to model the pure simply-typed lambda calculus. There will be necessary, however, when it comes to model interpreted constants such as those of \pcf\ or \ialgol.
    \end{itemize}
\end{remark}

\begin{example}
Consider the following computation tree:
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,inner ysep=0.5mm,sibling distance=12mm,
level 2/.style={sibling distance=40mm,level distance=5ex},
level 3/.style={sibling distance=10mm,level distance=7ex},
level 4/.style={sibling distance=10mm,level distance=6ex}]
\node (root) {$\lambda$}
child {
    node {$@$}
    child {
        node {$\lambda y$}
        child[dotted] {node {$y$}
           child{node {$\lambda\overline\eta_1$}
               child{node{}}
               edge from parent node[fill=white] {$1$}
           }
           child{node{}}
           child{node{$\lambda\overline\eta_i$}
             child{node{}}
             edge from parent node[fill=white] {$i$}
           }
           child{node{}}
           child{node{$\lambda\overline\eta_n$}
             child{node{}}
             edge from parent node[fill=white] {$n$}
           }
        }
        edge from parent node[fill=white] {$0$}
    }
    child {node{$\lambda\overline{x}$}
        child[dotted] {node{$x_i$}
           child{node{}}
           child{node{}}
        }
        edge from parent node[fill=white]{$1$}
    }
};
\end{tikzpicture}
\end{center}
An example of traversal of this tree is:
\vspace{0.3cm}
$$ \Pstr{ \lambda \cdot
            (app){@}  \cdot
            (ly){\lambda y} \cdot \ldots \cdot
            (y-ly,40:1){y} \cdot
            (lx-app,50:1){\lambda \overline{x}} \cdot \ldots \cdot
            (x-lx,40:i){x_i} \cdot
            (leta-y,50:i){\lambda \overline{\eta_i} } \cdot \ldots
        }$$
\end{example}



\begin{lemma}
\label{lem:jump_in_thread}
Take a traversal $t$ ending with an inner node hereditarily justified by an application node @. Then if we represent only the nodes appearing in the O-view, the thread of $t^\omega$ has the following shape:
$$ \Pstr[0.5cm]{ (app){@}\cdot
(l0-app){\lambda \overline{\xi}_0} \ldots (x1-l0){x_1} \cdot
(l1-app){\lambda \overline{\xi}_1} \ldots (x2-l1){x_2} \cdot
(l2-x1){\lambda \overline{\xi}_2} \ldots (x3-l2){x_3} \cdot
(l3-x2){\lambda \overline{\xi}_3} \ldots (x4-l3){x_4} \ldots
(xkm1){x_{k-1}}
(lkm1){\lambda \overline{\xi}_{k-1}} \ldots (xk-lkm1){x_k}
(lk-xkm1){\lambda \overline{\xi}_k} \enspace .
 } $$
Suppose that the initial node $@$ occurs in the computation as follows:
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=6ex,inner ysep=0.5mm,sibling distance=15mm]
\node (root) {$\ldots$}
child {node {$@$}
    child{node {$\lambda\overline\eta_1$}
          child[dotted]{node{}}}
    child{node{$\ldots$}}
    child{node {$\lambda\overline\eta_q$}
          child[dotted]{node{}}}};
\end{tikzpicture}
\end{center}
Let $\tau_i$ denote the sub-tree rooted at $\lambda \overline{\eta}_i$ for $i\in \{1.. q\}$.
Then for every $j\in \{1.. k\}$, $x_j$ and $\lambda \overline{\xi}_j$ must belong to two different subtrees $\tau_i$ and $\tau_{i'}$. Furthermore, $x_j$ is hereditarily justified by
some occurrence of $\lambda \overline{\eta}_i$ in $t$ and
$\lambda \overline{\xi}_j$ is hereditarily justified by
some occurrence of $\lambda \overline{\eta}_{i'}$ in $t$
(and therefore $\lambda \overline{\xi}_j \in \Nodes^{\lambda \overline{\eta}_{i} \enable}$
and $x_j \in \Nodes^{\lambda \overline{\eta}_{i'} \enable}$).
\end{lemma}
\begin{proof} The proof is by an easy induction. \end{proof}


\subsubsection{Traversal rules for interpreted constants}

The framework that we have established up to now aims at providing
a computation model of simply-typed lambda-terms. It is
possible to extend it to other extensions of the simply-typed lambda calculus. This is done by completing the traversal rules from Table \ref{tab:trav_rules}
with new rules describing the behaviour of the interpreted constants
of the language considered. For instance in the case of \pcf, we
need to define rules for the interpreted constant $\pcfcond$ that
replicate the behaviour of the conditional operation. (In a
forthcoming section of this chapter we will give a complete
definition of the constant traversal rules for \pcf\ and \ialgol.)

We mentioned before that uninterpreted constants can be regarded as
free variables. In the same way, we can consider interpreted
constants as a \emph{generalization} of free variables: for both of
them, the ``code'' describing their computational behaviour is not
defined within the scope of the term, it is instead assumed that the
environment knows how to interpret them. Free variables, however,
are more restricted than interpreted constants: When evaluating
an applicative term with a free variable in head position, the
evaluation of the head variable does not depend on the result of the
evaluation of its parameters; whereas for applicative term with an
interpreted constant in head position, the outcome of the evaluation may depend on the result of the evaluation of its parameters (\eg, the
\pcf\ constant $\pcfcond$ branches between two control points depending on the result of the evaluation of its first parameter).

We can thus derive a prototype for constant traversal rules by generalizing the input-variable rules \rulenamet{InputValue} and \rulenamet{InputVar}:
\begin{definition}[Constant traversal rule]
    \label{def:constant_traversal} A \defname{constant traversal} has
    one of the following two forms:
        $$\rulename{\Sigma\mbox{-Value}}\ \rulef{t = t_1\cdot \alpha \cdot t_2 \in \travset(M) \quad \alpha \in \INodes_\Sigma \union \INodes^{\INodes_\Sigma\enable}_{\sf var} \quad ?(t)^\omega = \alpha \quad P(t)}
          {
            \stackrel{\rule{0pt}{3pt} }{
                \Pstr[8pt]{ t' = t_1\cdot (alpha){\alpha} \cdot t_2 \cdot (v-alpha,35){v(t)} \in {\travset(M)}}
                }
           }
           $$
    or
    $$\rulename{\Sigma}/\rulename{\Sigma\mbox{-Var}}\ \rulef{t \in \travset(M) \quad t^\omega\in \INodes_\Sigma \union \INodes^{\INodes_\Sigma\enable}\union \LNodes_\lambda \quad P(t)}
      { \stackrel{  \rule{0pt}{3pt} }{\Pstr[5pt]{ t \cdot {n(t)} \in {\travset(M)}}}
       }$$
        where:
        \begin{compactitem}
          \item $P(t)$ is a predicate expressing some condition on $t$;
          \item $v(t)$ is a value-leaf of the node $\alpha$ that is determined by the traversal $t$;
          \item $n(t)$ is a lambda-node determined by $t$, and its link---also determined by $t$---points to some occurrence of its parent node in $\oview{t}$.
        \end{compactitem}
    Clearly, such rules preserve well-bracketing, alternation and visibility.
\end{definition}

\begin{remark}
The extra power of the constant rules over the input-variable rules
\rulenamet{InputValue} and \rulenamet{InputVar} comes from their
ability to base their choice of next visited node on
the shape of the traversal $t$.
\end{remark}

From now on, to make our argument as general as possible, we
consider a simply-typed lambda calculus language extended with
higher-order interpreted constants for which some constant traversal
rules have been defined (in the sense of Def.
\ref{def:constant_traversal}). Furthermore, we complete the set of
rules with the following additional copy-cat rule:
$$\rulename{Value^{\Sigma\mapsto\lambda}}\ \Pstr[0.4cm]{t \cdot
\lambda \overline{\xi} \cdot (x){c}  \ldots   (xv-x,50:v){v}_c} \in \travset(M) \zand\  c\in\Sigma \ \implies\ \Pstr[0.5cm]{t \cdot
(lmd){\lambda \overline{\xi}} \cdot (x){c}  \ldots  (xv-x,50:v){v}_c
\cdot (lmdv-lmd,33:v){v}_{\lambda \overline{\xi}}} \in \travset(M) \enspace .$$

\begin{definition}
\label{def:wellbehaved_traversal} A constant traversal rules is
    \defname{well-behaved} if
    for every traversal  \Pstr[0.5cm]{ t \cdot (a){\alpha} \cdot u \cdot (n-a,35){n}} formed with the rule
    we have $?(u) = \epsilon$.
\end{definition}

An example is the rule $\rulename{\Sigma\mbox{-Value}}$ which is
well-behaved due to the fact that traversals are  well-bracketed.
The rule $\rulename{\Sigma}/\rulename{\Sigma\mbox{-Var}}$, however, is not well-behaved
since the node $n(t)$ does not necessarily points to the pending node in $t$.

\begin{lemma}
\label{lem:sigma_order1_are_wellbehaved} If $\Sigma$-constants have
order $1$ at most, then constant rules are necessarily all
well-behaved.
\end{lemma}
\begin{proof} In the computation tree, an order-$1$ constant hereditarily
enables only its immediate children (which are all dummy lambda
nodes $\lambda$). Hence a traversal formed with the rule
$\rulename{\Sigma}/\rulename{\Sigma\mbox{-Var}}$ is of the form:
$$\Pstr[0.5cm]{ t = \ldots \cdot (a){\alpha} \cdot u \cdot
 (n-a,35){\lambda}}$$
where $\alpha$ appears in $\oview{t}$.

If $u=\epsilon$  then the result trivially holds. Otherwise, $u$'s
first node has necessarily been visited with the rule
$\rulename{\Sigma}/\rulename{\Sigma\mbox{-Var}}$ thus $u$'s first
node is a dummy lambda node $\lambda'$ pointing to $\alpha$. Since
$\alpha$ occurs in $\oview{t}$ and since the node $\lambda'$ enables
only its value-leaf in the computation tree, $t$ must be of the
following shape:

\begin{center}
\pstr[0.5cm]{
\ifLoadPGFengine
\nd {t = \ldots \cdot} (a){\alpha}
\nd \cdot (lp-a,35){\lambda'}
\nd \ldots (v-lp){v_{\lambda'}}
\nd(d) \ldots
\nd(l-a,35){\lambda}
\pstrPGFbrace{lp}{d}{5pt}{$u$}
\else
\nd {t = \ldots \cdot} (a){\alpha}
\txt{\cdot
\underbrace{
        \nd (lp-a,35){\lambda'}
        \nd \ldots (v-lp){v_{\lambda'}}
        \txt \ldots
    }_{u}
}
\nd(l-a,35){\lambda}
\fi
}
\end{center}
for some value leaf $v_{\lambda'}$ of $\lambda'$.

Again, the node following $v_{\lambda'}$ must be a dummy lambda node
pointing to $\alpha$. By iterating the same argument we obtain that
the segment $u$ is a repetition of segments of the form
\Pstr[0.5cm]{(lp){\lambda'} \cdot  \ldots (v-lp){v_{\lambda'}}}.
Hence $?(u)=\epsilon$.
\end{proof}


\subsubsection{Property of traversals}

\begin{proposition}
\label{prop:pviewtrav_is_path}
Let $t$ be a traversal. Then:
\begin{enumerate}[(i)]
\item $t$ is a well-defined justified sequence satisfying alternation, well-bracketing, P-visibility and O-visibility;
\item If the last element of $t$ is not a value-leaf whose parent-node is a lambda node (\ie, $t^\omega \not\in \LNodes_\lambda$) then $\pview{t}$ is the path in the computation tree going from the root to the node $t^\omega$.
\end{enumerate}
\end{proposition}
\begin{proof}
This is the counterpart of another result proved by Ong in the paper where he introduces the theory of traversals
\cite[proposition 6]{OngHoMchecking2006}. The original proof---an induction on the traversal rules---can be adapted to take into
account the constant rules and the presence of value-leaves in the traversal.
We detail the case \rulenamet{Lam} only. We need to show that $n$'s binder occurs only once in the P-view at that point. By the induction hypothesis (ii) we have that $\pview{t \cdot \lambda \overline{\xi}}$ is a path in the computation tree from the root to $\lambda \overline{\xi}$. But $n$'s binder occurs only once in this path, therefore the traversal $t \cdot \lambda \overline{\xi} \cdot n$ is well-defined and satisfies P-visibility. Thus (i) is satisfied. Furthermore $n$ is a child of $\lambda \overline{\xi}$ therefore (ii) also holds.
\end{proof}

%In particular to prove that the copy-cat rules are well-defined, one needs to ensure that
%if the last two unanswered nodes are $y$ and $\lambda \overline{\xi}$ in that order, for some non input-variable node $y$ then necessary
%      $y$ and $\lambda \overline{\xi}$ are consecutive nodes in the traversal.
%    This is because in a traversal, a non input-variable $y$ is always followed by a lambda node and whenever this lambda node is answered
%    there is only one way to extend the traversal: using the copycat rule to answer to the $y$ node.


\begin{lemma}
\label{lem:trav_last_not_leaf} If $t \cdot n $ is a traversal with
$n \in \INodes_{\sf var} \union \INodes_\Sigma \union \INodes_@$ then $t\neq\epsilon$ and $t^\omega$ is $n$'s parent in $\tau(M)$ (and is thus a lambda node).
\end{lemma}
\begin{proof}
By inspecting the traversal rules, we observe that \rulenamet{Lam}
is the only rule  which can visit a node in $\INodes_{\sf var} \union
\INodes_\Sigma \union \INodes_@$. Hence $t$ is not empty and $t^\omega$ is $n$'s parent in $\tau(M)$.
\end{proof}


\begin{lemma}
\label{lem:betanorm_enabling}
Suppose that $M$ is $\beta$-normal. Let $t$ be a traversal of $\tau(M)$
and $n$ be a node occurring in $t$. Then the root $\theroot$ does not hereditarily enable $n$ if and only if $n$ is hereditarily enabled by some node in $\INodes_\Sigma$. Formally:
$$ n \not\in \INodes^{\theroot\enable} \quad \iff \quad n \in \INodes^{\INodes_{\Sigma}\enable} \enspace .$$
\end{lemma}
\begin{proof}
 In a computation tree, the only nodes that do not have justification pointer are:
the root $\theroot$, @-nodes and $\Sigma$-constant nodes. But since $M$ is
in $\beta$-normal form, there is no @-node in the computation tree.
Hence nodes are either hereditarily enabled by $\theroot$ or hereditarily
enabled by some node in $\INodes_\Sigma$. Moreover $\theroot$ is not in $\INodes_\Sigma$
therefore the ``or'' is exclusive: a node cannot be both hereditarily
enabled by $\theroot$ and by some node in $\INodes_\Sigma$.
\end{proof}


\begin{lemma}[The O-view is contained in a single thread]
\label{lem:trav_oview_single_threaded}
Let $t \in \travset(M)$.
\begin{itemize}
\item[(a)] If $t= \ldots \cdot m \cdot n$ where
$m$ is a P-node and $n$ is an O-node then
$m$ and $n$ are in the same thread in $t$: they are hereditarily justified by the same initial occurrence (which is either $\tau(M)$'s root, a $\Sigma$-constant or an @-node);

\item[(b)] All the nodes in $\oview{t}$ belong to the same thread.
\end{itemize}
\end{lemma}
\begin{proof}
Clearly (b) follows immediately from (a) due to the way the O-view is computed. We show (a) by induction on the last traversal rule used to form $t$. The results trivially hold for the base cases \rulenamet{Empty} and \rulenamet{Root}.
Step case: Take $t = t' \cdot n$. If $n \in \INodes_\lambda\union \LNodes_{\sf var} \union \LNodes_\Sigma \union \LNodes_@$ then we do not need to show (a).
Otherwise $n$ is an O-node. By O-visibility it points in $\oview{t'}$, thus by the I.H., it must belong to the same thread as all the nodes in $\oview{t'}$ and in particular to the thread of $t'^\omega$. Therefore both (i) and (ii) hold.
\end{proof}


\subsubsection{Traversal core}



Occurrences of input-variable nodes correspond to point of the computation at which the term interacts with its context.
At these points, a traversal can be extended in a non-deterministic way. In contrast, after a node that is hereditarily enabled by an @-node or by a constant node, the next visited node is uniquely determined. We can therefore think of such nodes as being ``internal'' to the computation: their semantics is predefined and cannot be altered by the context in which the term appears. If we want to extract the essence of the computation from a traversal, a natural way to proceed thus consists in keeping only occurrences of nodes that are hereditarily enabled by the root:
\begin{definition}
The \defname{core of a traversal} $t$, written $t\filter \theroot$, is defined as $t\filter \Nodes^{\theroot \enable}$ (\ie, the subsequence of $t$ consisting of the occurrences of nodes that are hereditarily enabled by the root $\theroot$ of the computation tree). The set of traversal cores of $M$ is denoted by $\travset(M)^{\filter \theroot}$:
$$\travset(M)^{\filter \theroot} \defeq \{ t \filter \theroot \ :\  t  \in \travset(M) \} \enspace . $$
\end{definition}

\begin{example}
The core of the traversal given in example \ref{examp:trav} is:
$$ \Pstr[0.7cm]{t \filter \lambda f z = (n0){\lambda f z} \cdot (n1-n0){f}\cdot (n2-n1){\lambda }\cdot (n3-n0){z} } \enspace .$$
\end{example}


\begin{remark}\hfill
  \begin{itemize}
    \item The root occurs at most once in a traversal, therefore if $t$ is a non-empty traversal then its core is given by $t\filter r$ where $r$ denotes the only occurrence of $\theroot$ in $t$. Thus we have:
        $$\travset(M)^{\filter \theroot} = \{ t \filter r\ :\  t  \in \travset(M) \hbox{ and $r$ is the only occurrence of $\theroot$ in $t$}\} \enspace . $$

    \item Since @-nodes and $\Sigma$-constants do not have pointers, the traversal cores contains only nodes in $\Nodes_\lambda \union \Nodes_{\sf var}$.
\end{itemize}
\end{remark}


\subsubsection{Removing @-nodes and \texorpdfstring{$\Sigma$}{constant}-nodes from traversals}
\label{subsec:tstar}


Application nodes are essential in the definition of computation trees: they are necessary to connect together the operator and operands of an application. They also have another advantage: they ensure that the lambda-nodes are all at even level in the computation tree, which subsequently guarantees that traversals respect a
certain form of alternation between lambda nodes and non-lambda
nodes. Application nodes are however redundant in the sense that
they do not play any role in the computation of the term. In fact it
will be necessary to filter them out in order to establish the
correspondence with interaction game semantics.

\begin{definition}[@-free traversal]
\label{dfn:appnode_filter} Let $t$ be a traversal of $\tau(M)$. We
write $t-@$ for the sequence of nodes-with-pointers obtained by
\begin{itemize}
\item removing from $t$ all occurrences of @-nodes and their children value-leaves;
\item replacing any link pointing to an @-node by a link pointing to the immediate predecessor of @ in $t$.
\end{itemize}


Suppose $u = t-@$ is a sequence of nodes obtained by applying the
previously defined transformation on the traversal $t$, then $t$ can
be partially recovered from $u$ by reinserting the @-nodes as
follows. For each @-node in the computation tree with parent node
denoted by $p$, we perform the following operations:
\begin{enumerate}
\item replace every occurrence of the pattern $p \cdot n$ for some $\lambda$-node $n$, by $p \cdot @ \cdot n$;
\item replace any link in $u$ starting from a $\lambda$-node and pointing to $p$ by a link pointing to the inserted @-node;
\item for each occurrence in $u$ of a value-leaf $v_p$ pointing to $p$, insert the value-leaf $v_@$
    immediately before $v_p$ and make it point to the
    immediate successor of $p$ (which is precisely the $@$-node
inserted in step 1.).
\end{enumerate}
We write $u+@$ for this second transformation.
\end{definition}
These transformations are well-defined because in a traversal, an
@-node is always immediately preceded by its parent node $n_1$, and immediately followed by
its first child $n_2$:
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,sibling distance=12mm,level 2/.style={sibling distance=8mm}]
\path node (root) {$n_1$}
child{node {$@$}
    child{node {$n_2$} child[dotted]{node{}}}
    child[dotted]{node{}}
    child[dotted]{node{}}};
\end{tikzpicture}
\end{center}
\begin{example} Let $f$ be a $\Sigma$-constant
and $t = \Pstr[0.4cm]{ (l){\lambda \overline{\xi}} \cdot (at)@ \cdot (lx-at){\lambda x}\cdot (f)f \cdot (l-f){\lambda} \cdot (x-lx,60)x}$. Then
$$t-@ = \Pstr[0.5cm]{ (l){\lambda \overline{\xi}}
 \cdot (lx-l){\lambda x}\cdot (f)f\cdot (l2-f){\lambda} \cdot (x-lx)x} \enspace .$$
\end{example}

\begin{example}
Let $t$ be the traversal given in example \ref{examp:trav}, we have:
  $$\Pstr[1.3cm]{ t - @ = (n0){\lambda f z}\cdot (n1-n0){\lambda u v}\cdot (n2-n1){u}\cdot (n3-n0){\lambda y}\ (n4-n0){f}\cdot (n5-n4){\lambda }\cdot (n6-n3){y}\cdot (n7-n2){\lambda }\cdot (n8-n1){v}\cdot (n9-n0){\lambda }\cdot (n10-n0){z}} \enspace .$$
\end{example}


We also want to remove $\Sigma$-nodes from the traversals. To that end we define the operation $-\Sigma$ and $+\Sigma$ in the exact same way as $-@$ and $+@$. Again these transformations are well-defined since in a traversal, a $\Sigma$-node $f$ is always immediately preceded by its parent node $p$, and a value-node $v_p$ is always immediately preceded by a value-node $v_f$.

Note that the operations $-@$ and $-\Sigma$ are commutative:
$(t-@)-\Sigma = (t-\Sigma)-@$.

\begin{lemma} \label{lem:minus_at_plus_at}
For every non-empty traversal $t = t' \cdot t^\omega$ in $\travset(M)$:
\begin{align*}
(t-@)+@ = \left\{
            \begin{array}{ll}
              t, & \hbox{if $t^\omega \not\in \Nodes_@$\ ;} \\
              t', & \hbox{if $t^\omega \in \Nodes_@$\ ;}
            \end{array}
          \right.
\\
(t-\Sigma)+\Sigma = \left\{
            \begin{array}{ll}
              t, & \hbox{if $t^\omega \not\in \Nodes_\Sigma$\ ;} \\
              t', & \hbox{if $t^\omega \in \Nodes_\Sigma$\enspace .}
            \end{array}
          \right.
\end{align*}
\end{lemma}
\begin{proof} The result follows immediately from the definition of the
operation -@ and +@ (resp.\ $-\Sigma$ and $+\Sigma$ ). \end{proof}

\begin{remark}
Sequences of the form $t-@$ (resp.\ $t-\Sigma$) are not, strictly
speaking, proper justified sequences of nodes since after removing
@-nodes, all the prime $\lambda$-nodes become justified by their
parent's parent which are also $\lambda$-nodes!  Moreover, these
sequences do not respect alternation since two $\lambda$-nodes may
become adjacent after removing a @-node.
\end{remark}
\bigskip

We write $t^\star$ to denote the sequence obtained from $t$ by
removing all the @-nodes as well as the constant nodes together with
their associated value-leaves:
$$ t^\star \defeq t -@ - \Sigma \enspace .$$
\begin{example} Let $f$ be a $\Sigma$-constant. We have
$$\left(\Pstr[0.4cm]{ (l){\lambda \overline{\xi}} \cdot (at)@ \cdot
(lx-at){\lambda x}\cdot (f)f \cdot (l-f){\lambda} \cdot (x-lx,60)x}\right)^\star = \Pstr[0.5cm]{ (l){\lambda \overline{\xi}}
 \cdot (lx-l){\lambda x}\cdot (l2-lx){\lambda} \cdot (x-lx)x} \enspace .$$
\end{example}

We introduce the set
$$\travset(M)^\star = \{ t^\star \ | \  t \in \travset(M) \} \enspace .$$

\begin{remark}
If $M$ is a $\beta$-normal term and if it contains no
$\Sigma$-constant (as for pure simply-typed terms) then
$\tau(M)$ does not contain any @-node or $\Sigma$-node, thus all
nodes are hereditarily enabled by $\theroot$ and we have $\travset(M) =
\travset(M)^{\filter \theroot} = \travset(M)^\star$.
\end{remark}

\begin{lemma}
\label{lem:he_proj_root_is_hj_proj_r} For every traversal
$t$ we have  $t^\star\filter \Nodes^{\theroot\enable} = t\filter \theroot$.
\end{lemma}
\begin{proof}
 This is because nodes removed by the operation $\_^\star$ are not hereditarily enabled by the root of the tree.
\end{proof}


The notion of P-view extends naturally to sequences of the form $t^\star$: it is defined by the same induction as for P-views of traversals. It is then easy to check
that if $t^\omega$ is not in $\LNodes_@\union \LNodes_\Sigma$ then the P-view
of $t^\star$ is obtained from $\pview{t}$ by keeping only the non
@/$\Sigma$-nodes:
\begin{equation}
 \pview{t^\star} = \pview{t} \setminus (\Nodes_@ \union \Nodes_\Sigma) \enspace . \label{eqn:pview_tstar}
\end{equation}

We define a projection operation for sequences of the form $t^\star$
as follows:
\begin{definition}
\label{def:subterm_trav_projection}
  Let $t$ be a traversal such that $t^\omega\not\in \LNodes_@\union \LNodes_\Sigma$ and $r_0$ be an occurrence of some
lambda-node $n$. Then the projection $t^\star \filter \Nodes^{(n)}$ is
defined as the subsequence of $t^\star$ consisting of nodes of
$\Nodes^{(n)}$ only. If a variable node loses its pointer in $t^\star
\filter \Nodes^{(n)}$ then its justifier is reassigned to the only
occurrence of $n$ in $\pview{t^\star}$.
\end{definition}
Note that this operation is well-defined. Indeed if a variable $x$
loses its pointer in $t^\star \filter \Nodes^{(n)}$ then it means that
$x$ is free in $M^{(n)}$. But then $n$ must occur in the path to
the root $\theroot$ which is precisely $\pview{t_{\prefixof x}}$.
Thus by (\ref{eqn:pview_tstar}), $n$ must occur in
$\pview{{t_{\prefixof x}}^\star}$.



\subsubsection{Subterm projection (with respect to a node occurrence)}
\label{sec:tstar}
Let $n_0$ be a node-occurrence in a traversal $t$.
The \defname{subterm projection} $t \filterplus n_0$ is defined as the subsequence of $t$ consisting of the occurrences whose P-view at that point contain the node $n_0$. Formally:
\begin{definition}
Let $t\in \travset(M)$ and $n_0$ be an occurrence in $t$.
The subsequence $t \filterplus n_0$ of $t$ is defined inductively on $t$ as follows:
\indexnotation{$t \filterplus n$}{Subterm projection of a traversal $t$ with respect to occurrence $n$}%
\begin{compactitem}
\item $(t \cdot n_0) \filterplus n_0 = n_0$ ;
\item If $n$ is an O-node and $n\neq n_0$ then
\begin{align*}
(t \cdot n) \filterplus n_0 &= \left\{
                                  \begin{array}{ll}
                                    (t\filterplus n_0) \cdot n, & \hbox{if $n$'s justifier appears in $t\filterplus n_0$\enspace ;} \\
                                    t\filterplus n_0, & \hbox{otherwise ;}
                                  \end{array}
                                \right.
\end{align*}

\item If $n$ is a P-node and $n\neq n_0$ then
$$
(t \cdot n) \filterplus n_0 = \left\{
                                  \begin{array}{ll}
                                    (t\filterplus n_0) \cdot n, & \hbox{if $t^\omega$'s appears in $t\filterplus n_0$\enspace ;} \\
                                    t\filterplus n_0, & \hbox{otherwise ;}
                                  \end{array}
                                \right.
$$
where in the first subcase, if $n$ loses its justifier in
$t\filterplus r_0$ then it is reassigned to $r_0$.
\end{compactitem}
\end{definition}

We call this transformation the \emph{subterm projection with respect to a node occurrence} because it keeps only nodes that appear in the sub-tree rooted at some reference node. If $n_0$ is an occurrence of a lambda node $n \in \INodes_\lambda$ then we say that $t \filterplus n_0$ a \defname{sub-traversal of the
computation tree} $\tau(M)$. This name is suggestive of the
forthcoming Proposition \ref{prop:trav_projection} stating that $t
\filterplus n_0$ is a traversal of the sub-computation tree of
$\tau(M)$ rooted at $n$.

\begin{remark}
\label{rem:tplus} There is an alternative way to define $t \filterplus r_0$: For every traversal $t$ we write $t^+$ to denote the sequence-with-pointers obtained from $t$ by adding pointers as follows: For every occurrence of a $@$ or $\Sigma$-node $m$ in $t$ we add a pointer going from $m$ to its predecessor in $t$ (which is necessarily an occurrence of its parent node). Further, for every variable node $x$ we add auxiliary pointers going to each lambda node occurring in the P-view at that point after $x$'s binder. Conversely, for every sequence-with-pointers $u$ we define $u^-$ as the sequence obtained from $u$ by removing the links associated to $@$ and $\Sigma$-nodes and where for each occurrence of a variable node, only the ``longest'' link is preserved. (The length of a link being defined as the distance between the source and the target occurrence.) Clearly the operation $\_^-$ is the inverse of $\_^+$: For every traversal $t$ we have $t= (t^+)^-$.
Then it can be easily shown that the sequence $t \filterplus n$ is
precisely the subsequence of $t$ consisting of nodes hereditarily
justified by $n$ \emph{with respect to the justification pointers of
$t^+$}:
$$t \filterplus n = (t^+ \filter n)^- \enspace .$$
(Note that since the operation $\_^+$ changes the justification pointers, the hereditary justification relation in a traversal $t$ is different from the hereditary justification relation in $t^+$ and therefore we have $(t\filter n)^+ \subseqof t^+ \filter n$ but $(t\filter n)^+ \neq t^+ \filter n$.) End of remark.
\end{remark}
\bigskip


The following lemmas follow directly from the definition of
$t\filterplus r_0$:
\begin{lemma}
\label{lem:ifin_projplus_so_does_justifier} Let $t$ be a traversal
and  $r_0$ be an occurrence of a lambda node $r'$ in $t$.
\begin{enumerate}[(a)]
  \item Suppose that \Pstr[0.5cm]{t = \ldots (m){m} \ldots (n-m){n}} with $n \in \INodes_\lambda \union \LNodes_@\union \LNodes_\Sigma \union \LNodes_{\sf var}$ and $n \neq r_0$. Then $n$ appears in $t\filterplus r_0$ if
and only if $m$ appears in $t\filterplus r_0$.

  \item Suppose that $t = \ldots \cdot n$ where $n\in \INodes_{\sf var}\union \INodes_@\union
\INodes_\Sigma\union \LNodes_\lambda$.
    Then $n$ appears in $t\filterplus r_0$ if and only if the
    last lambda node in $\pview{t}$ does.

    \item Suppose that \Pstr[0.4cm]{t = \ldots (m){m} \ldots (vm-m){v_m}} with $v_m \in \LNodes = \LNodes_\lambda \union \LNodes_@ \union \LNodes_\Sigma \union \LNodes_{\sf var}$. Then $v_m$ appears in $t\filterplus r_0$ if and only if
$m$ does.
\end{enumerate}
\end{lemma}
\begin{proof} (a) holds by definition of $t\filterplus r_0$. (b) is proved by induction on $t$: It follows easily from the fact that in the definition of $t\filterplus r_0$, the inductive cases follow those from the definition of traversal P-views.
(c) If $v_m \in \LNodes_@\union \LNodes_\Sigma \union \LNodes_{\sf var}$ then it
falls back to (a). Otherwise $v_m \in \LNodes_\lambda$ and by (b), $v_m$
appears in $t\filterplus r_0$ if and only if the last lambda node in
$\pview{t}$ does. But the last node in $\pview{t}$ is necessarily
$m$ (since $v_m$ is necessarily visited with a copy-cat rule).
\end{proof}


\begin{lemma}
\label{lem:projplus_pendingnode}
 Let $t \in \travset(M)$ and $r_0$ be the occurrence in $t$ of a $\lambda$-node.
 We have:
  $$?(t\filterplus r_0) =\ ?(t) \filterplus r_0 \enspace .$$
\end{lemma}
\begin{proof} Take a prefix $u$ of $t$ ending with a value-leaf $v_n$ of an
occurrence $n$. By Lemma
\ref{lem:ifin_projplus_so_does_justifier}(c), the operation $\_
\filterplus r_0$ removes $v_n$ from $t$ if and only if it also removes
$n$.
\end{proof}

\subsubsection{O-view and P-view of the subterm projection}

\paragraph{P-view projection}


\begin{lemma}[P-view Projection for traversals]
\label{lem:pviewproj_traversal} Let $t$ be a traversal and
$r_0$ be an occurrence in $t$ of a lambda node $r' \in \INodes_\lambda$. Then:
\begin{itemize}
\item[(i)] If $t^\omega$ appears in $t\filterplus r_0$ then:
    \begin{itemize}
    \item[a.] $r_0$ appears in $\pview{t}$, all the nodes occurring after $r_0$ in $\pview{t}$ appear in $t\filterplus r_0$
    and all the nodes occurring before $r_0$ in $\pview{t}$ do not appear in $t\filterplus r_0$;

    \item[b.] $\pview{t\filterplus r_0}^{M^{(r')}} = \pview{t}^M_{\suffixof r_0} = r_0\cdot \ldots$; % = \pview{t}^M \filterplus r_0$.

    \item[c.] if $t^\omega$ also appears in $t\filterplus r_1$ for some occurrence $r_1$ $r'$ then $r_0 = r_1$;

    \item[d.] if \Pstr[0.5cm]{t = \ldots (l){m} \ldots (n-l,30){n} } and $m$ does not appear in $t\filterplus r_0$ then
    $r_0$ occurs after $m$ in $t$ and $m$ is a free variable
    node in the sub-computation tree $\tau(M^{(r')})$.
    \end{itemize}
\item[(ii)] Suppose \Pstr[0.3cm]{t = \ldots r_0 \ldots (l){m} \ldots (n-l,30){n} }. Then the node  $n$ appears in $t\filterplus r_0$ if and only if $m$ does.
\end{itemize}
\end{lemma}
\begin{proof}
 (i) A trivial induction shows both a.\ and b.\. (The inductive steps in the definition of the projection operation $\_ \filterplus r_0$ correspond precisely to those from the definition of P-views.)

c.\ By a., both $r_0$ and $r_1$ appears in the P-view. But the
P-view is the path from $t^\omega$ to the root, hence it cannot
contain two different occurrences of the same node $r'$.

d.\ Since $t^\omega$ appears in $t\filterplus r_0$ and its justifier
$m$ is not in $t\filterplus r_0$, by a., the justifier $m$
necessarily precedes $r_0$ in $t$, and by Lemma
\ref{lem:ifin_projplus_so_does_justifier}, $n$ is necessarily a variable node.
Thus $m$ occurs before $r_0$ in the P-view $\pview{t}$. In other words, $r_0$ lies in the path from
$n$ to its binder $m$. Consequently, $n$ is a free variable node in
$\tau(M^{(r')})$.

(ii) The case $n\not\in  \INodes_{\sf var}$ is handled by Lemma
\ref{lem:ifin_projplus_so_does_justifier}(a) and (c).

Suppose that $n\in  \INodes_{\sf var}$. If $n$ appears in $t\filterplus r_0$ then by
(i) all the nodes occurring in $\pview{t}$ up to $r_0$ appear in
$t\filterplus r_0$. By P-visibility, $m$ appears in $\pview{t}$ and
since $r_0$ precedes it by assumption, $m$ also appears in
$t\filterplus r_0$.
If $m$ appears in $t\filterplus r_0$ then since $m$ appears in the P-view at $x$, by definition of
$t\filterplus r_0$, $x$ must also appear in $t\filterplus r_0$.
\end{proof}


\begin{lemma}
\label{lem:insubterm_equ_inprojplus}
   Let $t \in \travset(M)$ such that $t^\omega \not\in \LNodes_\lambda$. Let $r'$ be some lambda node in $\INodes_\lambda$.

   The node $t^\omega$ belongs to the subtree of $\tau(M)$ rooted at $r'$ (\ie, $t^\omega \in \Nodes^{(r')}$) if and only if
   $t^\omega$ appears in $t\filterplus r_0$ for some occurrence $r_0$ of $r'$ in $t$.
\end{lemma}

\begin{proof}
\emph{Only if part:} Since $t$'s last move in not a lambda leaf, by
Proposition \ref{prop:pviewtrav_is_path}, the P-view $\pview{t}$
is the path to the root $\theroot$. Hence since $t^\omega$ belongs
to the subtree of $\tau(M)$ rooted at $r'$, $\pview{t}$ must contain
(exactly) one occurrence $r_0$ of $r'$. But then by definition of $t\filterplus r_0$, all the nodes following $r_0$
occurring in the P-view must also belong to $t\filterplus r_0$, so in particular, $t^\omega$ does.

\emph{If part:} By Lemma \ref{lem:pviewproj_traversal}(i), $r_0$ must occur in $\pview{t}$
and therefore $r_0$ lies in the path from $t^\omega$ to the root $\theroot$ of the computation
tree $\tau(M)$. Consequently, $t^\omega$ necessarily belongs to the subtree of $\tau(M)$ rooted at $r'$.
\end{proof}

\begin{lemma}
\label{lem:intfilterstar_iff_hjintstarfiltersubtree}
 Let $t$ be a traversal and $r_0$ be an occurrence in $t$ of some lambda node $r'$. Then an
occurrence $n \not\in \Nodes_@ \union \Nodes_\Sigma$ of $t$ is hereditarily justified by $n_0$ in $t^\star\filter \Nodes^{(r')}$ if and only if $n$ appears in $t\filterplus r_0$.
\end{lemma}
\begin{proof}
We proceed by induction on $t_{\prefixof n}$.
If $n=r_0$ or if $r_0$ does not occur in $t_{\prefixof n}$ then
the result holds trivially. Suppose that $r_0$ occurs in $t_{<n}$.
Let $m$ be $n$'s justifier in $t$. We do a case analysis on $n$.
The case $n\in \LNodes_@\union \LNodes_\Sigma \union \INodes_@ \union \INodes_\Sigma$
is excluded by assumption.

Suppose $n \in \LNodes_\lambda \union \LNodes_{\sf var} \union \INodes_\lambda$ then
\begin{align*}
\mbox{$n$ appears in $t\filterplus r_0$} &\iff \mbox{$m$ appears in $t\filterplus r_0$} & \mbox{by Lemma
\ref{lem:ifin_projplus_so_does_justifier}(a)} \\
&\iff \mbox{$m$ her.\ just.\ by $n_0$ in $t^\star\filter \Nodes^{(r')}$} & \mbox{by I.H.\ on $t_{\prefixof m}$} \\
&\iff \mbox{$n$ her.\ just.\ by $n_0$ in $t^\star\filter \Nodes^{(r')}$} & \mbox{since $m$ is $n$'s parent in $\tau(M^{(r')})$.}
\end{align*}

Suppose that $n \in \INodes_{\sf var}$ then
\begin{align*}
\mbox{$n$ appears in $t\filterplus r_0$} &\iff \parbox{11cm}{$r_0$ appears in $\pview{t}$ \hfill
\quad by Lemma \ref{lem:insubterm_equ_inprojplus} and \ref{lem:pviewproj_traversal}(i)} \\
&\iff \left\{
        \begin{array}{l}
          \hbox{$r_0$ precedes $m$ in $\pview{t}$, and thus $n$ is a bound variable in $M^{(r')}$} \\
          \hbox{or $r_0$ appears strictly after $m$ in $\pview{t}$ and $n$ is free in $M^{(r')}$}
        \end{array}
      \right. \\
&\iff \left\{
        \begin{array}{l}
          \parbox{11cm}{$m$ appears in $t\filterplus r_0$ \hfill by Lemma \ref{lem:pviewproj_traversal}(i)} \\
          \parbox{11cm}{or $n$ points to $r_0$ in $t^\star\filter \Nodes^{(r')}$ \hfill by def.\ of $\_ \filter \Nodes^{(r')}$}
        \end{array}
      \right. \\
&\iff \left\{
        \begin{array}{l}
          \parbox{11cm}{$m$ her.\ just.\ by $n_0$ in $t^\star\filter \Nodes^{(r')}$ \hfill by I.H.\ on $t_{\prefixof m}$} \\
          \hbox{or $n$ points to $r_0$ in $t^\star\filter \Nodes^{(r')}$}
        \end{array}
      \right. \\
&\iff \left\{
        \begin{array}{l}
          \parbox{11cm}{$n$ her.\ just.\ by $n_0$ in $t^\star\filter \Nodes^{(r')}$ \hfill $n$ is in $\Nodes^{(r')}$ iff its binder $m$ is} \\
          \hbox{or $n$ points to $r_0$ in $t^\star\filter \Nodes^{(r')}$}
        \end{array}
      \right.\\
&\iff \hbox{$n$ is her.\ just.\ by $n_0$ in $t^\star\filter \Nodes^{(r')}$ \enspace .}  \qedhere
\end{align*}
\end{proof}

\begin{lemma}
\label{lem:thread_projplus} Take a traversal $t$.  Let $r'$ be a
node in $\INodes_\lambda$ and $r_0$ an occurrence of $r'$ in $t$. Suppose
that $t^\omega$ appears in $t\filterplus r_0$ and that the thread of
$t^\omega$ is initiated by $\alpha \in \INodes_@ \union \INodes_\Sigma$.

(i) If $r_0$ precedes $\alpha$ in $t$ then all the nodes occurring in the thread appear in $t\filterplus r_0$.

(ii) If $\alpha$ precedes $r_0$ in $t$ then
    $t^\omega$ is hereditarily enabled by $r'$ in $\tau(M^{(r')})$.
\end{lemma}
\begin{proof}
(i) By definition of a thread, the nodes occurring in the thread
are all hereditarily justified by $\alpha$.
Since $r_0$ precedes $\alpha$ and $t^\omega$ appears in $t\filterplus r_0$, by Lemma \ref{lem:pviewproj_traversal}(ii) all the nodes in the thread must also appear in $t \filterplus r_0$.

(ii)
Let $q$ be the first node in $t$ that hereditarily justifies
$t^\omega$ in $t$ and that appears in $t\filterplus r_0$.


If $q \in \INodes_\lambda$ then necessarily $q = r_0$. Otherwise by definition of $\_\filterplus r_0$,
$q$'s justifier also appears in $t\filterplus r_0$ which contradicts
the definition of $q$. Hence the result holds trivially.

If $q\in \INodes_@\union \INodes_\Sigma$ then necessarily $q=\alpha$, since
links always point inside the current thread and since a thread contains by definition only one node in $\INodes_@\union \INodes_\Sigma$. But $\alpha$ precedes $r_0$ therefore $\alpha$ cannot be hereditarily justified by $r_0$ hence this case is not possible.

If $q \in \INodes_{\sf var}$ then by Lemma \ref{lem:pviewproj_traversal}(i.d),
$q$ is an free variable in $\tau(M^{(r')})$ and therefore
it is enabled by $r'$ in $\tau(M^{(r')})$. Hence since $t^\omega$ is hereditarily justified by $r_0$, it must be hereditarily enabled
by $r'$ in $\tau(M^{(r')})$.
\end{proof}

\paragraph{O-view projection}
In this paragraph we will spend some time proving the following Proposition:
\begin{proposition}[O-view projection for traversals]
\label{prop:oview_trav_projection}
   Let $t$ be a traversal of $\travset(M)$ such that its last node
   appears in $t \filterplus r_0$ for some occurrence $r_0$ in $t$ of a lambda node $r'$ in $\INodes_\lambda$.
   Then $ \oview{t}_M\filterplus r_0 \subseqof \oview{t\filterplus r_0}_{M^{(r')}}$.
\end{proposition}
One may recognize that this result bears resemblance with another
non trivial result of game semantics from the seminal paper by Hyland and Ong on full abstraction of PCF \cite{hylandong_pcf}:
\begin{proposition}[P-view projection in game semantics]{\cite[Prop.4.3]{hylandong_pcf}}
\label{prop:hylandong_pviewprojection}
  Let $s$ be a legal position of a game $A\gamear B$.
  If $s^\omega$ is in $B$ then $\pview{s}^{A\gamear B} \filter B \subseqof \pview{s\filter B}^B$.
\end{proposition}
Since such result is relatively hard to prove, it would be nice if we could just reuse the above proposition to show
our result. Unfortunately, the two settings are not exactly analogues of each other so we cannot immediately
deduce one proposition from the other. Indeed, the proof of the previous proposition relies on several properties of a legal position $s$ \cite{hylandong_pcf}:
\begin{itemize}
  \item (w1) Initial question to start: The first move played in $s$ is an initial move and there is no other occurrence of initial moves in the rest of $s$;
  \item(w2) Alternation: P-moves and O-moves alternate in $s$;
  \item(w3)  Explicit justification: \emph{every} move, except the first one, has a pointer to a preceding move,
  \item(w4)  Well-bracketing: The pending question is answered first;
  \item(w5)  Visibility: $s$ satisfies P-visibility and
O-visibility.
\end{itemize}
Also, further assumptions are made on the legal positions of the game
$A\gamear B$:
\begin{itemize}
  \item(w6) For every occurrence $n$ in the position, $n \in A \iff n \not\in
B$;
  \item(w7) Switching condition: The Proponent is the only player
      who can switch from game $A$ to $B$ or from $B$ to $A$.
  \item(w8) Justification in $A\gamear B$: Suppose $m$ justifies $n$ in $s$. Then
    \begin{itemize}
        \item $n \in B$ implies $m\in B$;
        \item if $n$ is a non-initial move in $A$ the $n \in A$;
        \item if $n$ is an initial move in $A$ the $n \in B$.
    \end{itemize}
\end{itemize}
Most of these requirements coincide with properties that we have already shown for traversals.
However traversals do not strictly satisfy explicit justification since there are some nodes---the @-nodes and $\Sigma$-nodes---that do not have justification pointers. The solution to this problem is simple: we just add justification pointers to @-nodes and $\Sigma$-nodes!

\indexnotation{$\extension{t}$}{Extension of a justified sequence of nodes}
Take a justified sequence of nodes $t$. We define $\extension{t}$, the \defname[extension of a justified sequence of nodes]{extension of $t$},
to be the sequence of nodes-with-pointers obtained from $\diamond \cdot t$ (where
$\diamond$ is a dummy node) by adding justification pointers going
from occurrences of the root $\theroot$, @-nodes and $\Sigma$-nodes
to their immediate predecessor in $t$.
\begin{example} Let $f \in \Sigma$. We have
$\extension{\Pstr[0.4cm]{ (l){\lambda \overline{\xi}} \cdot (at)@ \cdot (lx-at){\lambda x}\cdot (f)f \cdot (l-f){\lambda} \cdot (x-lx,60)x}} = \Pstr[0.6cm]{ (diam)\diamond \cdot (l-diam){\lambda \overline{\xi}}
 \cdot  (at-l)@\cdot  (lx-at){\lambda x}\cdot
(f-lx)f\cdot (l2-f){\lambda}\cdot (x-lx)x}$.
\end{example}

It is an immediate fact that for every two justified sequences $t_1$ and $t_2$ we have:
\begin{equation}
 \extension{t_1} \subseqof  \extension{t_2} \quad \iff \quad t_1 \subseqof  t_2 \label{eqn:hat_subseq}
\end{equation}
and for every justified sequence $t$:
\begin{equation}
 \extension{t} \filterplus r_0 = \extension{t \filterplus r_0} \label{eqn:extfilterplus_eq_filterplusext} \enspace .
\end{equation}



Since a traversal extension $\extension{t}$ may contain @/$\Sigma$-nodes with pointers,
it is not a proper justified sequence of nodes as
defined in Def.~\ref{dfn:justseqnode}. Nevertheless, the basic transformations that we have defined for justified sequences---such as hereditary projection, P-view and O-view---apply naturally to traversal extensions (without any modification in their definition). The views of a traversal extension can be expressed in term of the traversal's views as follows:
\begin{align}
  \oview{\extension{t}} &=  \oview{t} \label{eqn:oview_exttrav_trav} \\
  \pview{\extension{t}} &=  \left\{
                            \begin{array}{ll}
                              \epsilon, & \hbox{if $t=\epsilon$\enspace ;} \\
                              \diamond \cdot \extension{\pview{t}}, & \hbox{otherwise.}
                            \end{array}
                          \right. \label{eqn:pview_exttrav_trav}
\end{align}

The transformations $\pview{\_}$ and $\oview{\_}$, however, do not convey the appropriate notion
of view for extended traversals. We define an alternative notion of
view more appropriate to traversal extensions, called O-e-view and P-e-view, as follows:
\begin{definition}
\label{eqn:def_eview}

The O-e-view of a traversal extension $\extension{t}$, written, $\oeview{\extension{t}}$ is defined as
\begin{equation*}
\oeview{\extension{t}} \defeq \pview{\extension{t}} \enspace .
\end{equation*}

The P-e-view of $\extension{t}$, written, $\oeview{\extension{t}}$ is defined by induction:
$$\begin{array}{rcll}
 \peview{\epsilon} &=&  \epsilon \\
 \peview{u \cdot n }  &=&  \peview{u} \cdot n
    & \mbox{if $n$ is an O-node;}
    \\
 \peview{\Pstr[15pt]{u \cdot (m){m} \cdot \ldots \cdot (x-m,30){n}}} &=&
    \Pstr{ \peview{u} \cdot (m2){m} \cdot (n2-m2,60){n} }
    & \mbox{if $n$ is a P-node.}
\end{array}$$

\end{definition}

Inserting a dummy node $\diamond$ at the beginning of the traversal changes the parity of the alternation between P-nodes and O-nodes.
Thus the role of O and P is interchanged for traversal extensions. This explains why the O-e-view is calculated from the P-view.

For the P-e-view, the definition is almost the same as the traversal O-view $\oview{\_}$ except that the computation does not stop when reaching a node in $\INodes_@ \union \INodes_\Sigma$---this is sometimes referred as the \emphind{long O-view} \cite{Harmer2005}. (The O-view contains only one thread whereas the long-O-view may contain several; the O-view is a suffix of the long O-view.)
This is possible because occurrences of nodes from $\INodes_@ \union \INodes_\Sigma$ in a traversal extension all have a justification pointer.
The O-view of $t$ is a suffix of its P-e-view:
\begin{equation}
  \peview{t} = w \cdot \oview{t} \quad \mbox{for some sequence $w$.} \label{eqn:oview_suffix_preview}
\end{equation}
\smallskip

We are now fully equipped to establish an analogy between the traversal extension setting and the game-semantic setting. The reason why we make this analogy is purely to reuse the proof of Proposition \ref{prop:hylandong_pviewprojection} \cite[Prop.~4.3]{hylandong_pcf}. The reader must not confuse it with another correspondence that we will establish in a forthcoming section, between plays of game semantics and traversals of the computation tree. (In particular the colouring of nodes used here in term of P-move/O-move is the opposite of the one used in the
Correspondence Theorem.) The following analogy is made:
\begin{center}
\begin{tabular}{r|p{6cm}}
{\bf Traversal setting} & {\bf Game-semantic setting} \\
\hline
Extended traversal $\extension{t}$ & Play $s$ \\
P-Nodes ($\INodes_{\sf var} \union \INodes_\Sigma \union \INodes_@ \union \LNodes_\lambda$) or $\diamond$ & O-moves $\omove$ \\
O-nodes ($\LNodes_{\sf var} \union \LNodes_\Sigma \union \LNodes_@\union \INodes_\lambda$) & P-moves $\pmove$\\
P-view $\peview{\extension{t}}$  & P-view $\pview{s}$\\
O-view $\oeview{\extension{t}}$  & O-view $\oview{s}$\\
Occurrence $n$ appearing in $t\filterplus r_0$ & Occurrence $n \in B$ \\
Occurrence $n$ not appearing in $t\filterplus r_0$ & Occurrence $n \in A$ \\
\parbox[t]{6cm}{\raggedleft No notion of initiality (All nodes are considered to be non-initial).} & Distinction between initial and non-initial move.
\end{tabular}
\end{center}

Clearly sequences of the form $\extension{t}$ satisfy the requirements (w1) to (w5): For (w1), the initial node
becomes $\diamond$. Explicit justification (w4) holds since we have added pointers to @/$\Sigma$-nodes.
Finally, alternation (w3), well-bracketing (w4) and visibility (w5) of the traversal $t$ (Prop.~\ref{prop:pviewtrav_is_path}) are preserved by the extension operation (where visibility is defined with respect to the appropriate
notion of P-view and O-view).

The property (w6) trivially holds: $n \in t\filterplus r_0$ iff $\neg ( n \not\in t\filterplus
r_0)$. So does the switching condition (w7): if $t = \ldots \cdot m \cdot n$ where $n$ is a P-node and $m$ is an O-node then, by definition of $t\filterplus r_0$, $m$ appears in $t\filterplus r_0$ if and only if $n$ does. For (w8): Using the analogy of the preceding table and since all nodes are considered ``non-initial'' in
$\extension{t}$, this condition can be stated as:
\begin{quote}
 (w8) Suppose $m$ justifies $n$ in $\extension{t}$. Then $n \in t\filterplus r_0$ if and only if $m\in t\filterplus r_0$.
\end{quote}
Unfortunately, as we have seen previously, the direct implication
does not hold in general! (Indeed, a variable node can very well
appear in $t\filterplus r_0$ even though its justifier does not.)
Consequently, the proof of Proposition
\ref{prop:hylandong_pviewprojection} cannot be directly reused in
our setting. A weaker version of condition (w8) holds however: if $r_0$
occurs before $n$'s justifier then, by Lemma \ref{lem:pviewproj_traversal}(i), $n$ appears in $t\filterplus r_0$ if and only if its justifier does; this condition turns out to be
sufficient to reuse most of the proof of Proposition \ref{prop:hylandong_pviewprojection} \cite{hylandong_pcf}.

We reproduce here some definition used in this proof. Let
$s$ be a position of the game $A\gamear B$. A bounded segment is
a segment $\theta$ of $s$ of the form
$\Pstr[0.6cm]{(x){\stackrel{x}\pmove} \ldots
(y-x){\stackrel{y}\omove}}$. If $x$ is in $A$, and hence so does $y$,
then $\theta$ is an $A$-bounded segment. Respectively if $x$ and $y$
are in $B$ then it is a $B$-bounded segment. By an abuse of notation
we define $\pview{\theta \filter B}$ to be the subsequence of
$\pview{s_{\prefixof y} \filter B}$ consisting only of moves in
$\theta$ appearing after (and not including) $x$.

%The visibility condition (w5) then gives us the following lemma \cite[Lemma A.1]{hylandong_pcf}:
%\begin{lemma}[Spine decomposition]
%Any bounded segment $\theta$ with end-moves x and y may be decomposed
%in the following way:
%$$ \underbrace{\pstr[0.5cm]{\nd(x){\stackrel{x}\pmove}  \cdot
%            \framebox{\pstr[0.2cm]{\nd(pm){\stackrel{p_m}\omove} \ldots \nd(qm-pm,30){\stackrel{q_m}\pmove}}} \ldots
%            \framebox{\pstr[0.2cm]{\nd(pi){\stackrel{p_i}\omove} \ldots \nd(qi-pi,30){\stackrel{q_i}\pmove}}} \ldots
%            \framebox{\pstr[0.2cm]{\nd(p1){\stackrel{p_1}\omove} \ldots \nd(q1-p1,30){\stackrel{q_1}\pmove}}}
%            \cdot \nd(y-x,20){\stackrel{y}\omove}}}_\theta \enspace .$$
%\end{lemma}
We then have:
\begin{lemma} \cite[Lemma A.3]{hylandong_pcf}
Let $\theta$ be an $A$-bounded segment in $s$ with end-moves $x$ and
$y$.

\begin{enumerate}[(i)]
  \item $ \pview{\theta \filter B} = \Pstr{ (p){\stackrel{p_r}\pmove} \cdot (q-p){\stackrel{q_r}\omove} \ldots
                                     (p1){\stackrel{p_1}\pmove}
\cdot (q1-p1){\stackrel{q_1}\omove} }$ for some $r\geq 0$. Note
that each segment $p_i \ldots q_i$ is B-bounded in $s$, for
$1\leq i \leq r$.
  \item For every P-move $m$ in $\theta$ which appears in
$\oview{s_{<y}}$, $m$ does not belong to any of the $B$-bounded
segments $p_i \ldots q_i$ for $1\leq i \leq r$.
\end{enumerate}
\end{lemma}
This lemma assumes that the segment $\theta$ satisfies the
assumptions (w1) to (w8). As we have seen, (w8) does not always hold for extended traversals. But using our analogy with extended traversals, a  segment $\theta$ is ``A-bounded'' if $\theta$ is bounded by two nodes appearing in $t\filterplus r_0$. This can only happen if $r_0$ occurs before $\theta$ in $t$ or if $\theta$'s left bound is $r_0$.  Thus the condition (w8) holds at least for the nodes of the segment $\theta$.
The previous lemma thus translates into:
\begin{lemma}
\label{lem:pview_bounded_segment} Let $t$ be a traversal and
$\theta$ be a segment of $\extension{t}$ bounded by nodes $x$ and $y$ appearing in $t\filterplus r_0$.
\begin{enumerate}[(i)]
  \item $ \peview{\theta \filterplus r_0} = \Pstr{ (p){p_r} \cdot (q-p){q_r} \ldots
(p1){p_1} \cdot (q1-p1){q_1} }$ for some $r\geq 0$ where
$p_i$ is an O-node and $q_i$ is a P-node, for $1\leq i \leq r$.
  \item For every node O-node $m$ occurring in $\theta$ and appearing in
$\oeview{\extension{t}_{<y}}$, $m$ does not belong to any of the
segments $p_i \ldots q_i$ for $1\leq i \leq r$.
\end{enumerate}
\end{lemma}
\smallskip

We now show the analogue of Proposition \ref{prop:hylandong_pviewprojection} in the context of extended traversals:
\begin{proposition}
\label{prop:analog_pviewprojection} Let $t$ be a traversal and $r_0$
be an occurrence of some lambda node $r'$.
If $\extension{t}$'s last node appears in $t\filterplus r_0$ then
 $\peview{ \extension{t}}  \filterplus r_0 \subseqof \peview{ \extension{t\filterplus
 r_0}}$.
\end{proposition}
\begin{proof}
By (\ref{eqn:extfilterplus_eq_filterplusext}) we can equivalently show that:
$\peview{ \extension{t}}  \filterplus r_0 \subseqof \peview{ \extension{t}\filterplus
 r_0}$. By induction on the length of $t$. The base case is immediate. For the inductive case,
we do a case analysis:
    \begin{itemize}
    \item $t =  t' \cdot r_0$. We have $\extension{t} \filterplus r_0 = r_0$ and
     $\peview{\extension{t}} \filterplus r_0 = r_0 = \peview{\extension{t} \filterplus r_0}$.

    \item $t = t' \cdot n$ where $n$ is an O-node and is not the occurrence $r_0$.

    There are two cases.
    \begin{itemize}
        \item Suppose that the last node in $t'$ appears in $t\filterplus r_0$. Then
        by the I.H.\ we have $\peview{\extension{t'}} \filterplus  r_0 \subseqof \peview{\extension{t'} \filterplus  r_0}$ thus
            \begin{align*}
            \peview{\extension{t}} \filterplus r_0
                &=  \peview{\extension{t'}} \filterplus r_0 \cdot n  & \parbox[t]{7cm}{(\raggedleft P-view for extended justified\\sequences of nodes of $M$)} \\
                &\subseqof  \peview{\extension{t'} \filterplus  r_0} \cdot n            & (\mbox{induction hypothesis}) \\
                &=  \peview{\extension{t'} \filterplus  r_0 \cdot n} & \parbox[t]{7cm}{\raggedleft (P-view for extended justified sequences of nodes of $M^{(r')}$, $n$ belongs to $\Nodes^{(r')}$
                by Lemma \ref{lem:insubterm_equ_inprojplus})} \\
                &=  \peview{\extension{t' \cdot n} \filterplus  r_0  }   & (\mbox{$n$ occurs in $t\filterplus r_0$}) \\
                &= \peview{\extension{t} \filterplus  r_0  }     & (\mbox{definition of } t).
            \end{align*}

        \item Suppose that the last node $y_1$ in $t'$ does not appear in $t\filterplus r_0$.
        Let $\underline{m}$ be the last node preceding $m$ in $\peview{\extension{t}}$ that appears in $t\filterplus r_0$. Then for some $q\geq 0$ we have
        \begin{equation*}
        \peview{\extension{t}} = \peview{\extension{t}_{\prefixof \underline{m}}} \cdot \underbrace{\Pstr[0.2cm]{(xq){x_q} \cdot (yq-xq){y_q}\ \ldots\ (x1){x_1} \cdot (y1-x1){y_1}}}_{\mbox{all appear in $t\filterplus r_0 \cdot m$}}
        \end{equation*}
        where the $x_i$s are all O-nodes and the $y_i$s are all P-nodes.

        Therefore the sequence $\extension{t}$ must be of the following form:
        $$\extension{t}_{\prefixof \underline{m}} \cdot \underbrace{x_q \ldots y_q}_{\theta_q} \ \cdots \ \underbrace{x_1 \cdots y_1}_{\theta_1} \cdot\ m $$
        where each segment $\theta_i$ is bounded by nodes appearing in $t\filterplus r_0$.
        By Lemma \ref{lem:pview_bounded_segment}, when computing the P-view of $\extension{t}$, pointers going from a segment $\theta$ to a node outside the segment are never followed! In other words:
        $$ \peview{\extension{t} \filterplus r_0} =
        \peview{\extension{t}_{\prefixof \underline{m}} \filterplus r_0} \cdot \peview{\theta_q \filterplus r_0} \cdot\ \cdots\
        \cdot \peview{\theta_1 \filterplus r_0} \cdot m \enspace .$$
        Hence:
            \begin{align*}
            \peview{\extension{t}} \filterplus r_0
            &= \peview{\extension{t}_{\prefixof \underline{m}}} \filterplus r_0 \cdot n \\
            &\subseqof \peview{\extension{t}_{\prefixof \underline{m}} \filterplus r_0}  \cdot n
                    \hspace{5cm} \mbox{(I.H.)} \\
            &\subseqof \peview{\extension{t}_{\prefixof \underline{m}} \filterplus r_0} \cdot \peview{\theta_q \filterplus r_0} \cdot \cdots \cdot \peview{\theta_1 \filterplus r_0}  \cdot n \\
            &= \peview{\extension{t} \filterplus r_0} \hspace{5cm}
                    \mbox{(by the previous equation).}
          \end{align*}
    \end{itemize}

    \item $\Pstr{ t =  t' \cdot (m){m} \cdot u \cdot (lmd-m,30){n} }$
    where $n$ is a P-node. Then $m$ is an O-node.

     Suppose that $r_0$ appears in $t' \cdot m$, then since $n$ appears in $t\filterplus r_0$, by Lemma \ref{lem:pviewproj_traversal}(i) so does $m$. Thus we can apply the I.H.\ on $t' \cdot m$:
%
%%TODO make the following code compilable with pdflatex
\ifpdf%
\message{LaTeX Warning: !!!!!!!!!!Code incompatible with pdflatex!!!!!!!!!!}%
\else%
        \begin{align*}
        \peview{\extension{t}} \filterplus r_0
        &= \peview{\Pstr{\extension{t'} \cdot (m){m} \cdot \overline{u} \cdot (n-m,40){n}}}_M \filterplus r_0
                & (\mbox{definition of } t)\\
        &= (\pstr[0pt]{\peview{\extension{t'} \cdot \nd(m){m}}  \cdot \nd(lmd-m,60){n}}) \filterplus r_0
                & (\mbox{P-eview computation in $M$ }) \\
        &= \pstr[0.4cm]{ \peview{\extension{t' \cdot \nd(m){m}}} \filterplus r_0  \cdot  \nd(lmd-m,30){n} }
                & (\mbox{$n$ appears in $t \filterplus r_0$}) \\
        &\subseqof \pstr[0.4cm]{ \peview{(\extension{t' \cdot \nd(m){m}} )\filterplus r_0} \cdot \nd(lmd-m,25){n} }
                & \mbox{(induction hypothesis on $t' \cdot m$)} \\
        &= \pstr[0.4cm]{ \peview{\extension{t'}\filterplus r_0 \cdot \nd(m){m}} \cdot \nd(lmd-m,45){n} }
                & \mbox{($m$ appears in $t \filterplus r_0$)} \\
        &= \peview{ \Pstr[0.4cm]{\extension{t'} \filterplus r_0 \cdot (m){m} \cdot {(\extension{u} \filterplus r_0)} \cdot (lmd-m,30){n}}}
                & \parbox[t]{6cm}{\raggedleft(P-eview in $M^{(r')}$, nodes in $m\cdot (\extension{u} \filterplus r_0) \cdot n$ are all in $\Nodes^{(r')}$)} \\
        &= \peview{ (\Pstr{\extension{t'} \cdot (m){m} \cdot \extension{u} \cdot (lmd-m,35){n}}) \filterplus r_0 }
                & \mbox{($m$ and $n$ both appear in } t \filterplus r_0) \\
        &= \peview{ \extension{t} \filterplus r_0 }
                & \mbox{(definition of $t$).}
      \end{align*}

      Suppose that $r_0$ appears in $u$ then:
      \begin{align*}
        \peview{\extension{t}} \filterplus r_0
        &= \pstr[0.4cm]{ \peview{\extension{t' \cdot \nd(m){m}}}
           \filterplus r_0  \cdot  \nd(lmd-m,30){n} } \\
        &= n & (\mbox{$r_0$ occurs after $m$}) \\
            &\subseqof \pstr[0.4cm]{ \peview{(\extension{t' \cdot \nd(m){m}} )\filterplus r_0} \cdot \nd(lmd-m,25){n} }
                \\
        &= \peview{ \extension{t} \filterplus r_0 } \enspace .\qedhere
      \end{align*}
\fi
\end{itemize}
\end{proof}

We can now prove Proposition \ref{prop:oview_trav_projection}:
\begin{proof}[Proof of Proposition \ref{prop:oview_trav_projection}]
We have:
\begin{align*}
  \oview{t}\filterplus r_0
        &= \oview{\extension{t}} \filterplus r_0 & \mbox{by (\ref{eqn:oview_exttrav_trav})} \\
        &\subseqof \peview{\extension{t}} \filterplus r_0 & \mbox{by (\ref{eqn:oview_suffix_preview})} \\
        &\subseqof \peview{\extension{t \filterplus r_0}}  & \mbox{by Proposition \ref{prop:analog_pviewprojection}} \\
        &= w \cdot \oview{\extension{t \filterplus r_0}} & \mbox{for some $w$, by (\ref{eqn:oview_suffix_preview})} \\
        &= w \cdot \oview{t \filterplus r_0} & \mbox{by (\ref{eqn:oview_exttrav_trav})}.
\end{align*}
Thus $\oview{t}\filterplus r_0 \subseqof w \cdot \oview{t \filterplus r_0}$.
But by definition of the operator $\_ \filterplus$, both
$\oview{t}\filterplus r_0$ and $\oview{t \filterplus r_0}$ start with the occurrence $r_0$, we thus have
$\oview{t}\filterplus r_0 \subseqof \oview{t \filterplus r_0}$.
\end{proof}


\begin{example}
Take $\varphi:2, e:o \entail
    \varphi (\lambda x .
                (\lambda \psi .
                    \varphi (\lambda x' .
                                (\lambda y . \psi (\lambda z . z))
                                (\varphi (\lambda x'' . x'))
                            )
                )
            (\lambda u. u e))$. The computation tree is represented below together with an example of traversal $t$:

\begin{tabular}{lp{8cm}}
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,inner ysep=0.5mm,sibling distance=12mm]
\node (root) {$\lambda$}
child {node {$\varphi$}
    child {node {$\lambda x$}
        child {node {$@$}
           child{node {$\lambda\psi$}
               child{node {$\varphi$}
                   child{node {$\lambda x'$}
                       child{node {$@$}
                           child{node {$\lambda y$}
                               child{node {$\psi$}
                                   child{node {$\lambda z$}
                                       child{node {$z$}}
                                   }
                               }
                           }
                           child{node {$\lambda$}
                               child{node {$\varphi$}
                                   child{node {$\lambda x''$}
                                       child{node {$x'$}}
                                   }
                               }
                           }
                       }
                   }
               }
           }
           child{node {$\lambda u$}
               child{node {$u$}
                   child{node {$\lambda$}
                       child{node {$e$}}
                   }
               }
           }
        }
    }
}
;
\end{tikzpicture}
\hspace{1.8cm} &
\vspace{1cm}
\begin{asparablank}
\item $t = \Pstr[0.7cm]{(n0){\lambda }\ (n1-n0){\varphi}\ (n2-n1){\lambda x}\ (n3){@}\ (n4-n3){\lambda \psi}\ (n5-n0){\varphi}\ (n6-n5){\lambda x'}\ (n7){@}\ (n8-n7){\lambda y}\ (n9-n4){\psi}\ (n10-n3){\lambda u}\ (n11-n10){u}\ (n12-n9){\lambda z}\ (n13-n12){z}\ (n14-n11){\lambda }\ }$
\item $\oview{t} = \Pstr[0.7cm]{(n0){@}\ (n1-n0){\lambda \psi}\ (n2-n1){\psi}\ (n3-n0){\lambda u}\ (n4-n3){u}\ (n5-n2){\lambda z}\ (n6-n5){z}\ (n7-n4){\lambda }\ }$
\item $\oview{t}\filterplus r_0 = \Pstr[0.7cm]{(n0){\lambda \psi}\ (n1-n0){\psi}\ (n2-n1){\lambda z}\ (n3-n2){z}\ }$

\item $t\filterplus r_0 = \Pstr[0.7cm]{(n0){\lambda \psi}\ (n1-n0){\varphi}\ (n2-n1){\lambda x'}\ (n3){@}\ (n4-n3){\lambda y}\ (n5-n0){\psi}\ (n6-n5){\lambda z}\ (n7-n6){z}\ }$
\item $\oview{ t \filterplus r_0 } = \Pstr[0.7cm]{(n0){\lambda \psi}\ (n1-n0){\psi}\ (n2-n1){\lambda z}\ (n3-n2){z}\ }$.
\end{asparablank}
\end{tabular}
\end{example}


\begin{example}
Take the term-in-context:
 $$e:o \entail
    (\lambda f g . f (\lambda b . f (\lambda b'. b) (\lambda a' . a' e))
                        (\lambda a . a e))
    (\lambda x y . y (\lambda h . x (h e)) e) e \enspace .$$ Take the traversal:
$$t = \Pstr[1cm]{{\lambda }\ (n1){@}\ (n2-n1){\lambda f g}\ (n3-n2){f}\ (n4-n1){\lambda x y}\ (n5-n4){y}\ (n6-n3){\lambda a}\ (n7-n6){a}\ (n8-n5){\lambda h}\ (n9-n4){x}\ (n10-n3){\lambda b}\ (n11-n2){f}\ (n12-n1){\lambda x y}\ (n13-n12){y}\ (n14-n11){\lambda a'}\ (n15-n14){a'}\ (n16-n13){\lambda h}\ (n17-n12){x}\ (n18-n11){\lambda b'}\ (n19-n10){b}\ (n20-n9){\lambda }\ (n21-n8){h}\ }$$
then we have the following relations:
\smallskip

\begin{tabular}{ll}
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,inner ysep=0.5mm,sibling distance=12mm]
\node (root) {$\lambda$}
child {node {$@$}
    child {node {$\lambda f g$}
        child {node {$f$}
           child{node {$\lambda b$}
               child{node {$f$}
                   child{node {$\lambda b'$}
                       child{node {$b$}}
                   }
                   child{node {$\lambda a'$}
                       child{node {$a'$}
                           child{node {$\lambda$}
                               child{node {$e$}}
                           }
                       }
                   }
               }
           }
           child{node {$\lambda a$}
             child{node {$a$}
               child{node {$\lambda$}
                   child{node {$e$}}
               }
             }
           }
        }
    }
    child[missing]{}
    child {node {$\lambda x y$}
        child {node {$y$}
           child{node {$\lambda h$}
               child{node {$x$}
                   child{node {$\lambda$}
                       child{node {$h$}
                           child{node {$\lambda$}
                               child{node {$e$}}
                           }
                       }
                   }
               }
           }
           child{node{$\lambda$}
               child{node {$e$}}
           }
        }
    }
    child{node {$\lambda$}
       child{node {$e$}}
    }
};
\end{tikzpicture}
\hspace{0.5cm} &
\parbox[t]{7cm}{
\vspace{0.7cm}

$\oview{t} = \Pstr[0.7cm]{(n0){@}\ (n1-n0){\lambda f g}\ (n2-n1){f}\ (n3-n0){\lambda x y}\ (n4-n3){y}\ (n5-n2){\lambda a}\ (n6-n5){a}\ (n7-n4){\lambda h}\ (n8-n7){h}\ }$
\smallskip

$\oview{t}\filterplus r_0 = \Pstr[0.7cm]{(n0){\lambda f g}\ (n1-n0){f}\ (n2-n1){\lambda a}\ (n3-n2){a}\ }$
\smallskip

$t\filterplus r_0  = \Pstr[0.7cm]{(n0){\lambda f g}\ (n1-n0){f}\ (n2-n1){\lambda a}\ (n3-n2){a}\ (n4-n1){\lambda b}\ (n5-n0){f}\ (n6-n5){\lambda a'}\ (n7-n6){a'}\ (n8-n5){\lambda b'}\ (n9-n4){b}\ }$
\smallskip

$\oview{ t \filterplus r_0 } = \Pstr[0.7cm]{(n0){\lambda f g}\ (n1-n0){f}\ (n2-n1){\lambda a}\ (n3-n2){a}\ (n4-n1){\lambda b}\ (n5-n4){b}\ }$.
}
\end{tabular}
\end{example}

\subsubsection{Subterm projections are sub-traversals}

We now show an important result that relies on all the lemmas and propositions from the previous two sections:
\begin{proposition}[Subterm projections are sub-traversals]
    \label{prop:trav_projection}
    Let $t \in \travset(M)$. For every occurrence $r_0$ in $t$ of some lambda node
    $r'\in \INodes_\lambda$ we have $t\filterplus r_0 \in \travset(M^{(r')})$.
\end{proposition}
\begin{proof}
    We proceed by induction on the traversal rules. The base cases \rulenamet{Empty} and
    \rulenamet{Root} are trivial. \emph{Step case:} Take a traversal $t \in \travset(M)$ and suppose that the result holds for every traversal shorter than $t$.

    Suppose that $t^\omega$ does not appear in $t \filterplus r_0$ then
    the result follows by applying the induction hypothesis on the immediate prefix of $t$.
    Suppose that $t^\omega$ appears in $t \filterplus r_0$ then we do a case analysis on the last traversal rule used to form $t$:
    \begin{asparaitem}
    \item \rulenamet{Lam}
        We have  $t = t' \cdot n$ with $t' = \ldots \cdot \lambda \overline{\xi}$. By the induction hypothesis, $t' \filterplus r_0 \in  \travset(M^{(r')})$.

        Since $n$ is a variable node appearing in $t\filterplus r_0$, by definition of $t\filterplus r_0$ its immediate predecessor
        $\lambda \overline{\xi}$ must occur in $t\filterplus r_0$ and therefore must be the last occurrence in $t'\filterplus r_0$. Thus we can use the rule \rulenamet{Lam} in $\tau(M^{(r')})$ to produce the traversal $u = (t'\filterplus r_0) \cdot n$ of $M^{(r')}$.

        We have $t \filterplus r_0 = (t'\filterplus r_0) \cdot n$, but in order to state that $u = t \filterplus r_0$ it remains to prove that $n$ has the same link in $t \filterplus r_0$ and in $u$.

        Suppose $n \in \INodes_@ \union \INodes_\Sigma$ then $n$ has no justifier in both $u$ and $t\filterplus r_0$. Otherwise $n \in \INodes_{\sf var}$. Let $m_u$ denote the occurrence in $t$ of $n$'s justifier in $u$, $m_t$ for the occurrence in $t$ of $n$'s justifier in $t$, and $m$ for the occurrence in $t$ of $n$'s justifier in $t \filterplus r_0$. We want to show that $m_u = m$.
        By the rule \rulenamet{Var}, $m_u$ is defined as the only occurrence of $n$'s enabler in $\pview{t'\filterplus r_0}$ and $m_t$ is the only occurrence of $n$'s enabler in $\pview{t'}$.

        If $r_0$ occurs before $m_t$ then by Lemma \ref{lem:pviewproj_traversal}(ii), $m_t$ appears in $t \filterplus r_0$ thus by definition of $\_ \filterplus$ we have $m = m_t$. Moreover, since $m_t$ appears in $t\filterplus r_0$, it must appear
        after $r_0$ by Lemma \ref{lem:pviewproj_traversal}(i.a), thus since it is in the P-view at $t'$, it must be
        in $\pview{t}_{\suffixof r_0}$ which is equal to $\pview{t'\filterplus r_0}$ by Lemma \ref{lem:pviewproj_traversal}(i.b).
        Hence we necessarily have $m_u = m_t$ (since $r'$ occurs only once in the P-view $\pview{t'\filterplus r_0}$).

        If $r_0$ occurs after $m_t$ then $m_t$ does not appear in $t\filterplus r_0$ thus $m = r_0$ by definition of $\_ \filterplus$. Moreover by Lemma \ref{lem:pviewproj_traversal}(i), $n$'s binder occurs in the path from $r'$ to the root $\theroot$. Thus $n$ is a free variable in $\tau(M^{(r')})$ and consequently the only enabler of $n$ occurring in $\pview{t'\filterplus r_0}$ is necessarily $r_0$: $m_u = r_0$.

        This proves the equality $t \filterplus r_0 = u$ and thus $t \filterplus r_0$ is a valid traversal of $M^{(r')}$.

    \item \rulenamet{App} $t = \ldots \cdot \lambda \overline{\xi} \cdot @ \cdot n$.
        Since $n$ appears in $t\filterplus r_0$, so does $@$ (by definition of $t\filterplus r_0$). Hence @ is the last occurrence in $t'\filterplus r_0$. By the induction hypothesis, $t' \filterplus r_0$ is a traversal of $\tau(M^{(r')})$ therefore we can use the rule \rulenamet{App} in $\tau(M^{(r')})$ to produce the traversal $(t'\filterplus r_0) \cdot n = t \filterplus r_0$ of $M^{(r')}$.


    \item \rulenamet{Value^{@\mapsto\lambda}} Take \Pstr[0.5cm]{t = t' \cdot (lmd){\lambda
        \overline{\xi}} \cdot (x){@}  \ldots  (xv-x,50:v){v}_@  \cdot
        (lmdv-lmd,30:v){v}_{\lambda \overline{\xi}} }.

        The occurrence $v_{\lambda \overline{\xi}}$ appears
        $t\filterplus r_0$ therefore since $r_0$ is not a lambda
        node, its justifier $\lambda \overline{\xi}$ also appears in
        $t\filterplus r_0$. Moreover since $@$ and $v_@$ are hereditarily justified by $\lambda \overline{\xi}$, they must also appear in
        $t\filterplus r_0$.

        By the induction hypothesis $t' \filterplus r_0$ is a
        traversal of $\tau(M^{(r')})$ therefore since the occurrence
        $\lambda \overline{\xi}$, @, $v_@$, $v_{\lambda
        \overline{\xi}}$ all appear in $t\filterplus r_0$ we can use
        the rule \rulenamet{Value^{@\mapsto\lambda}} in $M^{(r')}$
        to form the traversal $(t'\filterplus r_0) \cdot n = t
        \filterplus r_0$ of $M^{(r')}$.

    \item \rulenamet{Value^{\lambda\mapsto @}}
          Take \Pstr[0.7cm]{t = t' \cdot (app){@} \cdot
        (lz-app,60){\lambda \overline{z}} \ldots
        (lzv-lz,60:v){v}_{\lambda \overline{z}} \cdot
        (appv-app,45:v){v}_@}. Again, since $v_@$ appears in $t
        \filterplus r_0$, necessarily the occurrences @, $\lambda
        \overline{z}$, $v_{\lambda \overline{z}}$ and $v_@$ must all
        appear in $t \filterplus r_0$. Hence using the induction
        hypothesis and the rule
        \rulenamet{Value^{\lambda\mapsto @}} in $M^{(r')}$ we
        obtain that $t \filterplus r_0$ is a traversal of
        $M^{(r')}$.

    \item \rulenamet{Value^{{\sf var}\mapsto\lambda}} Take \Pstr[0.6cm]{t = t' \cdot (lmd){\lambda
    \overline{\xi}} \cdot (x){x}  \ldots  (xv-x,50:v){v}_x  \cdot (lmdv-lmd,30:v){v}_{\lambda \overline{\xi}} }. Since $v_{\lambda \overline{\xi}}$ is in $t \filterplus r_0$, so must be $x$, $v_x$ and $\lambda \overline{\xi}$, by definition of $t \filterplus r_0$. Hence we can use the I.H.\ to form the traversal $t \filterplus r_0$ of $M^{(r')}$.

   \item \rulenamet{InputValue} Take \Pstr[0.4cm]{t =
    t_1 \cdot (x){x} \cdot t_2 \cdot (xv-x,38:v){v_x} } for some
    $v \in \mathcal{D}$ where $x$ is the pending node in $t_1 \cdot x \cdot t_2$ and $x \in \INodes_{\sf var}^{\theroot\enable}$.
    Since $v_x$ appears in $t\filterplus r_0$, so does $x$ hence
    by Lemma \ref{lem:projplus_pendingnode}, $x$ is also the
    pending node in $(t_1 \cdot x \cdot t_2)\filterplus r_0$.
    Furthermore since $M^{(r')}$ is a subterm of $M$, $x$ is
    necessarily an input-variable node in $\tau(M^{(r')})$.
    Hence we can conclude using the I.H.\ and the rule
    \rulenamet{InputValue}.

    \item \rulenamet{InputVar}  Take $t =  t' \cdot n$ where $n \in \INodes_\lambda$ points to an occurrence of its parent node $y \in \INodes_{\sf var}^{\theroot\enable}$ in $\oview{t}$.
    By Lemma \ref{lem:ifin_projplus_so_does_justifier}(a), $y$
    must also appear in $t\filterplus r_0$, therefore $y$ also
    occurs in $\oview{t\filterplus r_0} \subseqof
    \oview{t}\filterplus r_0$. Hence we can conclude using the
    rule \rulenamet{InputVar} in $M^{(r')}$.


    \item \rulenamet{Var}
    Take \Pstr[0.7cm]{ t = t' \cdot (p){p} \cdot (lx){\lambda
        \overline{x}} \ldots (x-lx,30:i){x_i}  \cdot
        (letai-p,40:i){\lambda \overline{\eta_i}} } for some
        variable $x_i$ in $\INodes_{\sf var}^{@\enable}$.
    If $\lambda \overline{\eta_i}$ is the occurrence $r_0$ then
    the traversal $t\filterplus r_0 = r_0$ can be formed using
    the rule \rulenamet{Root}.

    Suppose that $\lambda \overline{\eta_i}$ is not the occurrence $r_0$. Then both $\lambda \overline{\eta_i}$ and its justifier $p$ must appear in $t\filterplus r_0$. The nodes $\lambda
    \overline{x}$ and $x_i$, however, do not necessarily appear in    $t\filterplus r_0$.

    Consider the node @ that initiates the thread of $\lambda \overline{\eta_i}$.

    \begin{compactitem}
    \item Suppose that $r_0$ precedes @ in $t$ then
    by Lemma \ref{lem:thread_projplus}(i), the nodes $\lambda
    \overline{\eta_i}$, $p$, $\lambda \overline{x}$ and $x_i$ as
    well as @ all appear in $t\filterplus r_0$. Moreover since @
    appear in $t\filterplus r_0$, it must be an occurrence of an
    application node that appear in the subtree rooted at $r'$
    thus $@ \in \INodes_{\sf var}^{r'\enable}$.  Hence we can use the
    use the rule \rulenamet{Var} in $M^{(r')}$ to form the
    traversal $t \filterplus r_0$ of $M^{(r')}$.

    \item Suppose that @ precedes $r_0$ in $t$ then
    by Lemma \ref{lem:thread_projplus}(ii), $p$ is necessarily
    an input variable node in $\tau(M^{(r')})$.  We have $p \in \oview{t} \filterplus r_0 \subseqof \oview{t\filterplus r_0}$ by Proposition \ref{prop:oview_trav_projection}. Furthermore we can easily check (by alternation and using the fact that if an occurrence in $\INodes_\lambda \union \LNodes_{\sf var} \union \LNodes_@ \union \LNodes_\Sigma \union \INodes_@ \union \INodes_\Sigma$ appears in $t\filterplus r_0$ then so does its immediate successor) that the penultimate node in $t\filterplus r_0$ is necessarily in $\INodes_{\sf var} \union \LNodes_\lambda$. Hence we can make use of the rule \rulenamet{InputVar} in $M^{(r')}$ (in its alternative form) to produce the traversal $t \filterplus r_0$ of $M^{(r')}$.
    \end{compactitem}

    \item \rulenamet{Value^{\lambda\mapsto{\sf var}}} Take \Pstr[0.8cm]{t = t' \cdot (y){y} \cdot (lmd){\lambda \overline{\xi}} \ldots (lmdv-lmd,30:v){v}_{\lambda \overline{\xi}}  \cdot (vy-y,50:v){v}_y } for some variable $y$ in $\INodes_{\sf var}^{@\enable}$.
    The proof is similar to the previous case using the rule \rulenamet{InputValue} instead of \rulenamet{InputVar} in the second subcase.

    \item \rulenamet{\Sigma}/\rulenamet{\Sigma\mbox{\sf-var}} The proof is similar to the case \rulenamet{App} and \rulenamet{Var}.

    \item \rulenamet{\Sigma\mbox{\sf-Value}} The proof is similar to the case \rulenamet{Value^{\lambda\mapsto{\sf var}}}. \qedhere
  \end{asparaitem}
\end{proof}

The following Lemma will be useful to prove the Correspondence Theorem:
\begin{lemma} \label{lem:tstarproj_eq_tprojplusstar} Let $t$ be a traversal and $r_0$ be an occurrence of a
lambda node $r'$. We have
\begin{equation*}
(t\filterplus r_0)^\star = t^\star \filter \Nodes^{(r')} \filter r_0\enspace .
\end{equation*}
\end{lemma}
\begin{proof}
By the previous Lemma, $t\filterplus r_0$ is indeed a
traversal (of $\tau(M^{(r')})$) thus the expression ``$(t\filterplus
r_0)^\star$'' is well-defined. We show the result by induction on
$t$: It is true for the empty traversal. Take $t=t'\cdot n$.

If $n$ belongs to $\Nodes_@ \union \Nodes_\Sigma$ then
\begin{align*}
((t' \cdot n) \filterplus n_0)^\star &= (t' \filterplus n_0)^\star \cdot
                \left\{
                  \begin{array}{ll}
                    n, & \hbox{if $n$ appears in $t\filterplus n_0$;} \\
                    \epsilon, & \hbox{otherwise.}
                  \end{array}
                \right.
 \\
\mbox{and } ((t' \cdot n)^\star \filter \Nodes^{(r')}) \filter n_0 &=
(t'^\star \filter \Nodes^{(r')}) \filter n_0
\cdot
                \left\{
                  \begin{array}{ll}
                    n, & \hbox{if $n$ is her.\ just.\ by $n_0$ in $t^\star\filter \Nodes^{(r')}$;} \\
                    \epsilon, & \hbox{otherwise.}
                  \end{array}
                \right.
\end{align*}
Since $t^\omega \not\in \Nodes_@ \union \Nodes_\Sigma$, by Lemma
\ref{lem:intfilterstar_iff_hjintstarfiltersubtree} we have that $n$
is hereditarily justified by $n_0$ in $t^\star\filter \Nodes^{(r')}$ if and only if
$n$ appears in $t\filterplus n_0$. Hence we can conclude using the
I.H.\ on $t'$.


If $n$ does not belong to $\Nodes_@ \union \Nodes_\Sigma$ then
\begin{align*}
((t' \cdot n) \filterplus n_0)^\star &= (t' \filterplus n_0)^\star \\
&= (t'^\star \filter \Nodes^{(r')}) \filter n_0 & \mbox{by the I.H.\ on $t'$} \\
&= ((t' \cdot n)^\star \filter \Nodes^{(r')}) \filter n_0  \qedhere
\end{align*}
\end{proof}

Consequently, by Lemma \ref{lem:minus_at_plus_at}, if $t^\omega
\not\in \Nodes_@ \union \Nodes_\Sigma$ then $t \filterplus r_0 =
(t^\star\filter r_0) +\Sigma+@$.



\subsubsection{O-view and P-view projection with respect to root}

\begin{lemma}[O-view projection with respect to the root]
\label{lem:oviewproj_wrt_theroot}
Let $t$ be a non-empty traversal of $M$
and $r$ denote the only occurrence of $\tau(M)$'s root in $t$. If
$t^\omega$ appears in $t\filter r$ then:
$$\oview{t\filter r} = \oview{t}\filter r = \oview{t} \enspace .$$
\end{lemma}
\begin{proof}
It follows immediately from the fact that, by Lemma \ref{lem:trav_oview_single_threaded}, all the occurrences in $\oview{t}$ belong to the same thread and therefore are all hereditarily justified by $r$.
\end{proof}

\begin{lemma}[P-view projection with respect to the root]
\label{lem:pviewproj_wrt_theroot}
Let $t$ be a non-empty traversal of $M$ and $r$ denote the only occurrence of $\tau(M)$'s
root in $t$. If $t^\omega$ appears in $t\filter r$ then:
$$ \pview{t} \filter r \subseqof \pview{t \filter r} \enspace .$$
\end{lemma}
\begin{proof}
We just sketch the proof. We proceed exactly in the same way
as for the proof of Proposition \ref{prop:oview_trav_projection}.
Again we establish an analogy between traversals and plays of game
semantics:
\begin{center}
\begin{tabular}{r|p{6cm}}
{\bf Traversal setting} & {\bf Game-semantic setting} \\
\hline
Traversal $t$ & Play $s$ \\
O-Nodes ($ \LNodes_{\sf var} \union \LNodes_\Sigma \union \LNodes_@\union \INodes_\lambda$) & O-moves $\omove$ \\
P-Nodes ($\INodes_{\sf var} \union \INodes_\Sigma \union \INodes_@ \union \LNodes_\lambda$) or $\diamond$ & P-moves $\pmove$\\
P-view $\pview{t}$  & P-view $\pview{s}$\\
O-view $\oview{t}$  & O-view $\oview{s}$\\
Occurrence $n$ her.\ just.\ by $r$ in $t$ & Occurrence $n \in B$ \\
Occurrence $n$ not her.\ just.\ by $r$ in $t$ & Occurrence $n \in A$ \\
\parbox[t]{6cm}{\raggedleft No notion of initiality (all nodes are considered to be non-initial).} & Distinction between initial and non-initial move.
\end{tabular}
\end{center}
Clearly the conditions (w1) to (w8) hold. Hence we can reuse Proposition 4.3 form \cite{hylandong_pcf} which gives the desired result.
\end{proof}

The previous result gives us only an inequality. In the particular case where interpreted constants are
well-behaved, however, and if we consider the subsequence of a traversal consisting of unanswered nodes only, then we obtain an
equality:
\begin{lemma}
\label{lem:betanf_wellbehavedconst_trav_pview_red} Suppose that $M$
is in $\beta$-normal form and all the $\Sigma$-constants are
well-behaved. Let $t$ be a non-empty traversal of $M$ and $r$ denote
the only occurrence in $t$ of $\tau(M)$'s root.
\begin{enumerate}[(a)]
\item  If $t$'s last
occurrence is not a leaf then
$ \pview{t} \filter r = \pview{?(t) \filter  r } = \pview{?(t \filter  r)}
= ?(\pview{t \filter  r})$;
\item If $t$'s last occurrence is not a leaf and is hereditarily justified by $r$ then $\pview{t} \filter r = \pview{t \filter r}$.
\end{enumerate}
\end{lemma}
\begin{proof}
(a) It is easy to show that $?(t) \filter  r =\ ?(t \filter  r)$. This implies the second equality.
The third equality can be shown by an easy induction and by observing that in a traversal core, variable occurrences are always immediately preceded by a lambda node (and not by a leaf).
We show the first equality by induction. The base case $t=\epsilon$ is trivial. Consider a traversal $t$ and suppose that the property is satisfied for all traversals shorter than $t$. Observe that since $t$ contains at most a single occurrence $r$ of the root
$\theroot$, an occurrence $n$ in $t$ is hereditarily justified by
$r$ if and only if the corresponding node in $\tau(M)$ is
hereditarily enabled by $\theroot$. Thus $t\filter r = t \filter
\INodes^{\theroot \enable}$. We do a case analysis on $t$'s last node:
\begin{itemize}
\item $t^\omega \in \INodes_@$. This case does not happen since $M$ is $\beta$-normal.

\item $t = t' \cdot n$ with $n \in \INodes_{\sf var} \union \INodes_\Sigma$ then $t'^\omega$ is not a leaf (otherwise $n$ would also be a leaf by rule \rulenamet{Value}) thus we can use the I.H.\ on $t'$ which, by an easy calculation, gives the desired equality.
%%%% DETAILS OF THE PROOF
%    \begin{align*}
%    \pview{t} \filter  r
%        &= \pview{t' \cdot n} \filter  r & (\mbox{definition of } t)\\
%        &= \pview{t'} \cdot n \filter  r  & (\mbox{P-view computation}) \\
%        &= \pview{t'} \filter  r  \cdot (n \filter  r)            & (\mbox{def. of projection $\filter$}) \\
%        &= \pview{?(t') \filter r} \cdot (n \filter  r)           & (\mbox{induction hypothesis}) \\
%        &= \pview{?(t') \filter  r \cdot (n \filter  r) } & (\mbox{P-view computation, $n \in \INodes_{\sf var} \union \INodes_{\Sigma}$}) \\
%        &= \pview{(?(t') \cdot n ) \filter  r }           & (\mbox{def. of projection $\filter$}) \\
%        &= \pview{?(t) \filter  r  }
% & (\mbox{definition of } t).
%    \end{align*}
\end{itemize}
Suppose that $t^\omega$ is a lambda node. There are three subcases:
\begin{itemize}
\item $t^\omega \in \INodes^{@\enable}_\lambda$. Since the term is in $\beta$-normal form, there is no
    @-node in $\tau(M)$ so the rules \rulenamet{App} and
    \rulenamet{Var} are unused, hence this case does not happen.

\item $t^\omega \in \INodes^{\INodes_\Sigma\enable}_\lambda$. We have $t = \Pstr{t' \cdot (m){m} \cdot  u \cdot (lmd-m){n}}$ with $n\in \INodes^{\INodes_\Sigma
    \enable}_\lambda$ and $m \in \INodes_{\sf var} \union \INodes_\Sigma$.
    The occurrence $n$ is necessarily visited with a
    \rulenamet{\Sigma}-rule. Since, by assumption, these rules
    are well-behaved we have $?(u) = \epsilon$. Hence:
        \begin{align*}
        \pview{t} \filter  r
        &= \pview{\Pstr{t' \cdot (m){m} \cdot u \cdot (n-m){n}}} \filter  r  & (\mbox{def. of $t$})\\
        &= (\Pstr{\pview{t'} \cdot (m){m} \cdot (lmd-m){n}}) \filter  r & (\mbox{P-view computation}) \\
        &= \pview{t'} \filter  r                & (m, n \not\in \INodes^{\theroot \enable}) \\
        &= \pview{?(t') \filter  r }               & \mbox{(induction hypothesis)} \\
        &= \pview{ ?(\Pstr{t' \cdot (m){m} \cdot (lmd-m){n}}) \filter r }
        & (m, n \not\in \INodes^{\theroot \enable}) \\
        &= \pview{ ?(\Pstr{t' \cdot (m){m} \cdot u \cdot (lmd-m){n}}) \filter r }
        & (?(u)=\epsilon) \\
        &= \pview{ ?(t) \filter r }                & \mbox{(since $u = \epsilon$).}
        \end{align*}

\item $t^\omega \in \INodes^{\theroot\enable}_\lambda$. If $t=r$ then the result holds trivially.
%%%% THE PREVIOUS CASE MUST BE REPLACED BY THE FOLLOWING COMMENTED LINES IF THE CALCULUS
%%%% CONSIDERED ALLOWS THE USE OF THE TENSOR PRODUCT IN THE SYNTAX (in which case the traversals need to be redefined
%%%% to allow the root to be visited several times).
%\item If $t = t' \cdot r$ then we have:
%    \begin{align*}
%    \pview{t} \filter  r
%        &=  r \filter  r                         & (\mbox{def. P-view})\\
%        &=  r                                                & (\mbox{def. operator $\filter$})\\
%        &=  \pview{(t' \filter  r ) \cdot r }    & (\mbox{def. P-view})\\
%        &=  \pview{(t' \cdot r)  \filter  r }    & (\mbox{def. operator $\filter$})\\
%        &= \pview{t \filter  r }                & (\mbox{def. of } t).
%    \end{align*}
Otherwise $t =  \Pstr{t' \cdot (m){m} \cdot u \cdot
(lmd-m){n}}$ for some $n\in
    \INodes^{\theroot \enable}_\lambda$. An easy calculation using the induction hypothesis on $t'\cdot m$ shows the desired equality.
%%%% DETAILS OF THE PROOF:
%%        \begin{align*}
%%        \pview{t} \filter  r
%%        &= \pview{\Pstr{t' \cdot (m){m} \cdot u \cdot (n-m){n}}} \filter  r & (\mbox{definition of } t)\\
%%        &= (\Pstr{\pview{t'} \cdot (m){m} \cdot  (lmd-m){n}} ) \filter  r & (\mbox{P-view computation}) \\
%%        &= \Pstr{\pview{t'} \filter  r \cdot (m){m} \cdot  (lmd-m){n}} & (m, n \in \INodes^{\theroot \enable}) \\
%%        &= \pview{?(t')\filter r}  \cdot \Pstr{(m){m} \cdot  (lmd-m){n}} & \mbox{(induction hypothesis)} \\
%%        &= \pview{ ?(t') \filter r \cdot \Pstr{(m){m} \cdot {(?(u) \filter r)} \cdot (lmd-m,20){n}}}
%%& (\mbox{P-view computation}) \\
%%        &= \pview{ (?(t') \cdot \Pstr{(m){m} \cdot\ {?(u)} \cdot (lmd-m,20){n}}) \filter r }
%%& (m, n \in \INodes^{\theroot \enable}) \\
%%        &= \pview{ ?(t' \cdot \Pstr{(m){m} \cdot u \cdot (lmd-m){n}}) \filter r }
%%& \mbox{($m$ and $n$ are unanswered)} \\
%%        &= \pview{ ?(t) \filter r }                & \mbox{(def. of $t$).}
%%        \end{align*}
\end{itemize}

(b) If $t$'s last occurrence is hereditarily justified by $r$ then the last occurrence of $t\filter r$ is precisely the last occurrence of $t$ and is therefore not a leaf.
In a traversal core, variable nodes are immediately preceded by lambda nodes thus since the last node in $t\filter r$ is not a leaf, an easy induction shows that all the nodes in $\pview{t\filter r}$ are not leaves.
Consequently $?(\pview{t\filter r}) = \pview{t\filter r}$.
\end{proof}

The hypothesis that the term is beta-normal is crucial in this Lemma.
Take for instance the term $\lambda x^o\, f^{(o,o)}.(\lambda y^o . f\, y) x$. A possible traversal is
$$ t = \Pstr[0.7cm]{(lxf){\lambda x f} \cdot (app)@ \cdot (ly-app){\lambda y} \cdot (f-lxf)f \cdot (l1-f)\lambda \cdot (y-ly)y \cdot (l2-app)\lambda \cdot (x-lxf)x } \enspace .$$
But $\pview{t}\filter r = \lambda x f \cdot x$ is only a strict subsequence of
$\pview{t\filter r} = \lambda x f \cdot f \cdot \lambda \cdot x$.

\section{Game semantics correspondence}
\label{sec:gamesemcorresp}

We work in the general setting of an applied
simply-typed lambda calculus with a given set of higher-order
constants $\Sigma$. The operational semantics of these constants is
given by certain reduction rules. We assume that a fully abstract
model of the calculus is provided by means of a category of
well-bracketed games. For instance, if $\Sigma$ consists
of the \pcf\ constants then we work in the
category of games and innocent well-bracketed strategies
\cite{hylandong_pcf,abramsky94full}.
A strategy is commonly defined in the literature as a set of plays closed by
even-length prefixing. For our purpose, however, it is more convenient to represent strategies using \emph{prefix-closed} set of plays. This will spare us some considerations on the parity of traversal length when showing the correspondence between traversals and game semantics.
 For the rest of the section we fix a simply-typed term $\Gamma \entail M :T$. We write $\sem{\Gamma \entail M : T}$ for its strategy denotation (in the standard cartesian closed category of games and innocent strategies \cite{abramsky94full, hylandong_pcf}). We use the notation $\prefset(S)$ to denote the prefix-closure of the set $S$.
\indexnotation{$\prefset(S)$}{Prefix-closure of the set $S$.}%


\subsection{Revealed game semantics}
\label{sec:revealed_semantics}

In standard game semantics, terms are denoted by strategies that are computed
inductively on the structure of the term: calculating the denotation of a term boils down to
performing the composition of strategies denoting some of its subterms. Strategy composition is the CSP-like ``composition + hiding'' operation where all the internal moves are hidden.

It is possible to use an alternative notion of composition where the internal moves are not hidden.
Game model based on such notion of composition have appeared in the literature under the name \emph{revealed
semantics} \cite{willgreenlandthesis} and \emph{interaction semantics} \cite{DBLP:conf/sas/DimovskiGL05}.
In such game models, the denotation is computed inductively on the syntax of the term as in the standard game semantics, but certain internal
moves may be uncovered after composition. There is not just one revealed semantics as one may desire to hide/uncover different internal moves.
%(Moreover, since the denotation is computed inductively on the syntax of the term, the denotation is necessarily sensitive to the syntax and therefore such model cannot provide a full abstraction of the language considered.)
Such semantics will help to establish a correspondence between the game semantics of a term
and the traversals of its computation tree.

This section presents a general setting in which revealed semantics can be defined.
At the end of the section we will provide an example of such an revealed semantics that is
calculated inductively on the syntax of the $\eta$-long normal form of the term.

\subsubsection{Revealed strategies}

\begin{definition}
We consider ordered trees whose leaves are labelled with \pcf\ simple types and inner nodes are labelled with symbols in $\{ ;, \langle \_\ ,\_
\rangle, \Lambda \}$ where `$;$' and `$\langle \_\ ,\_ \rangle$'
are of arity $2$ and `$\Lambda$' is of arity one.
We write $\langle T_1, T_2 \rangle$ for the tree obtained by attaching $T_1$ and $T_2$ to a $\langle \_\ ,\_ \rangle$-node, and similarly
we use the notations $T_1 ; T_2$ and $\Lambda(T_1)$.

The set of \defname{interaction type trees}, or just \defname{interaction types}, is defined inductively as follows:
\begin{itemize}
    \item \emph{Leaf}: If $T$ is a leaf annotated by a type $A$ then $T$ is an interaction type, and we define $type(T)$ to be $A$;

    \item \emph{Currying}: If $T$ is an interaction type with
    $type(T) = A \gameprod B \gamear C$ then
    $\Lambda(T)$ is also an interaction type
    and $type(\Lambda(T)) = A \gamear (B \gamear C)$;

    \item \emph{Pairing}: If $T_1$ and $T_2$ are interaction types with
    $type(T_1) = C \gamear A$ and
    $type(T_2) = C \gamear B$ then
    $\langle T_1 , T_2 \rangle$ is also an interaction type
    and $type(\langle T_1 , T_2 \rangle) = C \gamear A \gameprod B$
    (Pairing generalizes straightforwardly to a $p$-tuple operator $\langle \Sigma_1, \ldots, \Sigma_p \rangle$ for $p\geq2$, in which case the tree has $p$ child subtrees.);

    \item \emph{Composition}: If $T_1$ and $T_2$ are interaction types with     $type(T_1) = A \gamear B$ and $type(T_2) = B \gamear C$
    then $T_1;T_2$ is also an interaction type and
    $type(T_1;T_2) = A \gamear C$.
\end{itemize}
We call $type(T)$ the \defname{underlying type} (or just type) of  the interaction type $T$. We sometimes write $T^A$ to indicate that $type(T) = A$.
\end{definition}

\indexnotation{$\revsem{M}$}{Revealed strategy denotation of a term $M$}%
Let $T$ be an interaction type tree. Each node of type $A$ in $T$
can be mapped to the (standard) game $\sem{A}$. By taking the image
of $T$ across this mapping we obtain a tree whose leaves and nodes
are labelled by games. This tree, written $\revsem{T}$, is called
an \defname{interaction game}.
A \defname{revealed strategy} $\Sigma$ on the interaction game $\revsem{T}$ is a compositions of several standard strategies in which certain internal moves are not hidden. Formally:
\begin{definition}
A \defname{revealed strategy} $\Sigma$ on an interaction game $\revsem{T}$,
written $\Sigma: \revsem{T}$, is an annotated interaction type
tree $T$ where
\begin{itemize}
\item each leaf $\sem{A}$ of $T$ is annotated with a (standard) strategy $\sigma$ on the game
$\sem{A}$;
\item each $;$-node is annotated with two sets of indices $S, P \subseteq \nat$ called respectively the \emph{superficial} and \emph{profound} uncovering indices.
\end{itemize}
\end{definition}

The intuition behind this definition is that if a $;$-node has
children $\Sigma_1 : \revsem{A\gamear B}$ and $\Sigma_2 : \revsem{B\gamear C}$ then the two sets of indices $S, P$ indicate which components of $B$ should be
uncovered when performing composition. The set $S$ indicates which
\defname[move!superficial]{superficial} internal moves (\ie, those that are created by the top-level composition between $\Sigma_1$ and $\Sigma_2$) to uncover; whereas the set $P$ indicates the \defname[move!profound]{profound} internal moves (\ie, those that are already present in the revealed strategies $\Sigma_1$ and $\Sigma_2$) to uncover. This notion of uncovering is made concrete in the next paragraph where we define \emph{revealed strategies} by means of \emph{uncovered positions}.

\begin{example}
The diagrams below represent an interaction type tree $T$ (left),
the corresponding interaction game $\revsem{T}$ (middle) and a
revealed strategy $\Sigma$ (right):
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=6ex,sibling distance=15mm,level 2/.style={sibling distance=20mm}]
\node (root) {$;$}
child {node {$;$}
    child{node{$A\gamear B$}}
    child {node {$B\gamear C$}}
}
child{node{$C\gamear D$}};
\end{tikzpicture}
\hspace{5ex}
\begin{tikzpicture}[baseline=(root.base),level distance=6ex,sibling distance=15mm,
level 2/.style={sibling distance=20mm}]
\node (root) {$;$}
child {node {$;$}
    child {node {$\sem{A\gamear B}$}}
    child {node {$\sem{B\gamear C}$}}
}
child{node{$\sem{C\gamear D}$}};
\end{tikzpicture}
\hspace{5ex}
\begin{tikzpicture}[baseline=(root.base),level distance=6ex,sibling distance=15mm,
level 2/.style={sibling distance=20mm}]
\node (root) {$;^{\{0\},\{0\}}$}
child {node {$;^{\emptyset,\{0\}}$}
    child {node {$(A\gamear B)^{\sigma_1}$}}
    child {node {$(B\gamear C)^{\sigma_2}$}}
}
child{node{$(C\gamear D)^{\sigma_3}$}};
\end{tikzpicture}
\end{center}
\end{example}
For convenience, a revealed strategy will be written as an expression in infix form:
for instance the strategy of the example above is written $\Sigma = (\sigma_1 ;^{\emptyset,\{0\}} \sigma_2) ;^{\{0\},\{0\}} \sigma_3$.

A revealed strategy induces a strategy in the usual sense: the standard strategy $\sigma : A$ \defname{induced} by a reveled strategy $\Sigma : T^{A}$ is obtained by replacing each occurrence of the operator `$;^{S,P}$' for some $S, P$ by `$;^{\emptyset,\emptyset}$' (also abbreviated `;') in the expression of $\Sigma$. For instance the strategy $\Sigma$ from the example above induces the strategy $(\sigma_1 ;\sigma_2) ;\sigma_3 : A \gamear D$.

\subsubsection{Uncovered play}

The analogue of a play in the revealed semantics is called an
\emph{uncovered play} or \emph{uncovered position}; it is a play whose moves are interleaved with internal moves. Each move in such a play may belong to multiple games from different nodes of the interaction game; they are thus implicitly tagged so that one can retrieve the components of the node-games to which the move belongs.

\begin{definition}
The \defname{set of possible moves} $M_T$ of an interaction game
$\revsem{T}$ is defined as $\mathcal{M}_T/\hspace{-0.5em}\sim_T$,
the quotient of the set $\mathcal{M}_T$ by the equivalence relation
$\sim_T \subseteq \mathcal{M}_T \times \mathcal{M}_T$ defined as follows:
For a single leaf tree $T$ labelled by a type $A$ we define
$\mathcal{M}_T = M_A$ and $\sim_T = id_{M_A}$; for other cases:
    \begin{align*}
        \mathcal{M}_{\Lambda(T^{A \gameprod B \gamear C})} &= \mathcal{M}_{T} + M_{A \gamear B \gamear C}
    \\
        \sim_{\Lambda(T^{A \gameprod B \gamear C})} &= \left( \sim_{T}
        \union \left((A \gameprod B \gamear C)
        \leftrightarrow  (A \gamear (B \gamear C))
%        type\ \Lambda(T) \leftrightarrow type\ T
        \right) \right)^=
    \\
    \\
        \mathcal{M}_{\langle T_1^{C^1 \gamear A^1}, T_2^{C^2 \gamear B^2}\rangle}
        &= \mathcal{M}_{T_1} + \mathcal{M}_{T_2} + M_{C \gamear (A \gameprod B)}
    \\
         \sim_{\langle T_1^{C^1 \gamear A^1}, T_2^{C^2 \gamear B^2}\rangle} &= \left( \sim_{T_1}
        \union \sim_{T_2} \union (C^1 \leftrightarrow C) \union (C^2 \leftrightarrow C)
        \union (A^1 \leftrightarrow A) \union (B^2 \leftrightarrow B)
        \right)^=
    \\
    \\
        \mathcal{M}_{T_1^{A \gamear B};T_2^{B \gamear C}} &=
            \mathcal{M}_{T_1} + \mathcal{M}_{T_2} + M_{A\gamear C}
        \\
         \sim_{T_1^{A^1 \gamear B^1};T_2^{B^2 \gamear C^2}} &= \left( \sim_{T_1}
        \union \sim_{T_2} \union (A^1 \leftrightarrow A)
        \union (B^1 \leftrightarrow B^2) \union (C \leftrightarrow C^2)
        \right)^=
    \end{align*}
    where $A\leftrightarrow B$ denotes the canonical bijection between $M_A$ and $M_B$ for two isomorphic games $A$ and $B$; and $R^=$ denotes the smallest equivalence relation containing $R$.
\end{definition}

It is easy to check that for every sub-type tree $T'$ of $T$, the equivalence classes of $M_{T'}$ are subsets of equivalence classes of $M_T$. Thus $M_{T'}$ can be viewed as a subset of $M_T$.

We call \defname{internal move} of the game $\revsem{T}$, any $\sim$-class from $M_T$ that does not contain any move from $M_{type(T)}$. We denote the set of all internal moves by $M_T^{\sf int}$. The complement of $M_T^{\sf int}$ in $M_T$, called the set of \defname{external moves}, is denoted by
$M_T^{\sf ext}$. For every subgame $A$ occurring in some node of the interaction game $T$, we write $M_{T,A}^{\sf int}$ (resp.\ $M_{T,A}^{\sf ext}$) for the subset of moves of $M_T^{\sf int}$ (resp.\ $M_T^{\sf ext}$) consisting of $\sim$-classes containing some move in $M_A$.
\smallskip

A \defname{justified interaction sequence} of moves on the interaction game $\revsem{T}$ is a sequence of moves from $M_T$ together with pointers where each move in the sequence except the first one has a link attached to it pointing to some preceding move in the sequence. We write $J_T$ to denote the set of justified interaction sequences over $\revsem{T}$.


\begin{definition}[Projection]
\label{def:sub_interstrat_projection}
Let $s \in J_T$ for some interaction game $T$. We define the following projection operations:
\begin{enumerate}[(a)]
\item Let $M'$ be a subset of $M_T$. The projection $s \filter M'$ is defined as the subsequence of $s$ consisting of $\sim$-equivalence classes from $M'$;

\item Let $A$ be a sub-game of $\sem{type(T)}$. We define the projection operator $s\filter A$ to be the subsequence of $s$ consisting of the $\sim$-classes that contain some move in $M_A$. Formally
    $s\filter A \defeq s \filter \{ [m] \ | m \in M_A \} $ where $[m]$ denotes the $\sim$-equivalence class of $m$.

\item Let $m$ be a $\sem{type(T)}$-initial move occurring in $s$. We define $s \filter m$ as the subsequence of $s$ consisting of moves that are \emph{hereditarily justified} by that occurrence of $m$ in $s \filter \sem{type(T)}$.
% NOTE: It is important to precise ``in $s \filter \sem{type(T)}$'' because $s$'justification pointers differs depending on the sub-interaction game considered.

\item Let $T'$ be an immediate subtree of $T$. The projection $s\filter T'$ is defined as follows:
    \begin{enumerate}[(i)]
    \item the sequence $s\filter T'$ viewed as a sequence of moves without pointers is defined as $s\filter M_{T'}$ (\ie, the subsequence of $s$ consisting of the $\sim$-equivalence classes that contain some equivalence class of $M_{T'}$; see (a));

    \item the justification pointers of $s\filter T'$ are those of $s$ except that if an element $m$ loses its pointer (\ie, if its justifier does not appear in $s \filter T'$) then its justifier is redefined as the only occurrence of an initial $\sem{type(T')}$-move in $\pview{s \filter M_{T'} \filter \sem{type(T')}}$ (\cf (a) and (b)).
    \end{enumerate}

\item  Let $T'$ be a non-immediate subtree of $T$.
    We define the projection $s\filter T'$ as  $(\ldots (s\filter T^0) \filter \ldots \filter T^{k-1}) \filter T^k$
    where $T^0$, \ldots, $T^k$ is the uniquely defined sequence of subtrees of $T$ satisfying $T=T^0$, $T'=T^k$ and such that for every $1\leq l \leq k$, $T^l$ is an immediate subtree of $T^{l-1}$.

\item Let $T'$ be some subtree of $T$ and $A$ be a sub-game of $\sem{type(T')}$. Then we write $s\filter A$ for $s\filter T' \filter A$.

\end{enumerate}
By extension, we also define these operations on \emph{sets} of justified interaction sequences.
\end{definition}

We now characterize revealed strategies by means of sets of justified sequences of moves called \emph{uncovered positions} or \emph{uncovered plays}.
This set is calculated by a bottom-up computation on the strategy tree. At each ;-node, we apply the composition operation of game semantics. In accordance with standard game semantics, justification pointers are adjusted when composing two interaction strategies $\Sigma_l:T_l^{A\gamear B}$ and $\Sigma_r:T_r^{B\gamear C}$: if an initial A-move $a$ is justified by an initial B-move itself justified by an initial C-move $c$ then $a$'s justifier is set to $c$ (see definition of the projection $\_ \filter A,C$ \cite{abramsky:game-semantics-tutorial}). This guarantees that for every interaction position $u$ of $\Sigma_l ; \Sigma_r$, the subsequence consisting of moves in $A$ and $C$ only---filtering out $B$-moves as well as the internal moves coming from compositions taking place at deeper level in the revealed semantics---is a valid position of the \emph{standard} strategy underlying $\Sigma_l ; \Sigma_r$. In contrast with the standard game semantics, however, not all internal moves are hidden during composition.

\begin{definition}
\label{dfn:revealedstrat}
A revealed strategy $\Sigma$ (defined by means of an annotated type tree) is characterized by its set of \defname{uncovered positions} defined inductively as follows:
\begin{itemize}[-]
\item \emph{Leaf} labelled with type $A$ and annotated by the strategy $\sigma$: The set of positions of the revealed strategy is precisely the set of positions of the standard strategy $\sigma$.

\item \emph{Currying}: Let $\Sigma : \revsem{T}$.
$$\Lambda(\Sigma) = \{ u \in J_{\Lambda(T)} \ |\  \rho(u) \in \Sigma \} \enspace , $$
where $\rho$ denotes the canonical bijection from $M_{\Lambda(T)}$ to $M_T$.

\item \emph{Pairing}: Let $\Sigma_1 : \revsem{T_1}$ and $\Sigma_2 :\revsem{T_2}$.
$$\begin{array}{lcll}
\langle \Sigma_1, \Sigma_2 \rangle  &=\ \{ u \in J_{\langle T_1, T_2 \rangle} \ | &
   (u \filter T_1 \in \Sigma_1 \zand\ u \filter T_2 = \epsilon) \\
&&  \zor\  ( u \filter T_1 = \epsilon \zand u \filter T_2 \in \Sigma_2) \}\enspace .
\end{array} $$

\item \emph{Uncovered composition}: Let $\Sigma_1 : \revsem{T_1}$ and $\Sigma_2 :\revsem{T_2}$ where $type(T_1) = A \gamear B_0 \gameprod
\ldots \gameprod B_l$ and $type(T_2) = B_0 \gameprod \ldots
\gameprod B_l \gamear C$.
\begin{align*}
\Sigma_1 \| \Sigma_2 = \{ u \in J_{T_1;T_2}  \ | \
& \ \ u \filter T_2 \in \Sigma_2 \\
& \zand\ \parbox[t]{8.5cm}{for all occurrence $b$ in $u$ of an initial
                $\sem{type(T_1)}$-move, $u \filter T_1 \filter b \in \Sigma_1$} \\
& \zand\ \parbox[t]{8.5cm}{for every initial $A$-move $a$ justified in $u \filter T_1$ by $b\in B_j$, itself justified by $c \in C$ in $u \filter T_2$, we have that $m$ is justified by $c$ in $u$. \} \enspace .}
\end{align*}

\item \emph{Partially covered composition}: Let $\Sigma_1 : \revsem{T_1}$ and $\Sigma_2 :\revsem{T_2}$ where $type(T_1) = A \gamear B_0 \gameprod
\ldots \gameprod B_l$ and $type(T_2) = B_0 \gameprod \ldots
\gameprod B_l \gamear C$.
\begin{align*}
\Sigma_1\ ;^{S,P}\ \Sigma_2 &= \{ \hide(u,\{0..l\}\setminus S, \{0..l\}\setminus P) \ | \ u \in \Sigma_1 \| \Sigma_2 \} \\
\mbox{ where } \hide(u,S,P) & = u \filter  ( M_T \setminus H(S,P) ) \\
H(S,P) & = \Union_{j\in S} \underbrace{M^{\sf ext}_{T_1,B_j} \union M^{\sf ext}_{T_2,B_j}}_{\hbox{\small superficial $B_j$-moves}}
\union\ \Union_{j\in P} \underbrace{M^{\sf int}_{T_1,B_j} \union M^{\sf int}_{T_2,B_j}}_{\hbox{\small profound $B_j$-moves}} \enspace .
\end{align*}

Observe that in particular $\Sigma_1 \| \Sigma_2 = \Sigma_1;^{\{0..l\},\{0..l\}} \Sigma_2$.
\end{itemize}
\end{definition}
In words, the \emph{uncovered composition}
of $\Sigma_1 \|\ \Sigma_2$ is the set of uncovered plays obtained by performing the usual composition of the standard strategies underlying $\Sigma_1$ and $\Sigma_2$ while preserving the internal moves already in $\Sigma_1$ and $\Sigma_2$ as well as the internal moves produced by the composition itself.

On the other hand, given a product game $B = B_0
\gameprod \ldots \gameprod B_l$,  the \emph{partially covered composition}
$\Sigma_1 ;^{S,P} \Sigma_2$ keeps only the superficial internal moves from the component $B_k$ for $k \in S$ as well as the profound internal moves from the component $B_k$ for $k \in P$.
\smallskip

As expected, this notion of set of uncovered positions is coherent with the usual notion of positions of a standard strategy:
\begin{lemma}
\label{lem:revealed_project_to_induced}
  Let $\Sigma : T$ be a revealed strategy \emph{inducing} the standard strategy $\sigma : \sem{type(T)}$. Then for all $u \in \Sigma$, $u\filter \sem{type(T)} \in \sigma$.
\end{lemma}
\begin{proof}
The proof is by induction on the structure of $\Sigma$. It follows from the fact that the operations on revealed strategies from Def.~\ref{dfn:revealedstrat} are defined identically to their counterparts in the standard game semantics.
\end{proof}

\subsubsection{Fully-revealed and syntactically-revealed semantics}
\label{subsec:syntac_revealedsem}
We call \emph{revealed semantics} any game model of a language in which a term is denoted by some revealed strategy as defined in the previous section. As we have already observed, depending on the internal moves that we wish to hide, we obtain different possible revealed strategies for a given term. Thus there is not a unique way to define a revealed semantics. In this section we give two examples of such semantics.

Let $\pi_i$ denote the $i^{th}$ projection strategy $\pi_i : \sem{X_1 \gameprod
\ldots \gameprod X_l} \gamear \sem{X_i}$.

\begin{definition}[The fully-revealed semantics]
\label{dfn:fully_revealed_semantics}
The \defname{fully-revealed game denotation} of $M$ written $\revsem{\Gamma \entail M : A}$ is defined by structural induction on the \emph{$\eta$-long normal form of $M$}:
\begin{eqnarray*}
\revsem{\Gamma \entail \alpha : o} &=&
\sem{\Gamma \entail \alpha : o} \quad \mbox{where } \alpha \in \Gamma \union \Sigma,\\
\revsem{\Gamma \entail \lambda \overline{\xi} . M  : A} &=& \Lambda^{|\overline{\xi}|}(\revsem{\Gamma, \overline{\xi} \entail M : o })  \\
\revsem{\Gamma  \entail x_i N_1 \ldots N_p :o} &=& \langle \pi_i, \revsem{\Gamma \entail N_1 : A_1}, \ldots, \revsem{\Gamma \entail N_p : A_p}  \rangle \| ev^p, \quad X_i = A_0 \\
\revsem{\Gamma \entail f N_1 \ldots N_p : o} &=& \langle \revsem{\Gamma \entail N_1 : A_1}, \ldots, \revsem{\Gamma \entail N_p : A_p} \rangle\ \|\ \sem{f}, \quad f : A_0 \in \Sigma \\
\revsem{\Gamma \entail N_0 \ldots N_p : o} &=& \langle \revsem{\Gamma \entail N_0 : A_0}, \ldots, \revsem{\Gamma \entail N_p : A_p}  \rangle\ \|\ ev^p
\end{eqnarray*}
where $\Gamma = x_1 : X_1 \ldots x_l : X_l$, $A_0 =
(A_1,\ldots,A_p,o)$ and $ev^p$ denotes the evaluation strategy with
$p$ parameters where $p\geq 1$.
\end{definition}

Fig.~\ref{fig:interaction_strategy_denotations} shows tree representations of the interaction games involved in the revealed strategy $\revsem{\Gamma \entail M : A}$ for the two application cases. These trees give us information about the constituent strategies involved in $\revsem{M}$. For instance the revealed strategy $\revsem{N_0}$ is defined on the interaction game $\revsem{T^{00}}$ whose root game is $A \gamear B_0$, and the strategy $ev$ is defined on the interaction game $\revsem{T^1}$ whose underlying tree is constituted of a single game-node $B_0 \gameprod \ldots \gameprod B_p \gamear o$.

    \begin{figure}[htbp]
       \begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,inner ysep=0.5mm,
level 1/.style={sibling distance=70mm},
level 2/.style={sibling distance=30mm}]
\node (root) {$\revsem{N_0 N_1 \ldots N_p :o}:T [A\gamear o]$}
child {node {$\langle \revsem{N_0}, \ldots, \revsem{N_p} \rangle:T^{0}[A\gamear B_0\gameprod \ldots \gameprod B_p]$}
    child{node {$\revsem{N_0}:T^{00}[A\gamear B_0]$}
       child[child anchor=north,level distance=1ex] {node[isosceles triangle,draw,anchor=north,shape border rotate=90]{\hspace*{20pt}}}
    }
    child {node {$\ldots$}}
    child{node {$\revsem{N_p}:T^{0p}[A\gamear B_p]$}
       child[child anchor=north,level distance=1ex] {node[isosceles triangle,draw,anchor=north,shape border rotate=90]{\hspace*{20pt}}}
    }
}
child{node{$ev:T^1[B_0 \gameprod \ldots \gameprod B_p \gamear o]$}};
\end{tikzpicture}
\bigskip

       \emph{Tree-representation of the revealed strategy $\revsem{\Gamma \entail N_0 N_1 \ldots N_p :o}$.}
       \end{center}
\bigskip

       \begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=7ex,inner ysep=0.5mm,
level 1/.style={sibling distance=60mm},
level 2/.style={sibling distance=35mm}]
\node (root) {$\revsem{x_i N_1 \ldots N_p :o}:T [A\gamear o]$}
child {node {$\langle \revsem{N_0}, \ldots, \revsem{N_p} \rangle:T^{0}[A\gamear B_0\gameprod \ldots \gameprod B_p]$}
    child{node {$\pi_i:T^{00}[A\gamear B_0]$}}
    child{node {$\revsem{N_1}:T^{01}[A\gamear B_1]$}
       child[child anchor=north,level distance=1ex] {node[isosceles triangle,draw,anchor=north,shape border rotate=90]{\hspace*{20pt}}}
    }
    child {node {$\ldots$}}
    child{node {$\revsem{N_p}:T^{0p}[A\gamear B_p]$}
       child[child anchor=north,level distance=1ex] {node[isosceles triangle,draw,anchor=north,shape border rotate=90]{\hspace*{20pt}}}
    }
}
child{node{$ev:T^1[B_0 \gameprod \ldots \gameprod B_p \gamear o]$}};
\end{tikzpicture}
\bigskip

       \emph{Tree-representation of the revealed strategy $\revsem{\overline{x}:\overline{X}\entail x_i N_1 \ldots N_p :o}$.}
       \end{center}
    \bigskip
    {\small
     A node label `$\Pi : T[G]$' indicates that $\Pi$ is a revealed strategy on the interaction
     game $T$ whose top-level game (at the root of the tree underlying $T$) is $G$. Each game is annotated with a string $s \in \{ 0..p \}^*$ in the exponent to indicate the path from the root to the corresponding node in the tree. (The digits in $s$ tell the direction to take at each branch of the tree.)

    The games $A$ and $B$ are given by:
    \begin{eqnarray*}
        A &=& X_1 \gameprod \ldots \gameprod X_n\\
        B &=& \underbrace{((B_1' \gameprod \ldots \gameprod B_p') \gamear o')}_{B_0} \gameprod B_1 \gameprod \ldots \gameprod B_p \enspace .
    \end{eqnarray*}
   }
       \caption{Tree-representation of the revealed strategy in the application case.}
      \label{fig:interaction_strategy_denotations}
    \end{figure}

\begin{example}
Take the term $\lambda x . (\lambda f . f x) (\lambda y . y)$.
Its fully-revealed denotation is $$\Lambda ( \langle \sem{ x:X \entail \lambda f . f
x : (o\typear o) \typear o} , \sem{ x:X \entail \lambda y . y
: o \typear o} \rangle \| ev^2 ) \enspace .$$
\end{example}

Note that the set of fully-revealed strategies does not give rise to a category because strategy composition is not associative and there is no identity interaction strategy.


\begin{definition}[Syntactically-revealed semantics]
\label{dfn:syntactic_revealed_semantics} The \defname{syntactically-revealed game denotation} of $M$ written $\syntrevsem{\Gamma \entail M : A}$ is defined by structural induction on the \emph{$\eta$-long normal form of $M$}. The equations are the same as in Def.~\ref{dfn:fully_revealed_semantics} except for the third case:
\begin{eqnarray*}
\syntrevsem{\Gamma  \entail x_i N_1 \ldots N_p :o} &=& \langle \pi_i, \syntrevsem{\Gamma \entail N_1 : A_1}, \ldots, \syntrevsem{\Gamma \entail N_p : A_p}  \rangle ; ^{\emptyset,\{1..p\}} ev^p, \quad X_i = A_0 \enspace .
\end{eqnarray*}
\end{definition}

The syntactically-revealed denotation differs from the fully-revealed one in that only certain internal moves are preserved during composition: when computing the denotation of an application (joint by an @-node) in the computation tree, all the internal moves are preserved. However when computing the denotation of $\syntrevsem{y_i N_1 \ldots N_p}$ for some variable $y_i$, we only preserve the internal moves of $N_1$, \ldots, $N_p$ while omitting the internal moves produced by the copy-cat projection strategy denoting $y_i$.

\subsubsection{Relating the two revealed denotations}
    \label{subsub:defdelta}

    As one would expect, the two revealed denotations that we have just introduced are in fact equivalent. We now show how $\revsem{\Gamma \entail M : A}$ can be obtained from $\syntrevsem{\Gamma \entail M : A}$ and conversely.

    \paragraph{Fully-uncovered composition versus partially-uncovered composition}

    In this paragraph we relate the fully-uncovered composition `$\|$'
    with the partially-uncovered composition `$;^{\emptyset,\{1..p\}}$' used in the definition of the syntactically-revealed semantics. Take a term $M \equiv x_i N_1 \ldots N_p$.
    Its revealed denotation is given by $\syntrevsem{\Gamma \entail M : o} =  \Sigma_s ;^{\emptyset,\{1..p\}} ev$ where $\Sigma_s = \langle \pi_i, \syntrevsem{\Gamma \entail N_1 : B_1}, \ldots, \syntrevsem{\Gamma \entail N_p : B_p} \rangle$. We use the notations introduced in Fig.~\ref{fig:interaction_strategy_denotations}: the composition takes place on the game
    $$ X_1 \times \ldots \overbrace{((B_1'' \times \ldots \times B_p'') \typear o'')}^{X_i} \ldots \times X_n \stackrel\Sigma\longrightarrow \tikz[baseline=(r.base)]{ \node[draw,dashed](r){$\overbrace{((B_1' \times \ldots \times B_p') \typear o')}^{B_0} \times B_1 \times \ldots \times B_p $};}\stackrel{ev}\longrightarrow o$$
    where the dashed-line frame contains the internal components of the game.

    In $\Sigma_s \| ev$, all the internal moves from $B_k$ for $k\in \{0..p\}$ are preserved, whereas in $\syntrevsem{M}$, the internal $B_0$-moves as well as the superficial internal $B_k$-moves for $k\in \{1..p\}$ are hidden. By definition of the composition operator `$;^{\emptyset,\{1..p\}}$', the set $\syntrevsem{\Gamma \entail M : o}$ is obtained from $\Sigma_s \| ev$ by eliminating the internal $B$-moves appropriately:
     $$ \syntrevsem{\Gamma \entail M : o} = \Sigma_s ;^{\emptyset,\{1..p\}} ev = \{ \hide(u,\emptyset,\{1..p\}) \ | \ u\in \Sigma_s \| ev \} \enspace .$$

    We now show that conversely, there exists a transformation mapping the set $\syntrevsem{\Gamma \entail M : o}$ to $\Sigma_s \| ev$. More precisely we show that for every $u \in \syntrevsem{\Gamma \entail M : o}$, there is a unique play $v$ of $\Sigma_s \| ev$ ending with an external move such that eliminating the superficial internal moves from it gives us back $u$.

    Let us look at the structure of an interaction play of $\Sigma \|  ev$. The state-diagram in Fig.~\ref{fig:flowdiag_moves_interplay_varcase} describes precisely the flow of an interaction play. A node of the diagram indicates the last move that was played. Its label is of the form `$A,\alpha$' where
     $A$ is the game in which the move was played, and $\alpha \in \{\omove,\pmove,\pomove,\opmove\}$ specifies the player that made the move. We use the symbols $\opmove$, $\pomove$, $\omove$, $\pmove$ for OP-move, PO-move, O-move and P-move respectively. We use the notation `$X_i.B''_k$' to denote the sub-component $B''_k$ of the game $X_i$.

     An edge from node $S_1$ to node $S_2$ in the diagram indicates that the move $S_2$ can be played if $S_1$ was the last moved played. It is labelled by the name of the strategy that is responsible of making the move or by `Env.' to denote a move played by the environment (\ie, the opponent in the overall game $\sem{\Gamma\gamear o}$). For instance the edge $B_k,\pomove \stackrel{ev}\longrightarrow B_0,\opmove$ tells us that if $B_k,\pomove$ is the last move played then the evaluation strategy can respond with the move $B_k,\pomove$.
     The game starts at node $C,\omove$ which corresponds to the initial move of the overall game. The dashed-edges correspond to moves played by the copy-cat strategies $\pi_i$ and $ev$.

    We observe that every (superficial) internal move played in some component $B_k$ for $k\in \{0..p\}$ is either a copy of a previous external move, or it is subsequently copied to a external component by the copy-cat strategy $ev$ or $\pi_i$: $\opmove$-moves from $B_0$ are copies by $ev$ of O-moves from $C$ and $\pomove$-moves from $B_k$, $k \in \{1..p\}$; $\pomove$-moves from $B_0$ are copies by $\pi_i$ of O-moves from $X_i$; $\opmove$-moves from $B_k$, $k \in \{1..p\}$ are copies by $ev$ of $\pomove$-moves from the components $B_k'$ of $B_0$; and finally $\pomove$-moves from $B_k$, $k \in \{1..p\}$ are copied into $B_0$.

    Moreover, each move on the diagram of Fig.~\ref{fig:flowdiag_moves_interplay_varcase} has either a single outgoing copy-cat edge---in which case the following move is uniquely determined---or it has multiple out-going edges all labelled by $\Sigma$---in which case the strategy $\Sigma$ determines which moves will be played next.
    Hence for every two consecutive moves in a play of $\syntrevsem{\Gamma \entail M : o}$ we can uniquely recover all the internal moves occurring between the two moves in the corresponding play of $\Sigma_s \| ev$ by following the arrows of the flow diagram.
    This transformation is called the \defname{syntactical uncovering function} with respect to $\Sigma_s$ and $ev$ and is denoted $\curlyvee_{\Sigma,ev} : \Sigma_s ;^{\emptyset,\{1..p\}}ev \rightarrow \Sigma_s \| ev $.
    By definition it satisfies the following property:
    \begin{equation*}
    \hide( \curlyvee_{\Sigma,ev} (u), \emptyset, \{1..p\} ) = u
    \end{equation*}
    for all $u \in \Sigma_s ;^{\emptyset,\{1..p\}} ev$ whose last occurrence is an external move (\ie, in $C$ or $X_i$ for $i\in\{1..n\}$).
    \begin{figure}
   \begin{center}
    \begin{tikzpicture}[->,solid]
    \matrix [matrix of math nodes, column sep=2cm, row sep=12pt]{
          \node(B0_op){B_0, \opmove}; & & & \node(C_o){C, \omove \xlongleftarrow{\mbox{Env.}}}; \\
                      & \node(Xi_p){X_i, \pmove}; \\
                      & \node(XiBk_o){X_i.B_k'', \omove}; & \node(Xio_o){X_i.o'',\omove}; \\[0pt]
          \node(B0Bk_po){B_0.B'_k, \pomove}; & & \node(B0o_po){B_0.o',\pomove}; & \node(C_p){C,\pmove}; \\[0pt]
          \node(Bk_op){B_k,\opmove}; \\
          & \node(Xj_p){{X_j}_{j\neq i},\pmove}; \\
          & \node(Xj_o){{X_j}_{j\neq i},\omove}; \\[0pt]
          \node(Bk_po){B_k,\pomove}; \\
    };
    \draw[dashed](C_o) -- node[above]{$ev$} (B0_op);
    \draw[dashed](B0_op) --node[above]{$\pi_i$} (Xi_p);
    \draw[dashed](XiBk_o) --node[above]{$\pi_i$} (B0Bk_po);
    \draw[dashed](Xio_o) --node[right]{$\pi_i$} (B0o_po);
    \draw[dashed](B0o_po) --node[above]{$ev$} (C_p);
    \draw[dashed](B0Bk_po) --node[right]{$ev$} (Bk_op);
    \draw[dashed](Bk_po)  .. controls +(140:2cm) and +(-140:2cm) .. node[left]{$ev$} (B0_op);
    % non-copy-cat moves
    \draw(Bk_op) -- node[right]{$\Sigma$} (Bk_po);
    \draw(Bk_op) -- node[above]{$\Sigma$} (Xj_p);
    \draw([xshift=5pt]Xj_p.south) --node[right]{Env.} ([xshift=5pt]Xj_o.north);
    \draw([xshift=-5pt]Xj_o.north) --node[left]{$\Sigma$} ([xshift=-5pt]Xj_p.south);
    \draw(Xj_o) -- node[above]{$\Sigma$} (Bk_po);
    \draw(Xj_p) -- node[left]{Env.} (XiBk_o);
    \draw(Xi_p) -- node[left]{Env.} (XiBk_o);
    \draw(Xi_p) -- node[above]{Env.} (Xio_o);
    \draw(Bk_op) .. controls +(150:2cm) and +(180:4cm) .. node[above]{$\Sigma$} (Xi_p);
    \draw[->]([yshift=+3pt]Xj_o.east) .. controls +(35:3cm) and +(-45:2cm) .. node[left]{$\Sigma$} (Xi_p);
    \draw[<-](Xj_o.east) .. controls +(25:3cm) and +(-30:3cm) .. node[right]{Env.} (Xi_p);
    \end{tikzpicture}

    where $k\in\{1..p\}$, $i,j \in \{1..n\}$ and $p\geq 1$.
    \end{center}
    \caption{Flow-diagram for interaction plays of $\revsem{\Gamma \entail x_i N_1 \ldots N_p : o}$.}
    \label{fig:flowdiag_moves_interplay_varcase}
    \end{figure}

    \paragraph{Recovering the fully-revealed semantics from the syntactically-revealed semantics}

    Given a term-in-context $\Gamma \entail M : A$, its syntactically-revealed denotation $\syntrevsem{\Gamma \entail M : A}$ can be obtained from $\revsem{\Gamma \entail M : A}$ by recursively hiding the appropriate internal moves. Conversely, the fully-revealed denotation $\revsem{\Gamma \entail M : A}$ can be obtained from $\syntrevsem{\Gamma \entail M : A}$
    by recursively applying the syntactical-uncovering transformation described in the previous paragraph for every subterm of the form $y_i N_1 \ldots N_p$.

\subsubsection{Revealed semantics versus standard game semantics}
\label{subsec:relating_revealed_and_standard_denotation}

In the standard semantics, given two strategies $\sigma : A
\gamear B$, $\tau : B \gamear C$ and a sequence $s \in
\sigma ; \tau$, it is possible to (uniquely) recover from the sequence $s$ the internal moves that were hidden during composition \cite[part II]{hylandong_pcf}. %This unique uncovering is denoted ${\bf u}(s, \sigma, \tau)$.
The revealed denotation of a term can be recovered from its standard game denotation by
recursively uncovering the internal moves for every application occurring in the term.

Conversely, the standard denotation can be obtained from the revealed denotation by filtering out all the internal moves:
\begin{eqnarray}
 \sem{\Gamma \entail M : T} = \revsem{\Gamma \entail M : T} \filter \sem{\Gamma \gamear T} \enspace . \label{eqn:int_std_gamsem}
\end{eqnarray}
This equality remains valid if we replace the fully revealed denotation by the syntactically-revealed denotation.


Observe that the two sets of plays $\revsem{\Gamma \entail M : T}$ and $\sem{\Gamma \entail M : T}$ are not in bijection.  Indeed, by definition the revealed denotation is prefix-closed therefore it also contains plays ending with an internal move. Thus the revealed denotation contains more plays than the standard denotation. What we can say, however, is that the set of plays $\sem{\Gamma \entail M : T}$ is in bijection with the subset of $\revsem{\Gamma \entail M : T}$ consisting of plays ending with an external move. Furthermore the set of complete plays of $\sem{\Gamma \entail M : T}$ is in bijection with the set of complete interaction plays of $\revsem{\Gamma \entail M : T}$.


\subsubsection{Projection}
The projection operation for justified sequences of moves of an interaction strategies (Def.~\ref{def:sub_interstrat_projection}) proceeds by eliminating some of the moves from the sequence.
In general when projecting a sequence $s \in \Sigma$ on a subtree $T'$, for some subtree $\Sigma' :T'$ of $\Sigma : T$, the resulting sequence is not necessarily an \emph{interaction position} of $\Sigma'$ because some internal moves may be missing from $s$. The following lemma shows that for strategies that are fully-revealed denotations the projection operation generates valid positions of its sub-interaction strategies.

\begin{lemma}[Projection for fully-revealed denotations]
\label{lem:proj_fullyrevealeddenot}
Let $\Sigma:T$ be a fully-revealed denotation (\ie, $\Sigma = \revsem{M}$ for some term $M$).
 Then for every sub-tree $\Sigma':T'$ of $\Sigma : T$ and $u \in \Sigma$:
  \begin{itemize}
  \item if $T'$ is the first subtree of a `;'-node in $T$ then
  for every initial $\sem{type(T')}$-move $b$ occurring in $u$ we have $u \filter T' \filter b \in \Sigma'$;

    \item otherwise ($T'$ is the subtree of a `$\Lambda$'-node, `$\langle \_,\_ \rangle$'-node or the $l^{th}$ subtree of a `;'-node for $l>1$) then $u \filter T' \in \Sigma '$.
  \end{itemize}
\end{lemma}
\begin{proof}
The proof is by induction on the distance between $T'$ and $T$'s root. The sequence $u\filter T'$ equals $u\filter T_0 \filter \ldots \filter T_k$ for some $k\geq 0$ where the $T_i$s are the unique subtrees of $T$ such that $T_0 = T$, $T_k=T'$, and $T_i$ is an immediate subtree of $T_{i-1}$ for $1\leq i \leq k$. Let $\Sigma_i : T_i$ denote the strategy corresponding to each subtree $T_i$ of $T$. We proceed by induction on $k\geq 0$.
The base case is trivial. Step case: Suppose that $v = u\filter T_{k-1} \in \Sigma_{k-1}$.  We do a case analysis on the type of the root node of $\Sigma_{k-1}$. The cases `$\Lambda$' and `$\langle \_,\_ \rangle$' are trivial. The only other possible case is `$\|$' (since $\Sigma$ is a fully-revealed denotation). The result then follows by definition of $\|$ with a subtlety in the case $l=1$:
we have $\Sigma_{k-1} = \Sigma'\|\Sigma_r$, $\Sigma':{T'}^{A\gamear B}$ for some strategy $\Sigma_r:T_r^{B\gamear C}$. When calculating the positions of the composition $\Sigma'\|\Sigma_r$, links going from initial A-moves to initial B-moves in the positions of $\Sigma'$ are changed into links pointing to initial C-moves in $\Sigma'\|\Sigma_r$. Thus in order to obtain a valid position of $\Sigma'$ from $v$ we need to recover the pointers accordingly.
This is precisely what the filtering operation $\_ \filter T'$ does (see Def.~\ref{def:sub_interstrat_projection}): if a move in $v$ loses its pointer in $v\filter M_{T'}$ then its justifier in $v\filter T'$ is set to the only initial move occurring in the P-view $\pview{v \filter M_{T'} \filter \sem{type(T')}}$, which is necessarily $b$.
Hence the justification pointers are properly restored  and $v\filter T' \filter b$ is indeed an uncovered position of $\Sigma'$.
\end{proof}

Together with Lemma \ref{lem:revealed_project_to_induced} this further implies:
\begin{lemma}
\label{lem:proj_fullyrevealeddenot_consequ}
  Let $\Sigma = \revsem{M} : T$.
 For every $u \in \Sigma$ and sub-tree $\Sigma':{T'}$ of $\Sigma : T$ inducing a standard strategy $\sigma' : \sem{type(T')}$:
  \begin{itemize}
      \item if $T'$ is the first subtree of a `;'-node in $T$ then
  for every initial $D$-move $b$ occurring in $u$ we have $u \filter \sem{type(T')} \filter b \in \sigma'$;

    \item otherwise ($T'$ is the subtree of a `$\Lambda$'-node, `$\langle \_,\_ \rangle$'-node or the $l^{th}$ subtree of a `;'-node for $l>1$) then $u \filter \sem{type(T')} \in \sigma'$.
  \end{itemize}
\end{lemma}
\begin{proof}
Follows immediately from Lemma \ref{lem:proj_fullyrevealeddenot} and \ref{lem:revealed_project_to_induced}.
\end{proof}

\begin{lemma}[Well-bracketing]
\label{lem:inter_wellbracket}
Let $\Sigma : T$ be the fully-revealed denotation of some term $M$.
Then for every sub-revealed strategies $\Sigma':T'$ of $\Sigma:T$, the standard strategy $\sigma':\sem{type(T')}$ induced by $\Sigma'$ is well-bracketed.
\end{lemma}
\begin{proof}
The leaves of a fully-revealed denotation are annotated by well-bracketed strategies therefore since well-bracketing is preserved by pairing, currying and composition, all the standard strategies induced by the sub-revealed strategies of $\Sigma$ are also well-bracketed.
\end{proof}

\begin{lemma}[Complete interaction play]
\label{lem:inter_complete}
Let $\Sigma :T$ and $\Sigma_s : T$ denote respectively the fully-revealed strategy and syntactically-revealed denotation of some term (\ie, $\Sigma = \revsem{M}$ and $\Sigma_s = \syntrevsem{M}$ for some term $M$). Then:
\begin{enumerate}[(i)]
\item For every $u \in \Sigma$,
if $u \filter \sem{type(T)}$ is complete (\ie, maximal and all question moves are answered) then so is $u$.

\item For every $u \in \Sigma_s$,
if $u \filter \sem{type(T)}$ is complete then so is $u$.
\end{enumerate}
\end{lemma}
\begin{proof}
(i) We show the contrapositive. If $u$ is not complete
then it contains an answered move $b$. If $b$ is not internal then it appears in $u\filter  \sem{type(T)}$ and therefore  $u\filter \sem{type(T)}$ is not complete. Otherwise, let $\Sigma' : T'$ be the subtree of $\Sigma$ where the internal move $b$ is uncovered: $\Sigma'$ is of the form $\Sigma_1 ;^{S,P} \Sigma_2$ for some $S,P \subseteq \nat$ with $\Sigma_1 : \revsem{T_1^{A\gamear B}}$ and $\Sigma_2 : \revsem{T_2^{B\gamear C}}$, and $b$ belongs to some
uncovered component of $B$ (\ie, whose index is in $S$).

Since $b$ is unanswered in $u$, it is not answered in $u \filter A,B$ and $u \filter B,C$ either; thus the sequences $u\filter A,B$ and $u\filter B,C$ are not complete.
 This further implies that $u\filter A,C$ is not complete (By contradiction: otherwise we would have $u\filter A\gamear C = \Pstr{(q)q\ u'\ (a-q)a }$ for some initial question $q$ and answer $a$; but since $q$ and $a$ both belong to $C$ this implies $u \filter B\gamear C = \Pstr{(q)q \ldots (a-q)a}$).
By Lemma \ref{lem:proj_fullyrevealeddenot_consequ},
$u \filter B\gamear C$ belongs to the standard strategy induced by $\Sigma_2$,
and by Lemma \ref{lem:inter_wellbracket} this strategy is well-bracketed, thus
$u \filter B\gamear C$ is well-bracketed; so since its first question is answered it is necessarily complete.

We have shown that $u \filter \sem{A\gamear C} = u\filter \sem{type(T')}$ is not complete.
We then conclude by observing that if $u\filter \sem{type(T')}$ is not complete for some sub-tree $T'$ of $T$ then $u\filter \sem{type(T)}$ is not complete either. This can be shown by an easy induction on the distance between the root of $T'$ and $T$: The currying and pairing cases are trivial; for the composition case, the argument is similar to the one used in the previous paragraph.

(ii) By applying the syntactical uncovering function on $u$ we obtain
a position $v$ of $\Sigma$ satisfying $u \filter \sem{type(T)} = v \filter \sem{type(T)}$. Hence by (i), $v$ is complete, and therefore so is $u$ (since $u$ is the subsequence of $v$ obtained by recursively hiding internal moves).
\end{proof}


\subsection{Relating computation trees and games}
In this paragraph we relate nodes of the computation tree to moves of the game arena.
First we use an example to explain the insight before giving the formal definition.
\subsubsection{Example}
Consider the following term $M \equiv \lambda f z . (\lambda g x . f (f x)) (\lambda y. y) z$ of type $(o \typear o) \typear o \typear o$.
Its $\eta$-long normal form is $\lambda f z . (\lambda g x . f (f x)) (\lambda y. y) (\lambda .z)$.
The following figure represents side-by-side the computation tree of $M$ (left) and the
arena of the game $\sem{(o \typear o) \typear o \typear o}$ (right):
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,inner ysep=0.5mm,sibling distance=10mm]
\node (root) {$\lambda f z$}
child {node {$@$}
    child {node {$\lambda g x$}
        child {node {$f$}
            child {node {$\lambda$}
                child {node {$f$}
                    child {node {$\lambda$}
                        child {node {$x$}}
                    }
                }
            }
        }
    }
    child {node {$\lambda y$}
           child {node {$y$}}
    }
    child {node {$\lambda$}
           child {node {$z$}}
    }
};
\end{tikzpicture}
\hspace{3cm}
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,inner ysep=0.5mm,sibling distance=8mm]
\node (root) {$q^1$}
child {node {$q^3$}
    child {node {$q^4$}
           child {node {$a_1^4$}}
           child {node {$\ldots$}}
    }
    child {node {$a_1^3$}}
    child {node {$\ldots$}}
    }
child[missing]{}
child[missing]{}
child {node {$q^2$}
       child {node {$a_1^2$}}
       child {node {$a_2^2$}}
       child {node {$\ldots$}}
    }
child {node {$a_1$}}
child {node {$a_2$}}
child {node {$\ldots$}};
\end{tikzpicture}
\end{center}

\newlength{\yNull}
\def\bow{\quad\psarc{->}(0,\yNull){1.5ex}{90}{270}}

Now consider the following partial mapping $\psi$ (represented by a dashed line in the diagram below) from the set of nodes of the computation tree
to the set of moves in the arena: (For simplicity, we now omit answer moves when representing arenas.)
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,inner ysep=0.5mm,sibling distance=15mm]
\path
node (root) {$\lambda f z^{[1]}$}
child{node {$@^{[2]}$}
    child{node {$\lambda g x^{[3]}$}
        child{node (f6) {$f^{[6]}$}
            child{node (l7) {$\lambda^{[7]}$}
                child{node (f8) {$f^{[8]}$}
                    child{node (l9) {$\lambda^{[9]}$}
                        child{node (l10) {$x^{[10]}$}}
                    }
                }
            }
        }
    }
    child {node {$\lambda y^{[4]}$}
           child {node {$y$}}
    }
    child {node {$\lambda^{[5]}$}
           child {node {$z$}}
    }
}
+(5cm,0)
node (q1){$q^1$}
child[level distance=15ex]{node(q3){$q^3$}
    child[level distance=5ex]{node(q4){$q^4$}}
    }
child[level distance=12ex]{node {$q^2$}};
\draw[dashed,->] (f6) -- (q3);
\draw[dashed,->] (f8) -- (q3);
\draw[dashed,->] (l7) -- (q4);
\draw[dashed,->] (l9) -- (q4);
\draw[dashed,->] (root) -- node[above]{$\psi$} (q1);
\end{tikzpicture}
\end{center}

Consider the justified sequence of moves:
 $$s = \Pstr[12pt][5pt]{(q1){q}^1\ (q3-q1,60){q}^3\ (q4-q3,60){q}^4\ (q3b-q1){q}^3\ (q4b-q3b,60){q}^4\ (q2-q1,30){q}^2 }
\in \sem{M} \enspace .$$

Its image by $\psi(r_i)$ gives a justified sequence of nodes of the computation tree:
$$r = \Pstr[0.8cm]{
        (q1){\lambda f z} \cdot
        (q3-q1,60){f}^{[6]} \cdot
        (q4-q3,60){\lambda^{[7]}} \cdot
        (q3b-q1,60){f}^{[8]} \cdot
        (q4b-q3b,50){\lambda^{[9]}} \cdot
        (q2-q1,50){z} }$$
where $s_i = \psi(r_i)$ for all $i < |s|$.

The sequence $r$ is in fact the core of the following
traversal:
$$t = \Pstr[1.1cm]{ (q1){\lambda f z} \cdot
            (n2){@^{[2]}} \cdot (n3-n2,60){\lambda g x^{[3]}} \cdot
            (q3-q1,60){f}^{[6]} \cdot (q4-q3,60){\lambda^{[7]}} \cdot
            (q3b-q1,40){f}^{[8]} \cdot (q4b-q3b,70){\lambda^{[9]}} \cdot
            (n8-n3,35){x^{[10]}} \cdot
            (n9-n2,30){\lambda^{[5]}} \cdot
            (q2-q1,35){z}} \enspace .
$$

This example motivates the next section where we formally define
the mapping $\psi$ for any given simply-typed term.

\subsubsection{Formal definition}

We now establish formally the relationship between games and
computation trees. We assume that a term $\Gamma \entail M : T$ in $\eta$-long
normal form is given.

\begin{notations} We suppose that computation tree $\tau(M)$ is given by
a pair $(\Nodes,E)$ where $\Nodes$ is the set of nodes and $E \subseteq
\Nodes \times \Nodes$ is the parent-child relation. We have $\Nodes = \INodes \union \LNodes$
where $\INodes$ and $\LNodes$ are the set of inner nodes and leaf nodes respectively.
Let $\mathcal{D}$ be the set of values of the base type $o$. If $n$
is an inner node in $\INodes$ then the value-leaves attached to the node $n$ are
written $v_n$ where $v$ ranges in $\mathcal{D}$. Similarly, if $q$
is a question in $A$ then the answer moves enabled by $q$ are
written $v_q$ where $v$ ranges in $\mathcal{D}$.
\end{notations}

\begin{definition}[Mapping from nodes to moves of the standard game semantics]\hfill
\label{def:psi mapping}

    \begin{itemize}
    \item Let $n$ be a node in $\INodes_\lambda \union \INodes_{\sf var}$ and $q$ be a question move of some game $A$
such that $n$ and $q$ are of type $(A_1,\ldots,A_p,o)$ for some
$p\geq 0$. Let $\{ q^1, \ldots, q^p \}$ (resp.\  $\{ v_q \ | \ v \in \mathcal{D} \}$)
be the set of question-moves (resp.\ answer-moves) enabled by $q$ in $A$ (each $q^i$ being of type $A_i$).

We define the function $\psi^{n,q}_A$ from $\Nodes^{n \enable}$---
nodes that are hereditarily enabled by $n$---to moves of $A$ as:
        \begin{eqnarray*}
        \psi^{n,q}_A &=& \{ n \mapsto q \} \union  \{ v_n \mapsto v_q \ | \ v \in \mathcal{D} \}\\
         &&\union \left\{
                        \begin{array}{ll}
                          \Union_{m \in \INodes_{\sf var} | n \enable_i m} \psi^{m, q^i}_A, & \hbox{if $n\in \INodes_{\lambda}$\ ;} \\
                          \Union_{i=1..p} \psi^{n.i, q^i}_A, & \hbox{if $n\in \INodes_{\sf var}$\enspace .}
                        \end{array}
                      \right.
        \end{eqnarray*}

    \item Suppose $\Gamma = x_1:X_1, \ldots ,
    x_k:X_k$. Let $q_0$ denote $\sem{\Gamma\gamear T}$'s
    initial move\footnote{Arenas involved in the game semantics
    of simply-typed lambda calculus are trees: they have
    a single initial move.} and suppose that the set of moves
    enabled by $q_0$ in $\sem{\Gamma\gamear T}$ is
     $\{ q_{x_1}, \ldots, q_{x_k}, q^1, \ldots, q^p \} \union \{
    v_q \ | \ v \in \mathcal{D} \}$ where each $q^i$ is of type
    $A_i$ and $q_{x_j}$ of type $X_j$.

    We define $\psi_M : \Nodes^{\theroot\enable} \rightarrow
    \sem{\Gamma\gamear T}$ (or just $\psi$ if there is
    no ambiguity) as:
    \begin{eqnarray*}
     \psi_M = && \{ r \mapsto q_0 \}  \union  \{ v_r \mapsto v_{q_0} \ | \ v \in \mathcal{D} \}\\
& \union& \Union_{n \in \INodes_{\sf var} | \theroot\enable_i n} \psi^{n, q^i}_\sem{\Gamma\gamear T} \\
& \union& \Union_{n \in \INodes_{\sf fv} | n \mbox{ \small labelled } x_j, j \in \{ 1..k \} } \psi^{n, q_{x_j}}_\sem{\Gamma\gamear T} \enspace .
    \end{eqnarray*}
    \end{itemize}
\end{definition}

It can easily be checked that the domain of definition of $\psi^{n,q}_A$
is indeed the set of nodes that are hereditarily enabled by $n$ and similarly,
the domain of $\psi_M$ is the set of nodes that are hereditarily enabled by
the root (this includes free variable nodes and nodes that are hereditarily enabled by free variable nodes).
Also, if $M$ is closed then we have $\psi_M = \psi^{\theroot,q_0}_{\sem{\gamear T}}$.
\smallskip

The construction of the function $\psi^{n,q}_A$, defined above, goes as follows. Let $p$ be the arity of the type of $n$ and $q$.
\begin{itemize}
\item If $p=0$ then $n$ is a dummy $\lambda$-node or a ground type variable: $\psi^{n,q}_A$ maps $n$ to the initial move $q$.

\item  If $p\geq 1$ and $n \in \INodes_{\lambda}$ with $n$ labelled $\lambda \overline{\xi} = \lambda \xi_1 \ldots \xi_p$ then the sub-computation tree rooted at $n$ and the
 arena $A$ have the following forms (value-leaves and answer
 moves are not represented for simplicity):
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,sibling distance=15mm]
\node (root){$\lambda \overline{\xi}^{[n]}$} child{node{$\alpha$}child{node{}child[dotted]{node{}}}child{node{$\ldots$}}child{node{}child[dotted]{node{}}}}
+(7cm,0)
node (qlx){$q$} child{node{$q^1$} child[dotted]{node{}}child[dotted]{node{}}} child{node{$q^2$}child[dotted]{node{}}child[dotted]{node{}}} child{node{$\ldots $}} child{node{$q^p$}child[dotted]{node{}}child[dotted]{node{}}};
\draw[dashed,->] (root) -- node[fill=white]{$\psi_A^{n,q}$} (qlx) ;
\end{tikzpicture}
\end{center}
    For each abstracted variable $\xi_i$ there exists a
    corresponding question move $q^i$ of the same order in the
    arena. The function $\psi^{n,q}_A$ maps each free occurrence of $\xi_i$
    in the computation tree to the move $q^i$.

\item If $p\geq 1$ and $n\in \INodes_{\sf var}$ then $n$ is labelled with a variable $x:(A_1,\ldots,A_p,o)$
with children nodes $\lambda \overline{\eta}_1$, \ldots,
$\lambda \overline{\eta}_p$. The computation tree $\tau(M)$
rooted at $n$ and the arena $A$ have the following forms:
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,sibling distance=15mm]
\node (root){$x^{[n]}$} child{node{$\lambda\overline\eta_1$}child[dotted]{node{}}}child{node{$\ldots$}}child{node{$\lambda\overline\eta_p$}child[dotted]{node{}}}
+(7cm,0)
node (qlx){$q$} child{node{$q^1$} child[dotted]{node{}}child[dotted]{node{}}} child{node{$q^2$}child[dotted]{node{}}child[dotted]{node{}}} child{node{$\ldots $}} child{node{$q^p$}child[dotted]{node{}}child[dotted]{node{}}};
\draw[dashed,->] (root) -- node[fill=white]{$\psi_A^{n,q}$} (qlx) ;
\end{tikzpicture}
\end{center}
    and $\psi^{n,q}_A$ maps each node $\lambda
    \overline{\eta}_i$ to the question move $q^i$.
\end{itemize}


\begin{example} For each of the following examples of term-in-context $\Gamma \entail M :T$, we represent the
computation tree $\tau(M)$, the arena of the game  $\sem{\Gamma \gamear T}$, and
the function $\psi_M$ (in dashed lines):
\begin{compactitem}
\item $M \equiv \lambda x^o . x$
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,sibling distance=15mm]
\node (root){$\lambda x$} child{node(x){$x$}}
+(5cm,0)
node (qlx){$q_{\lambda x}$} child{node(qx){$q_x$}};
\draw[dashed,->] (root) -- node[fill=white]{$\psi_M$} (qlx) ;
\draw[dashed,->]  (x) -- (qx);
\end{tikzpicture}
\end{center}

\item $M \equiv \lambda f^{(o,o,o)} . f x y$
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,inner ysep=0.5mm,sibling distance=15mm]
\path
node (root){$\lambda f$}
child{node(f){$f$}
 child{node(l1){$\lambda$} child{node(x){$x$}}}
 child{node(l2){$\lambda$} child{node(y){$y$}}}
}
+(6cm,0)
node (qlf){$q_{\lambda f}$}
child{node(qf){$q_f$}
    child{node(qf1){$q_{f_1}$}}
    child{node(qf2){$q_{f_2}$}}
    }
child{node(qx){$q_x$}}
child{node(qy){$q_y$}};
\draw[dashed,->] (root) -- node[fill=white]{$\psi_M$} (qlf);
\draw[dashed,->] (f) -- (qf);
\draw[dashed,->] (l1) .. controls +(-20:1cm) and +(200:1cm) ..  (qf1);
\draw[dashed,->] (l2) .. controls +(-20:1cm) and +(200:1cm) .. (qf2);
\draw[dashed,->] (x) .. controls +(-10:5cm) and +(-90:1cm) .. (qx);
\draw[dashed,->] (y) .. controls +(0:6cm) and +(-90:1cm) ..  (qy);
\end{tikzpicture}
\end{center}


\item $M \equiv \lambda f^{(o,o)} . (\lambda g^{(o,o,o)} . g (f x) z) (\lambda y^o w^o . y)$
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,inner ysep=0.5mm,sibling distance=15mm]
\path
node (root){$\lambda f$}
child{node{$@$}
 child{node(l1){$\lambda g$}
 child{node{$g$} child{node{$\lambda$} child{node(f){$f$}child{node(l){$\lambda$}child{node(x){$x$}}}}}
 child{node{$\lambda$}child{node(z){$z$}}}}
 }
 child{node{$\lambda y w$} child{node{$y$}}}
}
+(6cm,0)
node (qlf){$q_{\lambda f}$}
child{node(qf){$q_f$} child{node(qf1){$q_{f_1}$}}}
child{node(qz){$q_z$}}
child{node(qx){$q_x$}};
\draw[dashed,->] (root) -- node[fill=white]{$\psi_M$} (qlf);
\draw[dashed,->] (f) .. controls +(0:2cm) and +(200:1cm) .. (qf);
\draw[dashed,->] (l) .. controls +(0:2cm) and +(200:1cm) ..  (qf1);
\draw[dashed,->] (x) .. controls +(0:5.5cm) and +(-90:1cm) .. (qx);
\draw[dashed,->] (z) .. controls +(0:3cm) and +(-90:1cm) ..  (qz);
\end{tikzpicture}
\end{center}
\end{compactitem}
\end{example}

\begin{lemma} \
\label{lem:psi_properties}
\begin{enumerate}[(i)]
\item $\psi_M$ maps $\lambda$-nodes to O-questions, variable nodes to
P-questions, value-leaves of $\lambda$-nodes to P-answers and
value-leaves of variable nodes to O-answers;

\item $\psi_M$ preserves hereditary enabling: a node $n \in \Nodes^{\theroot\enable}$ is hereditarily
 enabled by some node $n' \in \Nodes^{\theroot\enable}$ in $\tau(M)$ if and only if
the move $\psi_M(n)$ is hereditarily enabled by $\psi_M(n')$ in $\sem{\Gamma \gamear T}$;

\item $\psi_M$ maps a node of a given order to a move of the same order;

\item Let $s \in \travset(M)^{\filter \theroot}$. The P-view (resp.\ O-view) of $\psi_M(s)$ and $s$ are computed
identically (\ie, the set of positions of occurrences that need to be deleted in order to obtain the P-view (resp.\ O-view) is the same for both sequences).
\end{enumerate}
\end{lemma}
\begin{proof}
(i), (ii) and (iii) are direct consequences of the definition. (iv): Because of (i) and since $t$ and $\psi_M(t)$ have the
same pointers, the computations of the views of the sequence of moves and the views of the sequence of nodes follow the same steps.
\end{proof}
The convention chosen to define the order of the root node (see Def.~\ref{def:nodeorder}) permits us to have property (iii).
This explains why the order of the root node was defined differently from other lambda nodes.
\smallskip

By extension, we can define the function $\psi_M$ on $\travset(M)^{\filter \theroot}$, the set of traversal cores, as follows:
\begin{definition}[Mapping traversal cores to sequences of moves]
The function $\psi_M$ maps
any traversal core $u = u_0 u_1 \ldots \in \travset(M)^{\filter \theroot}$ to
the following justified sequence of moves of the arena $\sem{\Gamma \gamear T}$: $\psi_M(u) = \psi_M(u_0)\ \psi_M(u_1)\  \psi_M(u_2) \ldots$ where $\psi_M(u)$ is equipped with $u$'s pointers.

The pointer-free function underlying $\psi_M$ is thus a monoid homomorphism.
\end{definition}



\subsection{Mapping traversals to interaction plays}

    Let $I$ be the interaction game of the revealed strategy $\syntrevsem{\Gamma \entail M : T}$ and
    $M_I$ be the set of equivalence classes of moves from $\mathcal{M}_I$.

    Let $r'$ be a lambda node in $\INodes_{\sf spawn}$ (the children nodes of @/$\Sigma$-nodes). We write $\Gamma(r') \entail M^{(r')} : T(r')$ to denote the subterm of $\elnf{M}$ rooted at $r'$ (thus $\Gamma(r')\subseteq \Gamma$).
    We consider the function $\psi_{M^{(r')}}$ which maps nodes of $\Nodes^{r'\enable}$
    to moves of $\sem{\Gamma(r') \gamear T(r')}$. Since $\mathcal{M}_I$ contains the
    moves from the standard game $\sem{\Gamma(r') \gamear A(r')}$, we can consider $\psi_{M^{(r')}}$ as a function from $\Nodes^{r'\enable}$ to $\mathcal{M}_I$.

    Every node in $n \in \Nodes\setminus (\Nodes_@ \union \Nodes_\Sigma)$ is either hereditarily enabled by the root or by some $\lambda$-node in $\INodes_{\sf spawn}$. Therefore we can define the following relation $\psi^*_M$ from
    $\Nodes\setminus (\Nodes_@ \union \Nodes_\Sigma)$ to $\mathcal{M}_I$:
    $$ \psi^*_M = \psi_{M} \quad \union \Union_{r' \in \INodes_{\sf spawn}} \psi_{M^{(r')}} \enspace .$$
    This relation is totally defined on $\Nodes\setminus (\Nodes_@ \union \Nodes_\Sigma)$ since those nodes are either hereditarily justified by the root, by an @-node or by a $\Sigma$-node. Moreover it is a relation and \emph{not} a function since for a given variable node $x$,
for every spawn node $r'$ occurring in the path from $x$ to $\theroot$, $x$ is hereditarily enabled by $r'$ \emph{with respect to the computation tree $\tau(M^{(r')})$}. Thus the domains of definition of the relations $\psi_{M^{(r')}}$ for such nodes $r'$ overlap.    It can be easily check, however, that for every node $n \in \Nodes\setminus (\Nodes_@ \union \Nodes_\Sigma)$,
    the moves in $\psi^*_M (n)$ are all $\sim$-equivalent, which leads us to the following definition:

\begin{definition}[Mapping from nodes to moves of the syntactically-revealed semantics]
    \label{def:phi mapping}
    We define the \emph{function}
    $\varphi_M:\Nodes\setminus (\Nodes_@ \union \Nodes_\Sigma) \rightarrow M_I$ as follows: For $n \in \Nodes\setminus (\Nodes_@ \union \Nodes_\Sigma)$, $\varphi_M(n)$ is defined as the $\sim$-equivalence class containing the set $\psi^*_M (n)$. We omit the subscript in $\varphi_M$ if there is no ambiguity.
\end{definition}

\begin{definition}[Mapping sequences of nodes to sequences of moves]
\label{dfn:phi_for_justsequ} We define the function $\varphi_M$ from
$\travset(M)^\star$ to justified sequence of moves in $M_I$
as follows. If $u = u_0 u_1 \ldots \in \travset(M)^\star$ then:
$$\varphi_M(s) = \varphi_M(u_0)\ \varphi_M(u_1)\  \varphi_M(u_2) \ldots$$
where $\varphi_M(u)$ is equipped with $u$'s pointers.
\end{definition}

\begin{example}
Take $M \equiv \lambda x^o . (\lambda g^{(o,o)} . g x z) (\lambda y^o .
y)$. The diagram below represents the computation tree (middle) and
the relation $\psi^*_M = \psi_{\lambda x}\union \psi_{\lambda g. g x}
\union \psi_{\lambda y.y}$ (dashed-lines).
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,inner ysep=0.5mm,sibling distance=12mm]
\path
node (root){$\lambda x$}
child{node{$@$}
 child{node(lg){$\lambda g$}
 child{node(g){$g$} child{node(l1){$\lambda$} child{node(x){$x$}}}
 child{node{$\lambda$}child{node(z){$z$}}}}}
 child{node(ly){$\lambda y$} child{node(y){$y$}}}}
+(6cm,-0.5)
node (qlx){$q_{\lambda x}$}
child{node(qx){$q_x$}}
child{node(qz){$q_z$}}
+(3cm,-1.3cm)
node (qly){$q_{\lambda y}$}
child{node(qy){$q_y$}}
+(-5.5cm,-1cm)
node (qlg){$q_{\lambda g}$}
child{node(qpx){$q'_x$}}
child{node(qpz){$q'_z$}}
child{node(qg){$q_g$} child{node(qg1){$q_{g_1}$}}};
\draw[dashed,->] (root) -- node[fill=white]{$\psi_M$} (qlx);
\draw[dashed,->] (x) .. controls +(-10:5.5cm) and +(-90:1cm) .. (qx);
\draw[dashed,->] (z) .. controls +(0:7cm) and +(-90:1cm) ..  (qz);
\draw[dashed,->] (ly) -- node[fill=white]{$\psi_{\lambda y.y}$} (qly);
\draw[dashed,->] (y) -- (qy);
\draw[dashed,->] (lg) -- node[fill=white]{$\psi_{\lambda g.gx}$} (qlg);
\draw[dashed,->] (g) -- (qg);
\draw[dashed,->] (l1) -- (qg1);
\draw[dashed,->] (x) .. controls +(180:5.5cm) and +(-90:1cm) .. (qpx);
\draw[dashed,->] (z) .. controls +(190:5cm) and +(-90:1cm) ..  (qpz);
\end{tikzpicture}
\end{center}
where $q_x'\sim q_x$, $q_z'\sim q_z$, $q_g\sim q_{\lambda y}$,
$q_{g_1}\sim q_y$ and $q_{\lambda g}\sim q_{\lambda x}$.
\end{example}


\begin{lemma}[Traversal projection lemma]
\label{lem:varphi_proj}
Let $\Delta \entail Q : A$ be a subterm of $\elnf{M}$ and $\theroot_Q$ denote the root lambda node of the subtree of $\tau(M)$ corresponding to the term $Q$. Let $t\in\travset(M)$, $r_0$ be an occurrence of $\theroot_Q$ in $t$ and $m_0$ be the occurrence of the initial $A$-move $\varphi_M(r_0)$ in $\varphi_M(t^\star)$.  Then:
$$
\varphi_{Q}(t^\star \filter \Nodes^{(\theroot_Q)} \filter r_0) = \varphi_M(t^\star) \filter \revsem{\Delta \typear A} \filter m_0 \enspace .
$$
\end{lemma}
\begin{proof}
Firstly we observe that the expression ``$\varphi_{Q}(t^\star \filter \Nodes^{(\theroot_Q)} \filter r_0)$'' is well-defined. Indeed, by Proposition \ref{prop:trav_projection} $t\filterplus r_0$ is a traversal of $\travset(Q)$ therefore the sequence $t^\star \filter \Nodes^{(\theroot_Q)} \filter r_0$, which is equal to $(t\filterplus r_0)^\star$ by Lemma \ref{lem:tstarproj_eq_tprojplusstar}, does belong to $\travset(Q)^\star$.

We now make the assumption that $\theroot_Q$ is a level-$2$ lambda nodes (\ie, a grand-child of the root $\theroot$). The proof easily
generalizes to other lambda nodes by iterating the argument at every lambda nodes occurring in the path from $\theroot_Q$ to $\theroot$.

\emph{Claim:} (i) The set of occurrence positions of $t^\star$ that are removed by the operation $\_ \filter \Nodes^{(\theroot_Q)}$ is the same as the set of positions of $\varphi_M(t^\star)$ removed by the operation  $\_ \filter \revsem{\Delta \typear A }$. (ii) The justification pointers in the sequences of nodes $t^\star \filter \Nodes^{(\theroot_Q)}$ are the same as those
of the sequence of moves $\varphi_M(t^\star) \filter \revsem{\Delta \typear A }$.

Indeed: (i) follows from the fact that, by definition, the range of the function $\varphi_M$ restricted to $\Nodes^{(\theroot_Q)}$ is included in
$M_{\revsem{\Delta \typear A }}$ (the set of moves of the interaction game of $Q$).

(ii) By Def.~\ref{dfn:phi_for_justsequ}, the sequences $\varphi_M(t^\star)$ and $t^\star$ have the same justification pointers.
The projections $\_ \filter \Nodes^{(\theroot_Q)}$
and $\_ \filter \revsem{\Delta \typear A}$ both alter the
pointers in the sequences $\varphi_M(t^\star)$ and $t^\star$, but they do so identically: the operation $\_ \filter \Nodes^{(\theroot_Q)}$ (Def.~\ref{def:subterm_trav_projection}) alters pointers only for variable nodes that are free in $\Nodes^{(\theroot_Q)}$; it makes them point to
the only occurrence of $\theroot_Q$ in the P-view at that point (which is also the only occurrence of a level-2 lambda node in the P-view).
Similarly, the operation $\_ \filter \revsem{\Delta \typear A}$ (Def.~\ref{def:sub_interstrat_projection}) alters pointers only for initial A-moves: it makes them point to the only occurrence of an initial B-move in  the P-view at that point. Further $\varphi_M$ maps free variables in $\Nodes^{(\theroot_Q)}$ to initial A-moves, and level-2 lambda nodes to initial B-moves.

Hence the claim holds which subsequently implies
$\varphi_M(t^\star) \filter \revsem{\Delta \typear A} = \varphi_M(t^\star \filter \Nodes^{(\theroot_Q)})$.
Thus $\varphi_M(t^\star) \filter \revsem{\Delta \typear A} \filter m_0 = \varphi_M(t^\star \filter \Nodes^{(\theroot_Q)}) \filter m_0
= \varphi_M(t^\star \filter \Nodes^{(\theroot_Q)} \filter r_0)$.
Finally, since the function $\varphi$ is defined inductively on the structure of the computation tree, the restriction of $\varphi_M$ to $\Nodes^{\theroot_Q}$ coincides with $\varphi_Q$.
\end{proof}

The following lemma states that projecting the image of a traversal by $\varphi$ gives the image of the traversal's core:
\begin{lemma}[Core projection lemma]
\label{lem:core_projection}
$$ \varphi_M(\travset(M)^\star) \filter \sem{\Gamma \gamear T} = \psi_M(\travset(M)^{\filter \theroot}) \enspace . $$
\end{lemma}
\begin{proof}
Let $H$ be the set of nodes of $\tau(M)$ which are mapped by
$\psi^*(M)$ to moves that are $\sim$-equivalent to moves in
$\sem{\Gamma \gamear T}$. We need to show that $H = \Nodes^{\theroot\enable}$.

Since $\psi_M \subseteq \psi^*(M)$ and the image of $\psi(M)$ is
$\sem{\Gamma \gamear T}$, $H$ must contain the domain of
$\psi(M)$ which is precisely $\Nodes^{\theroot\enable}$. Conversely, suppose that a node $n \in \Nodes\setminus (\Nodes_@\union \Nodes_\Sigma)$ is mapped by
$\varphi^*(M)$ to some move $m\in \mathcal{M}_I$ which is $\sim$-equivalent
to some move in $\sem{\Gamma \gamear T}$.
 If $m = \psi_M(n)$ then $n\in \Nodes^{\theroot\enable}$. Otherwise,
$m = \psi_{M^{(\odot)}}(n)$ for some $\odot \in \INodes_{\sf spawn}$. There
may be several nodes $\odot$ such that $n$ belongs to the domain of
definition of $\psi_{M^{(\odot)}}$, w.l.o.g.\ we can take $\odot$ to be
the one which is closest to the root. Let $\Gamma(\odot) \entail
M^{(\odot)} : T(\odot)$. Suppose that $m$ is $\sim$-equivalent to a move from
    \begin{compactitem}[-]
    \item the subgame $\sem{\Gamma}$ of $\sem{\Gamma \gamear T}$,
    then this means that $n$ is hereditarily justified by a free variable node in $M$ and therefore $n \in \Nodes^{\theroot\enable}$.

    \item the subgame $\sem{T}$ of $\sem{\Gamma \gamear T}$
    then $m$ must belong to the subgame $\Gamma(\odot)$ of $\sem{\Gamma(\odot)\gamear T(\odot)}$.
    Indeed, since $\odot$'s parent node is an application node, moves in the subgame $\sem{T(\odot)}$ correspond to internal moves of the application. By definition of
    the interaction strategy for the application case, such moves can only be $\sim$-equivalent to other internal  moves and thus cannot be equivalent to a move from $\sem{T}$.

    Consequently, $n$ is hereditarily justified by a free variable node $z$ in $M^{(\odot)}$. By assumption, $\odot$ is the closest node to the root $\theroot$ (excluding $\theroot$ itself) for which $n$ belongs to $\Nodes^{\odot\enable}$ (the domain of definition of $\psi_{M^{(\odot)}}$). Hence $z$ is not bound by any $\lambda$-node occurring in the path to the root. Thus $z\in
    \Nodes^{\theroot\enable}$ and therefore $n \in \Nodes^{\theroot\enable}$.
    \end{compactitem}
Hence $H = \Nodes^{\theroot\enable}$. Consequently, for every traversal $t$
we have $\varphi_M(t^\star) \filter \sem{\Gamma \gamear T} = \varphi_M(t^\star\filter \Nodes^{\theroot\enable})$ which equals
$\varphi_M(t\filter \theroot)$ by Lemma
\ref{lem:he_proj_root_is_hj_proj_r}.
\end{proof}

\subsection{The correspondence theorem for the pure simply-typed lambda calculus}
In this section, we establish a connection between the revealed
semantics of a simply-typed term without interpreted constants (\ie, $\Sigma = \emptyset$) and the traversals of its computation tree: we show that the set $\travset(M)$ of traversals of the computation tree is
isomorphic to the set of uncovered plays of the strategy denotation
(this is the counterpart of Ong's ``Path-Traversal Correspondence'' Theorem
\cite{OngLics2006}), and that the set of traversal cores is
isomorphic to the strategy denotation.


\subsubsection*{Preliminary lemmas}

\begin{notation} For every node occurrence $n$ in a justified sequence
(of nodes or of moves) $u$ we write $\ptrdist_u(n)$, or just
$\ptrdist(n)$ if there is no ambiguity, to denote the distance
between $n$ and its justifier in $u$ if it has one, and $0$
otherwise.
\end{notation}

\begin{lemma}
\label{lem:varphiinjective:prelem}
\begin{equation*}
\left(
  \begin{array}{ll}
    t \cdot n_1, t \cdot n_2 \in \travset(M) \\
    \zand\ n_1 \neq n_2
  \end{array}
\right)
 \implies n_1,n_2 \in \Nodes^{\theroot\enable}_{\lambda} \zand ( \psi(n_1) \neq \psi(n_2) \zor \ptrdist(n_1) \neq \ptrdist(n_2) ) \ .
 \end{equation*}
\end{lemma}
\begin{proof} Take $t \cdot n_1, t \cdot n_2 \in \travset(M)$. Suppose that
$n_1$ and $n_2$ belong to two distinct categories of nodes ($\INodes_{\sf var}$, $\INodes_@$, $\INodes_\lambda$, $\INodes_\Sigma$, $\LNodes_{\sf var}$, $\LNodes_@$, $\LNodes_\lambda$, or $\LNodes_\Sigma$)
then necessarily one must be visited with the rule
\rulenamet{InputVar} and the other by \rulenamet{InputVal}---they are
the only rules with a common domain of definition---thus one is
a leaf-node and the other is an inner node which implies that
$\psi(n_1) \neq \psi(n_2)$.

Otherwise $n_1$ and $n_2$ belong to the same category of nodes and we proceed by case analysis:
\begin{compactitem}
\item If $n_1, n_2 \in \INodes_@$ then $t
\cdot n_1$ and $t \cdot n_2$ are formed using the \rulenamet{App}
rule. Since this rule is deterministic we must have $n_1=n_2$ which
violates the second hypothesis.

\item If $n_1, n_2 \in \LNodes_@$ then the traversals are formed using the deterministic rule
\rulenamet{Value^{@\mapsto\lambda}} which again violates the
second hypothesis.

\item If $n_1, n_2 \in \INodes_\Sigma$ then they are formed using a deterministic constant rule (see Def.~\ref{def:constant_traversal}).

\item If $n_1, n_2 \in \LNodes_\Sigma$  then they are formed using a deterministic value-constant rule.

\item If $n_1,n_2\in \INodes_{\sf var}$ then
     $t \cdot n_1$ and $t \cdot n_2$ were formed using either rule \rulenamet{Lam} or \rulenamet{App}.
     But these two rules are deterministic and their domains of definition are disjoint. Hence again the second
     hypothesis is violated.

\item If  $n_1, n_2 \in \LNodes_{\sf var}$ then either the traversals were both formed using the deterministic rule
\rulenamet{Value^{{\sf var}\mapsto\lambda}} in which case the
second hypothesis is violated; or they were formed with
\rulenamet{InputValue} in which case $n_1$ and $n_2$ are two
different value leaves belonging to $\Nodes^{\theroot\enable}_\lambda$ and
justified by the same input variable node. Thus by definition of
$\psi$, $\psi(n_1)\neq\psi(n_2)$.

\item If  $n_1,n_2\in \INodes_\lambda$ then the traversals $t \cdot n_1$
    and $t \cdot n_2$ must have been formed using either rule
    \rulenamet{Root}, \rulenamet{App}, \rulenamet{Var} or \rulenamet{InputVar}. Since all these rules have
    disjoint domains of definition, the same rule must have been use to
    form $t \cdot n_1$ and $t \cdot n_2$.
    But since the rules \rulenamet{Root}, \rulenamet{App} and \rulenamet{Var} are all deterministic,
    the rule used is necessarily \rulenamet{InputVar}.

    By definition of \rulenamet{InputVar}, $n_1,n_2\in \INodes_\lambda^{\theroot\enable}$, the parent node of $n_1$ and the parent node of $n_2$ all occur in  $\oview{t_{\prefixof x}}$ where $x \in \INodes^{\theroot\enable}_{\sf var}$
    denotes the pending node at $t$. If $n_1$ and $n_2$ have the same
    parent node in $\tau(M)$ then since $n_1\neq n_2$, by definition of
    $\psi$, $\psi(n_1)\neq \psi(n_2)$. If their parent node is
    different, then $n_1$ and $n_2$ are necessarily justified by two different
    occurrences in $t$ therefore $\ptrdist(n_1) \neq \ptrdist(n_2)$.

\item If  $n_1,n_2\in \LNodes_\lambda$ then either the traversals $t \cdot n_1$
    and $t \cdot n_2$ were formed using
    \rulenamet{Value^{\lambda\mapsto{\sf var}}} or they were formed with
    \rulenamet{Value^{\lambda\mapsto @}} but this is impossible since these two rules are
    deterministic and $n_1 \neq n_2$. \qedhere
\end{compactitem}
\end{proof}




The function $\varphi_M$ regarded as a function from the set of
nodes $\Nodes \setminus \Nodes_@$ of the computation tree to moves in
arenas is not injective. (For instance the two occurrences of $x$ in
the computation tree of $\lambda f x. f x x$ are mapped to the same
question move.) However the function $\varphi_M$ defined on the set
of @-free traversals is injective, and similarly the function
$\psi_M$ defined on the set of traversal cores is injective as the following lemma shows:

\begin{lemma}[$\psi_M$ and $\varphi_M$ are injective]
\label{lem:varphiinjective}
For every two traversals $t_1$ and $t_2$:
\begin{itemize}
\item[(i)] If $\varphi (t_1^\star) = \varphi (t_2^\star)$ then $t_1^\star =t_2^\star$\ ;
\item[(ii)] if $\psi (t_1 \filter \theroot ) = \psi (t_2 \filter \theroot )$ then $t_1\filter \theroot = t_2\filter \theroot$\enspace .
\end{itemize}
\end{lemma}
\begin{proof} \noindent (i) The result is trivial if either $t_1$ or $t_2$
is empty. Otherwise, suppose that $t_1^\star\neq t_2^\star$ then
necessarily $t_1 \neq t_2$. W.l.o.g.\ we can assume that the two
traversals differ only by their last node (or last node's pointer).
Thus we have $t_1 = t \cdot n_1$ and $t_2 = t \cdot n_2$ for some
sequence $t$ and some occurrences $n_1, n_2$ where either $n_1$ and
$n_2$ are two distinct nodes in the computation tree or
$\ptrdist(n_1) \neq \ptrdist(n_2)$.

If $n_1 = n_2$ and $\ptrdist(n_1) \neq \ptrdist(n_2)$ then $n_1,n_2$
are not @-nodes nor $\Sigma$-nodes (since for such nodes we would
have $\ptrdist(n_1) = 0 = \ptrdist(n_2)$). By definition of the
sequence $\varphi(t_1)$ we have $\ptrdist(\varphi(n_1)) =
\ptrdist(n_1)$ and similarly $\ptrdist(\varphi(n_2)) =
\ptrdist(n_2)$ thus $\varphi(t' \cdot n_1) \neq \varphi(t' \cdot
n_2)$. Finally since $n_1,n_2 \not\in (\INodes_@ \union \INodes_\Sigma)$ we also
have $\varphi((t' \cdot n_1)^\star) \neq \varphi((t' \cdot
n_2)^\star)$. Hence $\varphi(t_1^\star) \neq \varphi(t_2^\star)$.

If $n_1 \neq n_2$ then by Lemma \ref{lem:varphiinjective:prelem}
$n_1,n_2$ are not @-nodes or $\Sigma$-nodes (since such nodes are
not hereditarily justified by the root) and we have either $\ptrdist(n_1) \neq
\ptrdist(n_2)$ or $\varphi(n_1) = \psi(n_1) \neq \psi(n_2) =
\varphi(n_2)$. Hence $\varphi(t_1^\star) \neq
\varphi(t_2^\star)$.
\smallskip

\noindent (ii) Suppose that $t_1 \filter \theroot \neq t_2 \filter \theroot$ then
necessarily $t_1 \neq t_2$. W.l.o.g.\ we can assume that the two
sequences differ only by their last occurrence. Hence we have $t_1 =
t \cdot n_1$, $t_2 = t' \cdot n_2$ for some sequence $t$ and some
nodes $n_1, n_2$ where either $n_1\neq n_2$ or $\ptrdist(n_1) \neq
\ptrdist(n_2)$.

If $n_1 \neq n_2$ then Lemma \ref{lem:varphiinjective:prelem} gives
$\psi( t_1\filter \theroot ) \neq \psi( t_2\filter \theroot )$.
Otherwise $n_1 = n_2$ and $\ptrdist(n_1) \neq \ptrdist(n_2)$.
The only rules that can visit the same node with two different pointers are \rulenamet{InputVar} and \rulenamet{InputValue}, thus $n_1$
and $n_2$ must be in $\Nodes_\lambda^{\theroot\enable}$. Hence:
\begin{equation*}
\psi(t_i\filter \theroot) = \psi(t\filter \theroot) \cdot \psi(n_i) \mbox{ for $i
\in \{1..2\}$}
\end{equation*}
where $\ptrdist_{\psi(t_i\filter r)}(\psi(n_i)) =
\ptrdist_{t_i\filter r}(n_i)$.

Furthermore, since $\ptrdist(n_1) \neq \ptrdist(n_2)$ and
${t_1}_{<n_1} = {t_2}_{<n_2}$ we have $\ptrdist_{t_1\filter \theroot}(n_1)
\neq \ptrdist_{t_2\filter \theroot}(n_2)$. Thus $\psi(t_1\filter \theroot) \neq
\psi(t_2\filter \theroot)$.
\end{proof}


\begin{corollary} \hfill
\label{cor:varphi_bij}
\begin{itemize}
\item[(i)] $\varphi$ defines a bijection from $\travset(M)^\star$
to $\varphi(\travset(M)^\star)$\ ;
\item[(ii)] $\psi$ defines a bijection from $\travset(M)^{\filter \theroot}$ to
$\psi(\travset(M)^{\filter \theroot})$\enspace .
\end{itemize}
\end{corollary}
\bigskip


The following lemma says that extending a traversal locally also extends the
traversal globally: the traversal $t$ of $M$ can be extended by
extending a sub-traversal $t'$ of some subterm of $M$. This is
not obvious since $t'$ is a subsequence of $t$ which means that the
nodes in $t'$ are also present in $t$ with the same pointers but
with some other nodes interleaved in between. However these
interleaved nodes are inserted in a way that allows us
to apply on $t$ the rule that was used to extend the sub-traversal $t'$:
\begin{lemma}[Sub-traversal progression]
\label{lem:subtraversal_progression} Let $\theroot_j$ be a lambda node in $\tau(M)$,
$t = t' \cdot t^\omega$ be a justified sequence of nodes of $\tau(M)$, and $r_j$ be an occurrence of $\theroot_j$ in $t$ different from $t^\omega$.
If
\begin{enumerate}[1.]
\item $t'$ is a traversal of $\tau(M)$,
\item $t^\omega$ appears in $t\filterplus r_j$,
\item $t \filterplus r_j$ is a traversal of $\tau(M^{(\theroot_j)})$ and its last node is visited using a rule different from \rulenamet{InputVar} and $\rulename{InputVar^{val}}$,
\end{enumerate}
then $t$ is a traversal of $\tau(M)$.
\end{lemma}
\begin{proof}
Let $t_j = t \filterplus r_j$. Since $t'$ is a traversal of
$M$, by Prop.~\ref{prop:trav_projection} the sequence $t' \filterplus r_j$ (which is also the immediate prefix of $t_j$) is a traversal of $\tau(M^{(\theroot_j)})$.
  We proceed by case analysis on the last rule used to produce the traversal $t_j$ and we show that $t$ is a traversal of $M$:
  \begin{asparaitem}
    \item \rulenamet{Empty}, \rulenamet{Root}. These cases do not occur since $|t_j| \geq 2$. Indeed, $t_j$ contains at least $t^\omega$ and $r_j$ which are two different occurrences.

    \item \rulenamet{Lam}
        We have  $t_j = \ldots \cdot \lambda \overline{\xi} \cdot n$. Since $t_j \subseqof t$, the node $\lambda \overline{\xi}$ also occurs in $t$.
        Therefore using the rule \rulenamet{Lam} in $M$ we can form the traversal
        $t_{\prefixof \lambda \overline{\xi}} \cdot n$. But then we have $(t_{\prefixof \lambda \overline{\xi}} \cdot n) \filterplus r_j =
        t_{\prefixof \lambda \overline{\xi}} \filterplus r_j \cdot n
        = {t_j}_{\prefixof \lambda \overline{\xi}} \cdot n = t_j = t \filterplus r_j$.
        Thus, since $t$'s last node and $n$ both appear in $t\filterplus r_j$, this implies that
         $t_{\prefixof \lambda \overline{\xi}} \cdot n = t$.
        Hence $t$ is a traversal of $M$.

    \item \rulenamet{App} $t_j = \ldots \cdot \lambda \overline{\xi} \cdot @ \cdot n$.
    The same reasoning as in the previous case permits us to conclude.


    \item \rulenamet{Value^{@\mapsto\lambda}} \Pstr[0.6cm]{t_j = \ldots \cdot (lmd){\lambda
        \overline{\xi}} \cdot (x){@}  \ldots  (xv-x,50:v){v}_@  \cdot
        (lmdv-lmd,30:v){v}_{\lambda \overline{\xi}} }. Since $t_j\subseqof t$, the nodes
    $\lambda \overline{\xi}$, $@$, $v_@$ and $v_{\lambda \overline{\xi}}$
    all appear in $t$. Moreover, since $\lambda \overline{\xi}$ is a lambda node
    appearing in $t\filterplus r_j$, its immediate successor must also appear in
    $t\filterplus r_j$. Thus the two nodes $\lambda \overline{\xi}$ and $@$ are also consecutive in $t$. Hence
    we can use the rule \rulenamet{Value^{@\mapsto\lambda}} in the computation tree $\tau(M)$ to produce
    the traversal $t_{\prefixof v_{\lambda \overline{\xi}}} \cdot n$ and by the same reasoning as in the previous case, we
    conclude that necessarily $t = t_{\prefixof v_{\lambda \overline{\xi}}} \cdot n$.

    \item \rulenamet{Value^{{\sf var}\mapsto\lambda}} \Pstr[0.6cm]{t_j = \ldots \cdot (lmd){\lambda
    \overline{\xi}} \cdot (x){x}  \ldots  (xv-x,50:v){v}_x  \cdot
    (lmdv-lmd,30:v){v}_{\lambda \overline{\xi}} }. This case is identical to the previous case.

    \item \rulenamet{Value^{\lambda\mapsto @}}
          \Pstr[0.7cm]{t_j = \ldots \cdot (app){@} \cdot
        (lz-app,60){\lambda \overline{z}} \ldots
        (lzv-lz,60:v){v}_{\lambda \overline{z}} \cdot
        (appv-app,45:v){v}_@}. Same as in the previous case by observing that @ and $\lambda \overline{z}$
are necessarily consecutive in $t$.

    \item \rulenamet{InputValue} and \rulenamet{InputVar}. By assumption these cases do not happen.

    \item \rulenamet{Var}
    \Pstr[0.7cm]{ t_j = \ldots \cdot (p){p} \cdot (lx){\lambda
        \overline{x}} \ldots (x-lx,30:i){x_i}  \cdot
        (letai-p,40:i){\lambda \overline{\eta_i}} } for some
        variable $x_i \in \INodes_{\sf var}^{@\enable}$.

In general, two nodes $p$ and $\lambda \overline{x}$ appearing consecutively in $t_j$ are not necessarily consecutive in $t$. For in $M$, $t$ can ``jump'' from $p$ to a node that do not belong to the subterm $M^{(\theroot_j)}$, and thus not appearing in $t_j = t\filterplus r_j$.
This situation cannot happen here, however. Indeed, suppose that $t_{\prefixof p}$ extends to $t_{\prefixof p} \cdot m$ in $\tau(M)$.
 All the nodes in the thread of $\lambda \overline{\eta_i}$, in
$t_j$, are hereditarily justified by the same initial @-node $\alpha$
which necessarily occurs after $r_j$ (the first node of $t_j$).
Consequently $p$ belongs to $\INodes_{\sf var}^{@\enable}$ and
therefore the traversal $t_{\prefixof p}\cdot m$ must have been
formed using the rule \rulenamet{Var} in $\tau(M)$. Since $p$
appears in $t\filterplus r_j$, by Lemma
\ref{lem:thread_projplus}(i), all the nodes in the thread of $p$
in $t$ appear in $t\filterplus r_j$. Thus $m$ appears in
$t\filterplus r_j$ (since by O-visibility it points in the
thread of $p$). Hence $(t_{\prefixof p} \cdot m)\filterplus r_0
=  t_{<p}\filterplus r_0 \cdot p \cdot m$ which implies that $m$
is precisely the occurrence $\lambda \overline{x}$.

Hence the nodes $p$, $\lambda \overline{x}$, $x_i$ and $\lambda \overline{\eta_i}$ all appear in $t$
with the two nodes $p$ and $\lambda \overline{x}$ appearing consecutively. We can therefore use the rule \rulenamet{Var} in $M$ to form the traversal $t$.

    \item \rulenamet{Value^{\lambda\mapsto{\sf var}}} Same proof as in the previous case.
    \item \rulenamet{\Sigma}/\rulenamet{\Sigma\mbox{\sf-var}} Same as \rulenamet{App} and \rulenamet{Var}.
    \item \rulenamet{\Sigma\mbox{\sf-Value}} Same as  \rulenamet{Value^{\lambda\mapsto{\sf var}}}.
\qedhere
  \end{asparaitem}
\end{proof}

\subsubsection*{The correspondence theorem}

We now state and prove the correspondence theorem for the
simply-typed lambda calculus without interpreted constants
($\Sigma = \emptyset$). This theorem establishes a correspondence between the denotation of a term in the \emph{intensional} game model and the set of traversals of its computation tree. The result extends immediately to the
simply-typed lambda calculus with \emph{uninterpreted} constants since we can regard constants as being free variables.

\begin{theorem}[The Correspondence Theorem]
\label{thm:correspondence}
 For every simply-typed term $\Gamma \entail M :T$,
$\varphi_M$ defines a bijection from $\travset(M)^\star$ to $\syntrevsem{\Gamma \entail M : T}$ and $\psi_M$ defines a bijection from $\travset(M)^{\filter
\theroot}$ to $\sem{\Gamma \entail M : T}$:
\begin{eqnarray*}
 \varphi_M  &:& \travset(\Gamma \entail M : T)^\star \stackrel{\cong}{\longrightarrow} \syntrevsem{\Gamma \entail M :T} \\
 \psi_M  &:& \travset(\Gamma \entail M : T)^{\filter \theroot} \stackrel{\cong}{\longrightarrow} \sem{\Gamma \entail M :T} \enspace .
\end{eqnarray*}
\end{theorem}

\begin{remark}
\label{rem:corresp_proofcore}
    By Corollary \ref{cor:varphi_bij}, we just need to show that
    $\varphi_M$ and $\psi_M$ are \emph{surjective}, that is to
    say: $\varphi_M(\travset(M)^\star) = \syntrevsem{\Gamma \entail M : T}$
    and $\psi_M(\travset(M)^{\filter \theroot}) = \sem{\Gamma \entail M : T}$.
    Moreover the former implies the latter, indeed:
    \begin{align*}
    \sem{\Gamma \entail M : T} &= \syntrevsem{\Gamma \entail M : T} \filter \sem{\Gamma \gamear T} & \mbox{by (\ref{eqn:int_std_gamsem}) from Sec.~\ref{subsec:relating_revealed_and_standard_denotation}} \\
            &= \varphi_M(\travset(M)^\star) \filter \sem{\Gamma \gamear T} & \mbox{by assumption}\\
            &= \psi_M(\travset(M)^{\filter \theroot}) & \mbox{by Lemma \ref{lem:core_projection}}.
    \end{align*}
    Therefore we just need to prove $\varphi_M(\travset(M)^\star) = \syntrevsem{\Gamma \entail M : T}$.
\end{remark}
\smallskip

    Since the proof is rather technical, we first give an overview of the argument:
    We proceed by induction on the structure of the computation tree. The only non-trivial case is the application; the computation tree $\tau(M)$ has the following form:
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,inner ysep=0.5mm,sibling distance=15mm]
\node (root) {$\lambda\overline\xi$}
child {node {$@$}
    child{node {$\tau(N_0)$}}
    child{node{$\ldots$}}
    child{node {$\tau(N_p)$}}};
\end{tikzpicture}
\end{center}

    A traversal of $\tau(M)$ goes as follows: It starts at the root $\lambda \overline{\xi}$ of the tree $\tau(M)$ (rule \rulenamet{Root}), visits the node @ (rule \rulenamet{Lam}) and the root of $\tau(N_0)$ (rule \rulenamet{App}) and then proceeds by traversing the subtree $\tau(N_0)$. While doing so, some variable $y_i$ bound by $\tau(N_0)$'s root may be reached, in which case the traversal is interrupted by a jump to $\tau(N_i)$'s root (performed with the rule \rulenamet{Var}) and the process goes on with $\tau(N_i)$. Again, if the traversal encounters a variable bound by $\tau(N_i)$'s root then the traversal of $\tau(N_i)$ is interrupted and the traversal of $\tau(N_0)$ resumes.  This schema is repeated until the traversal of $\tau(N_0)$ is completed\footnote{Since we are considering simply-typed terms, the traversal does indeed terminate. However this will not be true anymore in the \pcf\ case.}.

    The traversal of $M$ is therefore made of an initialization part followed by an interleaving of a traversal of $N_0$ and
    several traversals of $N_i$ for $i=1..p$. This schema is reminiscent of the way the evaluation copy-cat map $ev$ works in game semantics.

    The crucial idea of the proof is that every time the traversal jumps from one subterm to another, the jump is permitted by one of the ``copy-cat'' rules \rulenamet{Var}, \rulenamet{Value^{\lambda\mapsto @}}, \rulenamet{Value^{{\sf var}\mapsto\lambda}}, \rulenamet{Value^{@\mapsto\lambda}}, or
    \rulenamet{Value^{\lambda\mapsto{\sf var}}}. We show by a second induction that these copy-cat rules implement precisely the copy-cat evaluation strategy $ev$.
\smallskip

\begin{proof}
Let $\Gamma \entail M : T$ be a simply-typed term where $\Gamma =
x_1:X_1,\ldots x_n:X_n$. We assume that $M$ is already in
$\eta$-long normal form. By remark \ref{rem:corresp_proofcore} we just need to
show that $\varphi_M(\travset(M)^\star) = \syntrevsem{\Gamma \entail M : T}$.
We proceed by induction on the structure of $M$:
\begin{itemize}[$\bullet$]
    \item (abstraction) $M \equiv \lambda \overline{\xi}. N : \overline{Y} \typear B$ where $\overline{\xi} = \xi_1:Y_1,\ldots \xi_n:Y_n$. On the one hand we have:
\begin{eqnarray*}
\syntrevsem{\Gamma \entail \lambda \overline{\xi}. N:T} &=& \Lambda^n( \syntrevsem{\overline{\xi}, \Gamma \entail N : B } ) \\
        &\simeq& \syntrevsem{\overline{\xi}, \Gamma \entail N : B } \enspace .
\end{eqnarray*}
On the other hand, the computation tree $\tau(N)$ is isomorphic to
$\tau(\lambda \overline\xi. N)$ (up to renaming of the computation tree's root), and $\travset(N)$ is isomorphic to
$\travset(\lambda \overline\xi. N)$.
Hence we can conclude using the induction hypothesis.

  \item (variable) $M \equiv x_i$. Since $M$ is in $\eta$-long normal form, $x$ must be of ground
      type. The computation tree $\tau(M)$ and the arena $\syntrevsem{\Gamma \gamear o}$ are represented below
      (value leaves and answer moves are not represented):
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,sibling distance=12mm,level 2/.style={sibling distance=8mm}]
\path node (root) {$\lambda$} child[level distance=6ex] {node {$x_i$}}
+(5cm,0)
node {$q_0$}
child {node {$q_1$}
    child[dotted]{node{}}
    child[dotted]{node{}}
    }
child {node {$q_2$}
    child[dotted]{node{}}
    child[dotted]{node{}}
    }
child{node{$\ldots$}}
child {node {$q_n$}
    child[dotted]{node{}}
    child[dotted]{node{}}
    };
\end{tikzpicture}
\end{center}
        Let $\pi_i$ denote the $i^{th}$ projection of the interaction game
        semantics. We have:
        \begin{align*}
        \syntrevsem{M} &= \pi_i = \prefset(\{ \Pstr{(q0){q_0} \cdot (qi){q^i} \cdot (vqi-qi){v_{q^i}} \cdot (vq0-q0){v_{q_0}} } \ | \ v\in \mathcal{D} \})\enspace .
        \end{align*}

        It is easy to see that traversals of $M$ are precisely
        the prefixes of $ \Pstr{ (lmd)\lambda \cdot (xi){x_i}
        \cdot (vxi-xi){v_{x_i}} \cdot (vlmd-lmd){v_{\lambda}}}$.
        Since $M$ is in $\beta$-normal we have $\travset(M)^\star =
        \travset(M)$, and since $\varphi_M(\lambda) = q_0$ and
        $\varphi_M(x_i) = q^i$ we have:
        $$ \varphi_M(\travset(M)^\star) = \varphi_M(\travset(M)) = \varphi_M(\prefset( \lambda \cdot x_i \cdot v_{x_i} \cdot v_{\lambda}))
         = \syntrevsem{M} \enspace .
        $$


    \item (@-application) $M \equiv N_0 N_1 \ldots N_p :o$ where $N_0$ is not a variable.
    We have the typing judgments $\Gamma \entail N_0 N_1 \ldots
    N_p : o$ and $\Gamma \entail N_i : B_i$ for $i\in 0..p$ where
    $B_0 = (B_1,\ldots,B_p,o)$ and $p\geq 1$.

    The tree $\tau(M)$ has the following form:
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=5ex,inner ysep=0.5mm,
sibling distance=20mm]
\node(root){$\lambda^{[\theroot]}$}
child{node{$@$}
    child{node{$\lambda y_1 \ldots y_p^{[\theroot_0]}$}
       child[child anchor=north,level distance=1ex] {node[isosceles triangle,draw,anchor=north,shape border rotate=90]{$\tau(N_0)$}}
    }
    child{node{$[\theroot_1]$}
       child[child anchor=north,level distance=1ex] {node[isosceles triangle,draw,anchor=north,shape border rotate=90]{$\tau(N_1)$}}
    }
    child{node{$\ldots$}}
    child{node{$[\theroot_p]$}
       child[child anchor=north,level distance=1ex] {node[isosceles triangle,draw,anchor=north,shape border rotate=90]{$\tau(N_p)$}}
    }
};
\end{tikzpicture}
\end{center}
    where $\theroot_j$ denote the root of $\tau(N_j)$ for $j\in
    \{0..p\}$.

    We have:
    $$
    \syntrevsem{\Gamma \entail M : o}
            =  \underbrace{\langle \syntrevsem{\Gamma \entail N_0 : B_0}, \ldots, \syntrevsem{\Gamma \entail N_p : B_p} \rangle}_{\Sigma}\ \| \ ev \enspace .
    $$

    In the following, we use the notations introduced in Fig.~\ref{fig:interaction_strategy_denotations} from section \ref{subsec:syntac_revealedsem} which fixes the names of the different games involved in the interaction strategy $\syntrevsem{M}$. In particular the games $A$, $B$ and $C$ are defined as:
    \begin{eqnarray*}
        A &=& X_1 \gameprod \ldots \gameprod X_n\\
        B &=& \underbrace{((B_1' \gameprod \ldots \gameprod B_p') \gamear o')}_{B_0} \gameprod B_1 \gameprod \ldots \gameprod B_p\\
        C &=& o \enspace .
    \end{eqnarray*}


    Let $q_0$ and $q_0'$ be the initial
    question of $C$ and $B_0$ respectively.

%    Since $\varphi_M = \psi_M \union \varphi_{N_0} \union
%    \varphi_{N_1}$ the induction hypothesis gives us:
%    \begin{align}
%    \varphi_{M} (\travset(N_0)^\star) &= \syntrevsem{\Gamma \entail N_0 : B_0} \label{eqn:ih_1} \\
%    \varphi_{M}(\travset(N_1)^\star) &= \syntrevsem{\Gamma \entail N_1 : B_1} \label{eqn:ih_2}
%    \end{align}
\begin{enumerate}
\item[$\subseteq$]
    We first prove that $\syntrevsem{\Gamma \entail M : T}
    \subseteq \varphi_{M}( \travset(M)^\star )$. Suppose $u
    \in \syntrevsem{\Gamma \entail M : T}$. We give a
    constructive proof that there is a traversal $t$
    such that $\varphi_M(t^\star) = u$ by induction on
    $u$.

    For the base case $u=\epsilon$, take $t$ to be the empty traversal formed with \rulenamet{Empty}.
    \emph{Step case:} Suppose that $u = u' \cdot m \in
    \syntrevsem{\Gamma \entail M : T}$ for some move $m \in
    M_T$ where $u' = \varphi_M(t'^\star)$ for some traversal
    $t'$ of $\tau(M)$.

    By unraveling the definition of $u \in \syntrevsem{\Gamma \entail M : T}$ we have:
    \begin{equation}
    \left.
    \begin{array}{ll}
(a)\quad       u \in J_T\enspace ;  \\
(b)\quad        \hbox{For every occurrence $b$ in $u$ of an initial $B_k$-move, for some $k \in \{0..p\}$:} \\
\quad\quad                \left\{\begin{array}{ll}
                    u \filter T^{0k} \filter b  \in \syntrevsem{N_k} \enspace , \\
                    u \filter T^{0k'} \filter b  = \epsilon \quad \mbox{ for every } k'\in \{0..p\}\setminus\{k\} \enspace ;
        \end{array}
        \right. \\
(c)\quad        u \filter B_0 = u \filter B_1, \ldots, B_p, C \enspace .
    \end{array}
    \right\}
      \label{eqn:u_in_app_intersem}
    \end{equation}

We recall that each $m \in M_T$ is an equivalence class of moves
from $\mathcal{M}_T$. For every game $A$ appearing in the
interaction game $T$ we will write ``$m \in A$'' to mean
that some element of the class $m$ belongs to the set of
moves $M_A$. Similarly, for every sub-interaction game $T'$ of
$T$, we write ``$m \in T'$'' to mean that some element of
the class $m$ belongs to the set of moves
$\mathcal{M}_{T'}$. We proceed by case analysis on $m$: We either have $m\in C$ or $m\in T^0$; in the last case $m$ is either in $A$, a superficial internal move in $B$ or a profound internal move in $B$:
    \begin{itemize}
    \item Suppose $m \in C$. Moves in $C$ are played by the standard strategy $ev$ that does not contain any internal move. Hence $m$ is either $q_0$ or $v_{q_0}$ for some $v\in\mathcal{D}$.

    Suppose that $m=q_0$. Since $q_0$ can occur only once in
    $u$ we have $u=q_0$ and the traversal $t=\lambda^{[\theroot]}$ formed with \rulenamet{Root} clearly satisfies $\varphi(t^\star) = u$.

    Otherwise $m=v_{q_0}$. This P-move is played by the
    copy-cat strategy $ev$ therefore it is the copy of some answer $v_{q_0'}$ to the question $q_0'$ from the sub-game $o'$. The move $v_{q_0'}$ is necessarily the immediate predecessor of $m$ in $u$. (Indeed the play $u_{\prefixof v_{q_0'}}\filter A,B$ is complete since its  first move $q_0'$ is answered by $v_{q_0'}$, and therefore $u_{\prefixof v_{q_0'}}\filter T^0$ is also complete by Lemma \ref{lem:inter_complete}; thus no profound internal move can be played between $v_{q_0'}$ and $v_{q_0}$, and therefore these two moves are consecutive.)

    Hence by the induction hypothesis the last move in $t'$ is $\varphi(v_{q_0'}) = v_{\lambda y_1}$.
    The rules \rulenamet{Value^{\lambda\mapsto @}} and \rulenamet{Value^{@\mapsto\lambda}} permits us to extend
    the traversal $t'$ to $t' \cdot v_@ \cdot v_{\lambda \overline{\xi}}$ where $v_@$ and $v_{\lambda
    \overline{\xi}}$ point to the second and first node of $t'$ respectively. Clearly we have $\varphi_M((t'\cdot v_@ \cdot v_{\lambda \overline{\xi}})^\star) = u$.

    \item Suppose $m\in T^0$ and $m$ is an initial move in $B_0$.
    Then necessarily $m$ is $q_0' \in \sem{o'}$, the copy-cat move of the initial move $q_0 \in C$ of $u$. Hence $u = q_0 \cdot q_0'$. The rules \rulenamet{Root}, \rulenamet{App}
and \rulenamet{Lam} permit us to build the traversal $t =
\lambda^{[\theroot]} \cdot @ \cdot \lambda
\overline{y}^{[\theroot_0]}$ which clearly satisfies
$\varphi_M(t^\star) = u$.

    \item Suppose $m\in T^0$ and $m$ is an initial move in $B_k$ for some $k\in \{1..p\}$. Then $m$ is necessarily a copy-cat move played by the evaluation strategy, and the move $m^1$ immediately preceding $m$ in $u$ is an initial move of the component $B'_k$ of $B_0$.

    Thus since $\varphi_M(t'^\omega) = m^1$, $t'^\omega$ must be an occurrence of the node $y_k$---the $k^{th}$ variable bound by $\lambda \overline{y}$. We can thus form, with the rule \rulenamet{Var}, the traversal $t= t' \cdot \theroot_k$ satisfying $\varphi_M(t^\star) = \varphi_M(t'^\star) \cdot m = u$.


    \item Suppose $m\in T^0$ and $m$ is not initial in $B$. In $u \filter T^0$, $m$ must be hereditarily justified by some initial move $b$ in $B_k$ for some $k\in \{0..p\}$. Since $u \filter T^{0k} \filter b \in \syntrevsem{N_k}$, the outermost induction hypothesis gives us:
        \begin{equation}
        u \filter T^{0k} \filter b = \varphi_{N_k}(t_k^\star)  \label{eqn:corresp_outmost_ih}
        \end{equation}
        for some traversal $t_k \in \travset(N_k)$ where w.l.o.g.\ we can assume that $t_k^\omega \not\in \Nodes_@$. We have:
        \begin{align*}
            \varphi_M (t_k^\omega) &= (\varphi_M (t_k^\star))^\omega & \mbox{since $t_k^\omega \not\in \Nodes_@$}\\
                                   &= ((u' \cdot m) \filter T^{0k}\filter b)^\omega & \mbox{by (\ref{eqn:corresp_outmost_ih})}\\
                                   &= ((u' \filter T^{0k}\filter b) \cdot m))^\omega & \mbox{since $m$ is h.j. by $b$ and belongs to $T^{0k}$}\\
                                   &= m \enspace .
        \end{align*}

        Take $t = t'\cdot t_k^\omega$ where $t_k^\omega$ points in $t'$ to the image by $\varphi_M$ of the occurrence justifying $m$ in $u$. Since $t_k^\omega \neq @$ we have  $t^\star = t'^\star \cdot t_k^\omega$ where $t_k^\omega$ justifier in $t'^\star$ is the same as its justifier in $t$.


        Hence we have $\varphi_{M}(t^\star) =  \varphi_{M}(t'^\star)  \cdot \varphi_{M}(t_k^\omega)$ which, by the innermost I.H.\ together with the previous equation, equals $u' \cdot m$ where $m$'s justifier in $u'$ corresponds to $\varphi_{M}(t_k^\omega)$'s justifier in $\varphi_{M}(t'^\star)$. Consequently:
        \begin{equation}
                \varphi_M(t^\star) =  u  \enspace . \label{eqn:corresp_phi_t_minu_at_eq_u}
        \end{equation}
\smallskip

        We are half-done at this point, it remains to show that $t$ is indeed a traversal of $\tau(M)$. Let $r_k$ denote the occurrence of the root
        $\theroot_k$ in $t$ that is mapped to the
        occurrence $b$ in $\varphi_{M}(t^\star)$. We make the following claim:
        \begin{equation}
            t_k = t \filterplus r_k \enspace . \label{equ:claim_tk}
        \end{equation}

        Indeed we have:
        \begin{align*}
        \varphi_{N_k}(t_k^\star) &= u \filter T^{0k}\filter b
            & \mbox{by (\ref{eqn:corresp_outmost_ih})} \\
         &= \varphi_{M}(t^\star) \filter T^{0k}\filter b
            & \mbox{by (\ref{eqn:corresp_phi_t_minu_at_eq_u})} \\
         &= \varphi_{N_k}(t^\star \filter \Nodes^{(\theroot_k)} \filter r_k )
            & \mbox{by Lemma \ref{lem:varphi_proj}.}
        \end{align*}
        Since $\varphi_{N_k}$ is a bijection from  $\travset(N_k)^\star$ to $\varphi_{N_k}(\travset(N_k)^\star )$ (by Corollary \ref{cor:varphi_bij}) this implies that  $t_k^\star = t^\star \filter \Nodes^{(\theroot_k)} \filter r_k$ which in turn equals $(t\filterplus r_k)^\star$ by Lemma \ref{lem:tstarproj_eq_tprojplusstar} from Sec.~\ref{sec:tstar}. But since $t_k$ and $t$ do not end with an @-node, this implies equality (\ref{equ:claim_tk}).
    \smallskip

    We now show that $t$ is indeed a traversal by a case analysis of the rule used to visit the last occurrence of $t_k$ in the tree $\tau(N_k)$:
    \begin{enumerate}[(a)]
    \item  Suppose the rule used to visit $t_k^\omega$ is neither \rulenamet{InputVar} nor $\rulename{InputVar^{val}}$.
        Then by Lemma \ref{lem:subtraversal_progression}, $t$ is a traversal of $M$.

    \item Suppose $t_k^\omega$ is visited with \rulenamet{InputVar}. Then $t_k$ is of the form
        $$\Pstr[17pt]{ t_k = \ldots \cdot (z)z \cdot \ldots \cdot (n-z){t_k^\omega}}$$
        for some input-variable $z \in
        \INodes^{\theroot_k\enable}_{\sf var}$ occurring in
        $\oview{t_k}$ and where $t_k^\omega \in \INodes_\lambda^{\theroot_k\enable}$.


        Thus:
        $$u = \Pstr[0.5cm]{ \ldots \cdot (m3){\stk{\psi_{N_k}(z)}{=m^3}} \cdot
                    \ldots \cdot (m-m3,30){\stk{\psi_{N_k}(t_k^\omega)}{=m}} } \enspace .$$


%        Since $z$ is hereditarily enabled by the $\theroot_k$ and
%        appears in the immediate prefix of $t_k$ (which equals $t' \filterplus r_k$), it is
%        necessarily her.\ \emph{justified} by $r_k$ in
%        $t_k$. Thus $\psi_{N_k}(z)$ is hereditarily justified  by $b \in B_k$ in $\psi_{N_k}(t_k\filter r_k)$
%        (and therefore so is $\psi_{N_k}(t_k^\omega)$).

        The occurrence $t_k^\omega$ is hereditarily enabled by the root $\theroot_k$ itself enabled by an application node, thus $t_k^\omega$ is not hereditarily enabled by the root $\theroot$.
        Since only nodes that are hereditarily enabled by the root are mapped to move in $A$ we know that $\psi_{N_k}(t_k^\omega)$ is not played in $A$ and therefore $\psi_{N_k}(t_k^\omega) \in B_k$. Similarly we have $\psi_{N_k}(z) \in B_k$.

        Now consider the top-most composition in the interaction strategy $\syntrevsem{M}$---that of the interaction strategy $\Sigma : A \gamear B$ with the evaluation copy-cat strategy $ev:B \gamear o$. Consider the sub-sequence $u \filter A,B,C$ of $u$ consisting only of moves involved in this top-most composition (\ie, the internal moves coming from other compositions at deeper level in the revealed semantics are removed). Since $z$ is a variable node, the move $m^3 = \psi_{N_k}(z) \in B_k$ is a P-move with \emph{respect to the game} $\sem{A \gamear B_k}$, and therefore it is an O-move in the game $\sem{B \gamear o}$. Consequently the strategy $ev$ is responsible to play at $u_{\prefixof m^3} \filter A, B, C$. Let $m^2$ denote the move played by $ev$ which immediately follows $m^1$ in $u\filter A,B,C$.

        We claim that $m^3$ and $m^2$ are also consecutive in $u$. That is to say that no internal moves generated from the        other compositions at deeper levels in the interaction strategy can ever be played between $m^3$ and $m^2$. Indeed, firstly the strategy $ev$ is a pure standard strategy thus it does not play any (profound) internal move. Furthermore, suppose that the strategy $\Sigma$ comes from the composition $\Sigma_l \| \Sigma_r$ of two interaction strategies $\Sigma_l : A \gamear D$ and $\Sigma_r : D\gamear B$ for some game $D$, then by the Switching Condition for function-space game \cite{hylandong_pcf} the Opponent cannot switch of component, and thus the move following $m^3$ in the interaction sequence $u \filter A,D,B$ must belong to $B$. Hence internal moves from $D$ cannot be played immediately after $m^3$.

        Similarly, we can show that the move $m$ is played by the strategy $ev$ and is the copy of the move $m^1$ immediately preceding it in $u\filter A,B,C$ as well as in $u$.

        Hence the sequence $u$ has the following form:
        $$u = \Pstr[0.6cm]{ \ldots \cdot (m3){m^3} \cdot
                    (m2){m^2} \cdot \ldots \cdot
                    (m1-m2,30:i){m^1} \cdot (m-m3,37:i){m} } \enspace .$$
        Consequently we have:
        \begin{align*}
        t_k &= \Pstr{ \ldots \cdot (m)z \cdot \ldots \cdot (n-m,30:i){t_k^\omega} }  &
        t'&= \Pstr[0.5cm]{ \ldots \cdot z \cdot (n2){\lambda \overline{y}} \cdot \ldots \cdot (n1-n2,30:i){y} } \enspace .
        \end{align*}

        The first equation implies that $t_k^\omega$ is the $i^{th}$ child of $z$ in the computation tree,
        thus since $z\not\in \INodes^{\theroot\enable}$, we can apply the (Var) rule to the second equation which produces the traversal of $\tau(M)$:
        \begin{eqnarray*}
            t' \cdot t_k^\omega = \Pstr[0.5cm]{ \ldots \cdot (n3){z} \cdot (n2){\lambda \overline{y}} \cdot \ldots \cdot (n1-n2,30:i){y} \cdot (n-n3,35:i){t_k^\omega} }
        \end{eqnarray*}
        which is precisely the sequence $t$. Hence $t$ is indeed a traversal of $\tau(M)$.

    The diagram on Fig.~\ref{fig:example_seq_u} shows an example of such interaction sequence $u$.
    \begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[style={anchor=base}]
    \matrix [matrix of math nodes, column sep=1ex, row sep=0pt]
    {   & A & \longrightarrow & ( (B_1' &\gamear & o') & \gameprod & B_1 ) & \longrightarrow & o  \\
      &&& &&&&&& \node(q0){q_0 (\lambda \overline{\xi})}; & O\\
      &&& &&&&&  \\
    O &&& && \node(q1){q_0' (\lambda \overline{z})}; &&&&& P \\
    P &&& \node(m3){m^3 (z)}; &&&&&&& O \\
    O &&& &&&& \node(m2){m^2 (\lambda \overline{y})}; &&& P \\
    P &&& &&&& \node(m1){m^1 (y)}; &&& O \\
    O &&& \node(m){m (t_k^\omega)}; &&&&&&& P \\
    };
    \path[->,draw] (q1) -- node[fill=white]{@} (q0);
    \path[->,draw] (m1.west) .. controls +(160:7pt) and +(200:5pt) .. (m2.west);
    \path[->,draw] (m3) -- (q1);
    \path[->,draw] (m) --  (m3);
    \path[->,draw] (m2) -- (q0);
    \end{tikzpicture}
    \caption{Example of a sequence $u\filter A,B,C$ for $u\in\syntrevsem{M}$ and $l=1$.}
    \label{fig:example_seq_u}
    \end{figure}


    \item Suppose $t_k$'s last move is visited with the rule $\rulename{InputVar^{val}}$ then the proof is the same as in the previous case but with $\rulename{InputVar^{val}}$ substituted for $\rulename{InputVar}$.
    \end{enumerate}

    \end{itemize}

\item[$\supseteq$]
  The converse, $\varphi_{M}( \travset(M)^\star) \subseteq \syntrevsem{M}$, is the easy part of the proof.

  Let $u$ be as sequence of $\varphi_{M}( \travset(M)^\star)$. Then
  $u = \varphi_{M}(t^\star)$ for some traversal $t$ of $\tau(M)$. To show that
  $u$ is a position of $\syntrevsem{\Gamma \entail M : T}$ we have to prove that it satisfies the three conditions of  (\ref{eqn:u_in_app_intersem}):
\begin{itemize}
    \item (a) By definition, $\varphi_{M}$ maps justified sequences of nodes to justified sequences of moves from $M_T$ therefore $\varphi_{M}(t^\star) \in J_T$.

    \item (b) Take an initial $B$-move $b \in B_k$, for some $k\in\{0..p\}$, occurring in $\varphi_{M}(t^\star)$. There is a corresponding occurrence $r_k$ in $t$ of a level-$2$ lambda node $\theroot_k$ of $\tau(M)$.
    By definition, the function $\varphi_{M}$ maps nodes from the subtree of $\tau(M)$ rooted at $\theroot_{k'}$, for every $k'\in \{0..p\}$, to moves of the game $\syntrevsem{\Gamma \typear B_{k'}}$ that are hereditarily justified by some occurrence of $\varphi_M(\theroot_{k'})$.
    Hence for every $k'\in \{0..p\}\setminus\{k\}$ we clearly have $\varphi_{M}(t^\star) \filter T^{0k'} \filter b = \epsilon$.
    Moreover:
    \begin{align*}
        u \filter T^{0k}\filter b &= \varphi_{M}(t^\star) \filter T^{0k}\filter b \\
         &= \varphi_{M}(t^\star \filter \Nodes^{(\theroot_k)} \filter r_k ) & \mbox{by Lemma \ref{lem:varphi_proj}} \\
         &= \varphi_{M}((t\filterplus r_k)^\star) & \mbox{by Lemma \ref{lem:tstarproj_eq_tprojplusstar}} \\
         &= \varphi_{N_k}((t\filterplus r_k)^\star) & \mbox{since $t\filterplus r_k$ is a traversal of $N_k$ by Prop.~ \ref{prop:trav_projection}} \\
         &\in \varphi_{N_k}(\travset(N_k)^\star) \\
         &\quad = \syntrevsem{N_k} & \mbox{by the induction hypothesis.}
    \end{align*}
    \item  (c) We can show that $\varphi_{M}(t^\star) \filter B_0 = \varphi_{M}(t^\star) \filter B_1, \ldots, B_p, C$ by a trivial induction on the traversal $t$. (This property holds because of the way the traversal rules mimic the behaviour of the evaluation strategy.)
    \end{itemize}

\end{enumerate}


    \item (Var-application) $M \equiv x_i N_1 \ldots N_p :o$.

    The revealed denotation is
    $\syntrevsem{\Gamma \entail M : o} =  \underbrace{\langle
            \pi_i, \syntrevsem{\Gamma \entail N_1 : B_1}, \ldots,
            \syntrevsem{\Gamma \entail N_p : B_p} \rangle}_{\Sigma}
            ;^{\emptyset,\{1..p\}} \ ev$
    and the computation tree is
%\parpic(5.5cm,4cm)[r]
{\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,inner ysep=0.5mm,sibling distance=15mm]
\node (root) {$\lambda^{[\theroot]}$}
child {node {$x_i$}
    child{node{$\tau(N_1)^{[\theroot_1]}$}}
    child{node{$\ldots$}}
    child{node{$\tau(N_p)^{[\theroot_p]}$}}};
\end{tikzpicture} .
\end{center}
   }

    We use the notations of Fig.~\ref{fig:interaction_strategy_denotations} for names of the games involved in the interaction strategy. The composition of $\Sigma$ with $ev$ takes place on the following games:
    $$\overbrace{X_1 \times \ldots \overbrace{((B_1'' \times \ldots \times B_p'') \typear o'')}^{X_i} \ldots \times X_n}^A \stackrel\Sigma\longrightarrow \overbrace{\tikz[baseline=(r.base)]{ \node[draw,dashed](r){$\overbrace{((B_1' \times \ldots \times B_p') \typear o')}^{B_0} \times B_1 \times \ldots B_p $};}}^B \stackrel{ev}\longrightarrow \overbrace{o}^C$$

        Let $q_0$, $q_0'$ and $q_0''$ be the initial
    question of $C$, $B_0$ and $X_i$ respectively.
    \begin{description}
        \item[$\syntrevsem{\Gamma \entail M : T} \subseteq \varphi_{M}( \travset(M)^\star )$.] We show (constructively) by induction that for every $v \in \Sigma \| ev$, there is some traversal $t$ such that
        the sequence $u = \hide(v, \{0..p\}, \{0\})$ equals $\varphi_M(t^\star)$.

    The base case $v=\epsilon$ is trivial. Suppose that $v = v' \cdot m \in  \Sigma   \| ev$  where $\hide(v', \{0..p\}, \{0\}) = \varphi_M(t'^\star)$ for some traversal $t'$ of $\tau(M)$ and move $m \in M_T$. Unraveling the definition of $v \in \Sigma \| ev$ gives
    \begin{equation}
    \left.
    \begin{array}{ll}
              & \hbox{- } v \in J_T; \\
              & \hbox{- for every occurrence $b$ in $v$ of an initial $B_k$-move for some $k \in \{0..p\}$:} \\
        & \begin{array}{ll}
            v \filter T^{00} \filter b  \in \pi_i \hbox{ if $k=0$ and } v \filter T^{0k} \filter b  \in \syntrevsem{N_k} \hbox{ if $k>0$,} \\
            \hbox{and } \forall k'\in \{0..p\}\setminus\{k\} .\ v \filter T^{0k'} \filter b  = \epsilon;
        \end{array}
        \\
         & \mbox{- and } v \filter B_0 = v \filter B_1, \ldots, B_p, C \enspace .
    \end{array}
    \right\}
    \label{eqn:u_in_varapp_intersem}
    \end{equation}



    We proceed by case analysis on $m$. It is either played in $A$, $B$ or $C$.
        \begin{enumerate}[1.]
            \item $m\in C$. The proof is the same as in the @-application case except that the rules \rulenamet{Value^{\lambda\mapsto{\sf var}}} and \rulenamet{Value^{{\sf var}\mapsto\lambda}} are used instead of \rulenamet{Value^{\lambda\mapsto @}} and \rulenamet{Value^{@\mapsto\lambda}} respectively.

            \item $m$ is a superficial internal $B$-move. Then $\hide(v,\{0..p\}, \{0\}) = \hide(v', \{0..p\}, \{0\})$ so we can directly conclude from the I.H.

            \item $m$ is a profound internal $B$-move. Then necessarily $m$ belongs to $B_k$ for some $k\in \{1..p\}$ (since $\pi_i$ does not contain internal moves). Thus $m$ must be hereditarily justified by some $b \in B_k$. The treatment of this case is identical to the @-application case where $m\in T^0$ is not initial in $B$ and $b \in B_k$ for some $k\in \{0..p\}$.

            \item $m \in A$. Let $b$ denote the initial $B_k$-move that hereditarily justifies $m$ for some $k \in\{0..p\}$.
                  If $k>0$ then the treatment is the same as in case 3. Otherwise $b \in B_0$:

                   \begin{itemize}
                     \item Suppose $m$ is an occurrence of the initial $o''$-move $q_0''$. Then $m$ is played by $\pi_i$ and therefore is the copy of $q_0'$ itself the copy of the initial move $q_0$ of $v$. Thus $v = q_0 \cdot q_0' \cdot q_0''$ and $u = q_0 \cdot q_0''$. The traversal $t = \lambda^{[\theroot]} \cdot x_i$ formed using the rules \rulenamet{Root} and \rulenamet{Lam} meets the requirement.

                   \item Otherwise since $v \filter b \in \pi_i$ we have $ v \filter b \filter X_i = v \filter b \filter B_0$ therefore $m$ must necessarily be hereditarily justified by the \emph{first} occurrence of $q_0''$ in $v$.

                       \begin{itemize}
                         \item Suppose $m$ is an $\omove$-question.
                       Then the preceding move in $v$ is necessarily a $\pmove$-move also played in $A$ by the strategy $\pi_i$ and therefore it is also hereditarily justified by the first occurrence of $q_0''$.

                       By definition of $\varphi_M$, the last node in  $t'$ is a variable node (if the preceding move is a $\pmove$-question) or a value-leaf of a lambda node (if the preceding move is a $\pmove$-answer) that is hereditarily justified by the node $x_i$. Hence the  rule \rulenamet{InputVar} can be applied at $t'$.

                       Let $m'$ be $m$'s justifier in $v'$ and $\alpha'$ be the corresponding node in $t'$ that $\varphi_M$ maps to $m'$.
                       Suppose $m$ is the $i^{th}$ move enabled by $m'$ in the arena and let $\alpha$ be the $i^{th}$ child node of $\alpha'$ in $\tau(M)$. By definition of $\varphi_M$ we have $\varphi_M(\alpha) = m$.
                       We want to show that we can use the rule \rulenamet{InputVar} to append $\alpha$ to the traversal $t'$. Since we have $v\filter A,C \in \sem{M}$, by O-visibility $m'$ appears in $\oview{v'\filter A,C}$, and by the induction hypothesis we have $v'\filter A,C = \psi_M (t'\filter r)$. Hence \begin{align*}
                       m' \in \oview{\psi_M (t'\filter r)} &= \psi_M ( \oview{t'\filter r}) \\
                          &= \varphi_M ( \oview{t' \filter r}) & \mbox{since $\varphi_M$ and $\psi_M$ coincide on $\Nodes^{\theroot \enable}$,} \\
                        &= \varphi_M ( \oview{t'}) & \mbox{by Lemma \ref{lem:oviewproj_wrt_theroot}.} \end{align*}
               This implies that $\alpha'$ appears in $\oview{t'}$ which allows us to use the rule \rulenamet{InputVar} to form the traversal $t = t'\cdot \alpha$ satisfying $\varphi_M(t^\star) =               \hide(v,\{0..p\},\{0\})$.

                \item Suppose $m$ is a $\pmove$-answer. The same argument as above holds but using \rulenamet{InputValue} instead of \rulenamet{InputVar}.

               \item  Suppose $m$ is an $\omove$-question.
                   We proceed identically using the rule \rulenamet{Lam} instead of \rulenamet{InputVar}. The proof that
                   $\alpha'$ appears in the P-view $\pview{t'}$ goes as follows:

                   Let $\pview{v}$ denote the \emph{core} of the interaction sequence $v$ \cite{McCusker-GamesandFullAbstrac}. By P-visibility in $v\filter A,C$, $m$ occurs in $\pview{v' \filter A,C}$.
                   Further we have $\pview{v' \filter A,C} = \pview{v'} \filter A,C$ \cite{McCusker-GamesandFullAbstrac}, and clearly $\pview{v'} \filter A,C$ equals $\pview{\hide(v', \{0..p\}, \{0\})}\filter A,C$.
                   Hence
                    \begin{align*}
                       m' \in \pview{\varphi_M (t'^\star)} \filter A,C &\subseqof  \pview{\varphi_M (t'^\star)} \enspace .
                   \end{align*}
                   This implies that $\alpha'$ occurs in $\pview{t'^\star}$, which is a subsequence of $\pview{t'}$ by (\ref{eqn:pview_tstar}). (See Sec.~\ref{subsec:tstar}).

               \item  If $m$ is a $\pmove$-answer then we proceed as above but using the rule \rulenamet{Value} instead.
               \end{itemize}
        \end{itemize}

\item[$\varphi_{M}( \travset(M)^\star) \subseteq \syntrevsem{M}$.]
  Let $t$ be some traversal of $\tau(M)$. To show that
  $\varphi_{M}(t^\star)$ is a position of $\syntrevsem{\Gamma \entail M : T}$ we have to prove that $\varphi_{M}(t^\star) = \hide(v, \{0..p\}, \{0\})$ for some $v$ satisfying condition (\ref{eqn:u_in_varapp_intersem}).   It suffices to take $v = \synthuncover_{\Sigma,ev}(\varphi_{M}(t^\star))$
  where $\synthuncover_{\Sigma,ev}$ denotes the function defined in Sec.~\ref{subsub:defdelta} that transforms plays of the syntactically-revealed semantics to their corresponding plays of the fully-revealed semantics. The rest of the argument is the same as in the @-application case. \qedhere

        \end{enumerate}

    \end{description}

\end{itemize}
\end{proof}


\begin{corollary} \hfill
If $M$ is in $\beta$-normal form then for every traversal $t$,
$\varphi_M(t)$ is a maximal play if and only if $t$ is a maximal
traversal.
\end{corollary}
\begin{proof}
If $M$ is in $\beta$-normal form then
$\travset(M)^{\filter \theroot} = \travset(M)$ therefore
$\varphi$ defines a bijection on $\travset(M)$. Let $t$ be a
traversal such that $\varphi(t)$ is a maximal play. Let $t'$ be
a traversal such that $t \prefixof t'$. By monotonicity of
$\varphi$ we have $\varphi(t) \prefixof \varphi(t')$ which
implies $\varphi(t) = \varphi(t')$ by maximality of $\varphi(t)$
which in turn implies $t'=t$ by injectivity of $\varphi$. The
other direction is proved identically using injectivity and
monotonicity of $\varphi^{-1}$.
\end{proof}
\smallskip The diagram on Fig.~\ref{fig:correspondence} recapitulates the main results of
this section.
\begin{figure}[htbp]
\centering
\begin{tikzpicture}[style={anchor=base}]
  \matrix (m) [matrix of math nodes, column sep=3cm, row sep=0.7cm]
  {
   & \travset(M)^\star  & \syntrevsem{M} \\
    \travset(M)  & &  \\
   & \travset(M)^{\filter \theroot} & \sem{M} \\
  };

\draw[->] ([yshift=3pt]m-2-1.east) to [out=30,in=180] node[above]{$\_^\star = \_\ -@-\Sigma$\ } ([yshift=3pt]m-1-2.west) ;
\draw[<-] ([yshift=0pt]m-2-1.east) to [out=0,in=210]  node[below]{\ $\_\ +@+\Sigma$} ([yshift=0pt]m-1-2.west) ;
\draw[->] ([yshift=-3pt]m-2-1.east) to [out=-30,in=180] node[above]{$\_ \filter \theroot$} ([yshift=-3pt]m-3-2.west)  ;

\draw[->] ([yshift=3pt]m-1-2.east) -- node[above]{$\varphi_M$} ([yshift=3pt]m-1-3.west) ;
\draw[<-] ([yshift=-3pt]m-1-2.east) -- node[below]{$\varphi_M^{-1}$}  ([yshift=-3pt]m-1-3.west) ;

\draw[->] ([yshift=3pt]m-3-2.east) -- node[above]{$\varphi_M$} ([yshift=3pt]m-3-3.west);
\draw[<-] ([yshift=-3pt]m-3-2.east) -- node[below]{$\varphi_M^{-1}$} ([yshift=-3pt]m-3-3.west);

\draw[->] ([xshift=-3pt]m-3-3.north) -- node[left]{full uncovering} ([xshift=-3pt]m-1-3.south);
\draw[<-] ([xshift=3pt]m-3-3.north)  -- node[right]{$\_ \filter \sem{\Gamma\gamear T}$} ([xshift=3pt]m-1-3.south);
\end{tikzpicture}

\noindent where an arrow `$A \stackrel{f}\longrightarrow B$' indicates that
$f(A) = B$.

\caption{Transformations involved in the Correspondence Theorem.}
\label{fig:correspondence}
\end{figure}
% SAME DIAGRAM USING XYPIC
%$$
%\xymatrix @C=6pc{
%                                           & \travset(M)^\star \ar@/^/[dl]^{\_\ +@+\Sigma}  \ar@/^/[r]^{\varphi_M}
%                                           & \syntrevsem{M}
%                                           \ar@/^/[l]^{\varphi_M^{-1}} \ar@/^/[dd]^{\_ \filter \sem{\Gamma\gamear T}} \\
%\travset(M) \ar@/^/[ur]^{\_^\star = \_\ -@-\Sigma}^{} \ar[dr]^{\_ \filter \theroot}  \\
%                                           & \travset(M)^{\filter \theroot} \ar@/^/[r]^{\varphi_M} & \sem{M}
%                                           \ar@/^/[l]^{\varphi_M^{-1}}
%                                           \ar@/^/[uu]^{\mbox{full uncovering}}
%}
%$$


\begin{example}
Take $M \equiv \lambda f z . (\lambda g x . f x) (\lambda y. y) (f z) :
((o,o),o, o)$.  The figure below represents the computation tree
(left tree), the arena $\sem{((o,o),o, o)}$ (right tree) and
$\psi_M$ (dashed line). (Only question moves are shown for clarity.)
The justified sequence of nodes $t$ defined hereunder is an example
of traversal:
\bigskip

\noindent\begin{tabular}{cc}
\begin{minipage}{6cm}
\centering
\begin{tikzpicture}[baseline=(root.base),level distance=4ex,sibling distance=8mm,inner ysep=0.5mm]
\path
node (root){$\lambda f z$}
child{node{$@$}
 child{node{$\lambda g x$} child{node(f1){$f^{[1]}$}child{node(l2){$\lambda^{[2]}$}child{node{$x$}}}}}
 child{node{$\lambda y$} child{node{$y$}}}
 child{node{$\lambda^{[3]}$} child{node(f4){$f^{[4]}$} child{node(l5){$\lambda^{[5]}$}child{node(z){$z$}}}}}
}
+(4cm,0)
node (q0){$q^0$}
child[level distance=7ex]{node(q1){$q^1$} child[level distance=4ex]{node(q2){$q^2$}}}
child[level distance=7ex]{node(q3){$q_3$}};
\draw[dashed,->] (root) -- node[fill=white]{$\psi_M$} (q0);
\draw[dashed,->] (f1) -- (q1);
\draw[dashed,->] (f4) --  (q1);
\draw[dashed,->] (l2) .. controls +(0:1cm) and +(200:1cm) .. (q2);
\draw[dashed,->] (l5) .. controls +(0:1cm) and +(-90:20pt) .. (q2);
\draw[dashed,->] (z) .. controls +(0:2.5cm) and +(-90:1cm) ..  (q3);
\end{tikzpicture}
\end{minipage}
&
\begin{minipage}{8cm}
\begin{asparablank}
  \item  \Pstr[1cm]{
t = (n){\lambda f z} \cdot
(n2){@} \cdot
(n3-n2,60){\lambda g x} \cdot
(n4-n,45){f^{[1]}}\cdot
(n5-n4,45){\lambda^{[2]}} \cdot
(n6-n3,45){x} \cdot
(n7-n2,35){\lambda^{[3]}} \cdot
(n8-n,35){f^{[4]}} \cdot
(n9-n8,45){\lambda^{[5]}} \cdot
(n10-n,35){z}
}

\item \Pstr[1.2cm]{
t\filter \lambda f z = (n){\lambda f z} \cdot (n4-n,50){f}^{[1]} \cdot
(n5-n4,60){\lambda}^{[2]} \cdot (n8-n,45){f}^{[4]} \cdot
(n9-n8,60){\lambda}^{[5]} \cdot (n10-n,40){z}}
\item
\Pstr[1.2cm]{ {\varphi_M(t\filter \lambda f z) =\ } (n){q^0}\cdot
(n4-n,60){q^1}\cdot (n5-n4,60){q^2}\cdot (n8-n,45){q^1}\cdot
(n9-n8,60){q^2}\cdot (n10-n,38){q^3} \in \sem{M}\enspace .}
\end{asparablank}
\end{minipage}
\end{tabular}
\end{example}


\begin{remark}
Observe that the way we have defined traversals, the Opponent, contrary to the Proponent, is not required to play deterministically, let alone innocently. It is only required that he plays visibly (\ie, his justifiers must appear in the O-view) and respects well-bracketing. This means that the game-denotation given by the Correspondence Theorem also accounts for contexts that are not simply-typed terms. This indeed corresponds to the standard innocent game model of \pcf: the morphisms of the category $\mathcal{C}_{ib}$ are P-innocent strategies but not O-innocent. The addition of O-knowing-plays in the denotations is conservative for observational equivalence because the full-abstraction result holds in the category quotiented by the intrinsic preorder, and in the definition of the preorder, the ``test'' strategy $\alpha$ ranges over innocent strategies only.
\end{remark}


